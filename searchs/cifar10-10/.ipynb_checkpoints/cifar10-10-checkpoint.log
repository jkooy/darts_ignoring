07/20 09:44:39 PM | 
07/20 09:44:39 PM | Parameters:
07/20 09:44:39 PM | ALPHA_LR=0.0003
07/20 09:44:39 PM | ALPHA_WEIGHT_DECAY=0.001
07/20 09:44:39 PM | BATCH_SIZE=64
07/20 09:44:39 PM | DATA_PATH=./data/
07/20 09:44:39 PM | DATASET=cifar10
07/20 09:44:39 PM | EPOCHS=50
07/20 09:44:39 PM | GPUS=[0]
07/20 09:44:39 PM | INIT_CHANNELS=16
07/20 09:44:39 PM | LAYERS=8
07/20 09:44:39 PM | NAME=cifar10-10
07/20 09:44:39 PM | PATH=searchs/cifar10-10
07/20 09:44:39 PM | PLOT_PATH=searchs/cifar10-10/plots
07/20 09:44:39 PM | PRINT_FREQ=50
07/20 09:44:39 PM | SEED=2
07/20 09:44:39 PM | W_GRAD_CLIP=5.0
07/20 09:44:39 PM | W_LR=0.025
07/20 09:44:39 PM | W_LR_MIN=0.001
07/20 09:44:39 PM | W_MOMENTUM=0.9
07/20 09:44:39 PM | W_WEIGHT_DECAY=0.0003
07/20 09:44:39 PM | WORKERS=4
07/20 09:44:39 PM | 
07/20 09:44:39 PM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:44:51 PM | Train: [ 1/50] Step 000/001 Loss 2.533 Prec@(1,5) (12.5%, 25.0%)
07/20 09:44:54 PM | Train: [ 1/50] Step 001/001 Loss 2.502 Prec@(1,5) (11.1%, 33.3%)
07/20 09:44:55 PM | Train: [ 1/50] Final Prec@1 11.1111%
07/20 09:44:55 PM | Valid: [ 1/50] Step 000/390 Loss 2.372 Prec@(1,5) (4.7%, 45.3%)
07/20 09:45:04 PM | Valid: [ 1/50] Step 050/390 Loss 2.342 Prec@(1,5) (9.4%, 48.6%)
07/20 09:45:14 PM | Valid: [ 1/50] Step 100/390 Loss 2.338 Prec@(1,5) (9.8%, 49.4%)
07/20 09:45:23 PM | Valid: [ 1/50] Step 150/390 Loss 2.337 Prec@(1,5) (9.7%, 49.4%)
07/20 09:45:32 PM | Valid: [ 1/50] Step 200/390 Loss 2.338 Prec@(1,5) (9.8%, 49.2%)
07/20 09:45:41 PM | Valid: [ 1/50] Step 250/390 Loss 2.336 Prec@(1,5) (9.8%, 49.5%)
07/20 09:45:51 PM | Valid: [ 1/50] Step 300/390 Loss 2.335 Prec@(1,5) (9.9%, 49.7%)
07/20 09:46:00 PM | Valid: [ 1/50] Step 350/390 Loss 2.335 Prec@(1,5) (9.9%, 49.8%)
07/20 09:46:08 PM | Valid: [ 1/50] Step 390/390 Loss 2.336 Prec@(1,5) (10.0%, 49.7%)
07/20 09:46:08 PM | Valid: [ 1/50] Final Prec@1 9.9720%
07/20 09:46:08 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('avg_pool_3x3', 0)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('skip_connect', 1)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('sep_conv_5x5', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1251, 0.1248, 0.1249, 0.1250, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1249, 0.1251, 0.1252, 0.1249, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1253, 0.1251, 0.1250, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1250, 0.1246, 0.1248, 0.1253, 0.1249, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1248, 0.1251, 0.1253, 0.1250, 0.1251, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1248, 0.1250, 0.1250, 0.1250, 0.1253, 0.1252, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1248, 0.1251, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1248, 0.1249, 0.1251, 0.1249, 0.1249, 0.1251],
        [0.1250, 0.1251, 0.1252, 0.1247, 0.1251, 0.1249, 0.1249, 0.1251],
        [0.1251, 0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1250, 0.1248],
        [0.1248, 0.1250, 0.1249, 0.1254, 0.1251, 0.1251, 0.1248, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1250, 0.1248, 0.1250, 0.1249, 0.1250, 0.1252, 0.1251],
        [0.1249, 0.1248, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251],
        [0.1249, 0.1248, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1249, 0.1249, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1248, 0.1250, 0.1252, 0.1252, 0.1248, 0.1251, 0.1248],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1249],
        [0.1250, 0.1252, 0.1250, 0.1249, 0.1251, 0.1249, 0.1250, 0.1248],
        [0.1250, 0.1251, 0.1251, 0.1250, 0.1248, 0.1251, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249],
        [0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1252, 0.1249, 0.1248],
        [0.1249, 0.1251, 0.1251, 0.1251, 0.1248, 0.1250, 0.1248, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:46:13 PM | Train: [ 2/50] Step 000/001 Loss 1.767 Prec@(1,5) (62.5%, 100.0%)
07/20 09:46:16 PM | Train: [ 2/50] Step 001/001 Loss 1.830 Prec@(1,5) (55.6%, 88.9%)
07/20 09:46:17 PM | Train: [ 2/50] Final Prec@1 55.5556%
07/20 09:46:17 PM | Valid: [ 2/50] Step 000/390 Loss 2.482 Prec@(1,5) (9.4%, 46.9%)
07/20 09:46:26 PM | Valid: [ 2/50] Step 050/390 Loss 2.399 Prec@(1,5) (10.2%, 49.7%)
07/20 09:46:36 PM | Valid: [ 2/50] Step 100/390 Loss 2.397 Prec@(1,5) (10.2%, 49.7%)
07/20 09:46:45 PM | Valid: [ 2/50] Step 150/390 Loss 2.400 Prec@(1,5) (10.0%, 49.7%)
07/20 09:46:54 PM | Valid: [ 2/50] Step 200/390 Loss 2.399 Prec@(1,5) (10.1%, 49.9%)
07/20 09:47:05 PM | Valid: [ 2/50] Step 250/390 Loss 2.397 Prec@(1,5) (10.1%, 50.0%)
07/20 09:47:15 PM | Valid: [ 2/50] Step 300/390 Loss 2.400 Prec@(1,5) (9.9%, 49.6%)
07/20 09:47:25 PM | Valid: [ 2/50] Step 350/390 Loss 2.400 Prec@(1,5) (9.9%, 49.7%)
07/20 09:47:33 PM | Valid: [ 2/50] Step 390/390 Loss 2.399 Prec@(1,5) (10.0%, 49.7%)
07/20 09:47:33 PM | Valid: [ 2/50] Final Prec@1 10.0400%
07/20 09:47:33 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('dil_conv_5x5', 0)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_3x3', 3), ('max_pool_3x3', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1251, 0.1249, 0.1249, 0.1250, 0.1251, 0.1249, 0.1249],
        [0.1248, 0.1250, 0.1248, 0.1252, 0.1253, 0.1248, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1254, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1246, 0.1247, 0.1253, 0.1249, 0.1250, 0.1252, 0.1254],
        [0.1249, 0.1249, 0.1248, 0.1251, 0.1254, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1252, 0.1248, 0.1251],
        [0.1249, 0.1247, 0.1249, 0.1249, 0.1250, 0.1253, 0.1253, 0.1249],
        [0.1250, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250, 0.1250, 0.1251],
        [0.1249, 0.1249, 0.1249, 0.1250, 0.1252, 0.1252, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1247, 0.1250, 0.1252, 0.1250, 0.1249, 0.1252],
        [0.1249, 0.1250, 0.1251, 0.1247, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1249, 0.1248, 0.1251, 0.1250, 0.1252, 0.1251, 0.1249],
        [0.1248, 0.1249, 0.1249, 0.1255, 0.1251, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1250, 0.1248, 0.1251, 0.1249, 0.1250, 0.1252, 0.1251],
        [0.1250, 0.1248, 0.1251, 0.1251, 0.1249, 0.1249, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1250, 0.1249, 0.1250, 0.1248, 0.1251],
        [0.1249, 0.1248, 0.1251, 0.1252, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1250, 0.1248, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1250, 0.1252, 0.1252, 0.1248, 0.1251, 0.1248],
        [0.1250, 0.1249, 0.1251, 0.1250, 0.1252, 0.1249, 0.1250, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1249, 0.1252, 0.1249, 0.1250, 0.1248],
        [0.1251, 0.1251, 0.1251, 0.1251, 0.1248, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1248],
        [0.1252, 0.1247, 0.1251, 0.1250, 0.1249, 0.1250, 0.1251, 0.1250],
        [0.1249, 0.1250, 0.1251, 0.1249, 0.1250, 0.1249, 0.1250, 0.1253],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1252, 0.1249, 0.1249],
        [0.1249, 0.1251, 0.1251, 0.1250, 0.1248, 0.1250, 0.1248, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:47:38 PM | Train: [ 3/50] Step 000/001 Loss 1.141 Prec@(1,5) (75.0%, 100.0%)
07/20 09:47:41 PM | Train: [ 3/50] Step 001/001 Loss 1.269 Prec@(1,5) (66.7%, 100.0%)
07/20 09:47:41 PM | Train: [ 3/50] Final Prec@1 66.6667%
07/20 09:47:42 PM | Valid: [ 3/50] Step 000/390 Loss 2.600 Prec@(1,5) (14.1%, 40.6%)
07/20 09:47:51 PM | Valid: [ 3/50] Step 050/390 Loss 2.523 Prec@(1,5) (10.1%, 48.4%)
07/20 09:48:00 PM | Valid: [ 3/50] Step 100/390 Loss 2.522 Prec@(1,5) (10.2%, 48.7%)
07/20 09:48:10 PM | Valid: [ 3/50] Step 150/390 Loss 2.519 Prec@(1,5) (10.0%, 49.1%)
07/20 09:48:19 PM | Valid: [ 3/50] Step 200/390 Loss 2.518 Prec@(1,5) (10.0%, 49.5%)
07/20 09:48:29 PM | Valid: [ 3/50] Step 250/390 Loss 2.514 Prec@(1,5) (10.0%, 49.7%)
07/20 09:48:38 PM | Valid: [ 3/50] Step 300/390 Loss 2.515 Prec@(1,5) (9.8%, 49.6%)
07/20 09:48:47 PM | Valid: [ 3/50] Step 350/390 Loss 2.512 Prec@(1,5) (9.9%, 49.8%)
07/20 09:48:55 PM | Valid: [ 3/50] Step 390/390 Loss 2.512 Prec@(1,5) (10.0%, 49.9%)
07/20 09:48:55 PM | Valid: [ 3/50] Final Prec@1 10.0400%
07/20 09:48:55 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('sep_conv_5x5', 0)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('skip_connect', 2), ('skip_connect', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1250, 0.1248, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249],
        [0.1247, 0.1249, 0.1247, 0.1252, 0.1253, 0.1249, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1253, 0.1251, 0.1250, 0.1250, 0.1248, 0.1250, 0.1248],
        [0.1248, 0.1245, 0.1246, 0.1254, 0.1250, 0.1250, 0.1252, 0.1255],
        [0.1248, 0.1248, 0.1247, 0.1252, 0.1254, 0.1250, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1248, 0.1249, 0.1250, 0.1251, 0.1252, 0.1247, 0.1252],
        [0.1248, 0.1247, 0.1248, 0.1249, 0.1251, 0.1254, 0.1254, 0.1249],
        [0.1249, 0.1249, 0.1249, 0.1249, 0.1252, 0.1250, 0.1251, 0.1252],
        [0.1248, 0.1248, 0.1248, 0.1250, 0.1252, 0.1252, 0.1251, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1246, 0.1250, 0.1252, 0.1250, 0.1250, 0.1253],
        [0.1248, 0.1249, 0.1250, 0.1248, 0.1252, 0.1251, 0.1250, 0.1253],
        [0.1249, 0.1248, 0.1247, 0.1252, 0.1250, 0.1252, 0.1252, 0.1250],
        [0.1247, 0.1248, 0.1247, 0.1256, 0.1251, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1249, 0.1249, 0.1250, 0.1250, 0.1252, 0.1251, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1250, 0.1247, 0.1252, 0.1250, 0.1250, 0.1252, 0.1251],
        [0.1250, 0.1247, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1251, 0.1251, 0.1249, 0.1250, 0.1248, 0.1251],
        [0.1248, 0.1247, 0.1252, 0.1253, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1250, 0.1247, 0.1250, 0.1251, 0.1248, 0.1248, 0.1252, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1250, 0.1252, 0.1252, 0.1249, 0.1250, 0.1248],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1253, 0.1249, 0.1250, 0.1249],
        [0.1251, 0.1252, 0.1250, 0.1249, 0.1252, 0.1249, 0.1250, 0.1247],
        [0.1251, 0.1252, 0.1251, 0.1251, 0.1249, 0.1251, 0.1248, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1251, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1248],
        [0.1252, 0.1246, 0.1250, 0.1250, 0.1249, 0.1251, 0.1251, 0.1251],
        [0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1248, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1250, 0.1251, 0.1252, 0.1248, 0.1249],
        [0.1250, 0.1251, 0.1252, 0.1250, 0.1248, 0.1250, 0.1247, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:49:00 PM | Train: [ 4/50] Step 000/001 Loss 0.816 Prec@(1,5) (75.0%, 100.0%)
07/20 09:49:04 PM | Train: [ 4/50] Step 001/001 Loss 0.966 Prec@(1,5) (77.8%, 100.0%)
07/20 09:49:04 PM | Train: [ 4/50] Final Prec@1 77.7778%
07/20 09:49:04 PM | Valid: [ 4/50] Step 000/390 Loss 2.724 Prec@(1,5) (10.9%, 53.1%)
07/20 09:49:14 PM | Valid: [ 4/50] Step 050/390 Loss 2.774 Prec@(1,5) (9.9%, 49.6%)
07/20 09:49:23 PM | Valid: [ 4/50] Step 100/390 Loss 2.772 Prec@(1,5) (9.9%, 49.8%)
07/20 09:49:32 PM | Valid: [ 4/50] Step 150/390 Loss 2.767 Prec@(1,5) (10.3%, 49.9%)
07/20 09:49:42 PM | Valid: [ 4/50] Step 200/390 Loss 2.771 Prec@(1,5) (10.1%, 49.6%)
07/20 09:49:51 PM | Valid: [ 4/50] Step 250/390 Loss 2.767 Prec@(1,5) (10.3%, 49.9%)
07/20 09:50:00 PM | Valid: [ 4/50] Step 300/390 Loss 2.769 Prec@(1,5) (10.3%, 49.8%)
07/20 09:50:10 PM | Valid: [ 4/50] Step 350/390 Loss 2.770 Prec@(1,5) (10.3%, 49.8%)
07/20 09:50:17 PM | Valid: [ 4/50] Step 390/390 Loss 2.771 Prec@(1,5) (10.3%, 49.8%)
07/20 09:50:17 PM | Valid: [ 4/50] Final Prec@1 10.2920%
07/20 09:50:17 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('skip_connect', 4)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1249, 0.1248, 0.1249, 0.1252, 0.1252, 0.1251, 0.1249],
        [0.1246, 0.1247, 0.1246, 0.1253, 0.1254, 0.1250, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1252, 0.1250, 0.1250, 0.1250, 0.1248, 0.1251, 0.1249],
        [0.1247, 0.1243, 0.1245, 0.1255, 0.1251, 0.1251, 0.1253, 0.1256],
        [0.1247, 0.1247, 0.1246, 0.1252, 0.1255, 0.1250, 0.1252, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1247, 0.1248, 0.1249, 0.1252, 0.1253, 0.1248, 0.1253],
        [0.1247, 0.1246, 0.1247, 0.1249, 0.1252, 0.1255, 0.1254, 0.1250],
        [0.1248, 0.1248, 0.1248, 0.1250, 0.1252, 0.1250, 0.1252, 0.1253],
        [0.1247, 0.1247, 0.1247, 0.1250, 0.1253, 0.1253, 0.1252, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1247, 0.1245, 0.1251, 0.1253, 0.1251, 0.1251, 0.1254],
        [0.1247, 0.1248, 0.1249, 0.1248, 0.1253, 0.1252, 0.1250, 0.1254],
        [0.1248, 0.1247, 0.1246, 0.1252, 0.1251, 0.1253, 0.1252, 0.1250],
        [0.1245, 0.1246, 0.1246, 0.1257, 0.1252, 0.1253, 0.1249, 0.1251],
        [0.1247, 0.1247, 0.1248, 0.1251, 0.1250, 0.1253, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1249, 0.1246, 0.1252, 0.1251, 0.1251, 0.1251, 0.1250],
        [0.1249, 0.1246, 0.1252, 0.1251, 0.1248, 0.1250, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1249, 0.1251, 0.1251, 0.1249, 0.1251, 0.1247, 0.1251],
        [0.1248, 0.1247, 0.1252, 0.1253, 0.1251, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1247, 0.1251, 0.1250, 0.1248, 0.1248, 0.1252, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1248, 0.1250, 0.1251, 0.1252, 0.1248, 0.1250, 0.1247],
        [0.1251, 0.1249, 0.1251, 0.1250, 0.1253, 0.1248, 0.1250, 0.1248],
        [0.1251, 0.1252, 0.1250, 0.1249, 0.1253, 0.1249, 0.1250, 0.1246],
        [0.1251, 0.1251, 0.1251, 0.1252, 0.1248, 0.1250, 0.1248, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1251, 0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1247],
        [0.1251, 0.1246, 0.1249, 0.1250, 0.1250, 0.1252, 0.1252, 0.1250],
        [0.1250, 0.1250, 0.1252, 0.1248, 0.1250, 0.1247, 0.1250, 0.1253],
        [0.1250, 0.1248, 0.1250, 0.1251, 0.1251, 0.1253, 0.1249, 0.1249],
        [0.1250, 0.1251, 0.1252, 0.1249, 0.1249, 0.1249, 0.1248, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:50:22 PM | Train: [ 5/50] Step 000/001 Loss 0.299 Prec@(1,5) (100.0%, 100.0%)
07/20 09:50:26 PM | Train: [ 5/50] Step 001/001 Loss 0.505 Prec@(1,5) (88.9%, 100.0%)
07/20 09:50:26 PM | Train: [ 5/50] Final Prec@1 88.8889%
07/20 09:50:27 PM | Valid: [ 5/50] Step 000/390 Loss 3.579 Prec@(1,5) (17.2%, 57.8%)
07/20 09:50:36 PM | Valid: [ 5/50] Step 050/390 Loss 3.657 Prec@(1,5) (12.0%, 53.6%)
07/20 09:50:46 PM | Valid: [ 5/50] Step 100/390 Loss 3.645 Prec@(1,5) (12.3%, 54.1%)
07/20 09:50:55 PM | Valid: [ 5/50] Step 150/390 Loss 3.605 Prec@(1,5) (12.7%, 54.2%)
07/20 09:51:05 PM | Valid: [ 5/50] Step 200/390 Loss 3.588 Prec@(1,5) (12.8%, 54.1%)
07/20 09:51:14 PM | Valid: [ 5/50] Step 250/390 Loss 3.589 Prec@(1,5) (12.9%, 54.0%)
07/20 09:51:23 PM | Valid: [ 5/50] Step 300/390 Loss 3.590 Prec@(1,5) (12.8%, 54.2%)
07/20 09:51:33 PM | Valid: [ 5/50] Step 350/390 Loss 3.589 Prec@(1,5) (12.8%, 54.5%)
07/20 09:51:40 PM | Valid: [ 5/50] Step 390/390 Loss 3.586 Prec@(1,5) (12.9%, 54.5%)
07/20 09:51:40 PM | Valid: [ 5/50] Final Prec@1 12.8760%
07/20 09:51:40 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1249, 0.1247, 0.1249, 0.1253, 0.1251, 0.1251, 0.1250],
        [0.1245, 0.1246, 0.1245, 0.1254, 0.1255, 0.1251, 0.1251, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1248, 0.1251, 0.1250],
        [0.1246, 0.1242, 0.1244, 0.1255, 0.1252, 0.1252, 0.1254, 0.1256],
        [0.1246, 0.1246, 0.1245, 0.1252, 0.1256, 0.1250, 0.1253, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1248, 0.1246, 0.1247, 0.1249, 0.1253, 0.1254, 0.1248, 0.1254],
        [0.1246, 0.1244, 0.1246, 0.1250, 0.1252, 0.1256, 0.1255, 0.1251],
        [0.1246, 0.1246, 0.1246, 0.1250, 0.1253, 0.1251, 0.1253, 0.1254],
        [0.1246, 0.1246, 0.1246, 0.1250, 0.1254, 0.1254, 0.1253, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1246, 0.1244, 0.1252, 0.1253, 0.1252, 0.1251, 0.1255],
        [0.1246, 0.1247, 0.1247, 0.1249, 0.1253, 0.1252, 0.1251, 0.1255],
        [0.1247, 0.1246, 0.1245, 0.1253, 0.1252, 0.1254, 0.1253, 0.1251],
        [0.1244, 0.1245, 0.1245, 0.1257, 0.1253, 0.1254, 0.1250, 0.1252],
        [0.1246, 0.1246, 0.1247, 0.1252, 0.1251, 0.1253, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1249, 0.1248, 0.1245, 0.1253, 0.1252, 0.1251, 0.1251, 0.1250],
        [0.1248, 0.1245, 0.1252, 0.1251, 0.1248, 0.1250, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1252, 0.1250, 0.1248, 0.1250, 0.1246, 0.1251],
        [0.1247, 0.1246, 0.1253, 0.1253, 0.1252, 0.1250, 0.1250, 0.1250],
        [0.1250, 0.1246, 0.1251, 0.1250, 0.1248, 0.1247, 0.1252, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1248, 0.1250, 0.1252, 0.1251, 0.1248, 0.1250, 0.1247],
        [0.1250, 0.1248, 0.1252, 0.1251, 0.1254, 0.1247, 0.1251, 0.1248],
        [0.1252, 0.1252, 0.1250, 0.1248, 0.1253, 0.1250, 0.1249, 0.1246],
        [0.1251, 0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1248, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1247],
        [0.1251, 0.1246, 0.1249, 0.1249, 0.1250, 0.1252, 0.1252, 0.1250],
        [0.1251, 0.1250, 0.1253, 0.1249, 0.1248, 0.1247, 0.1250, 0.1252],
        [0.1249, 0.1247, 0.1249, 0.1252, 0.1251, 0.1253, 0.1250, 0.1249],
        [0.1249, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:51:46 PM | Train: [ 6/50] Step 000/001 Loss 0.090 Prec@(1,5) (100.0%, 100.0%)
07/20 09:51:49 PM | Train: [ 6/50] Step 001/001 Loss 0.310 Prec@(1,5) (100.0%, 100.0%)
07/20 09:51:49 PM | Train: [ 6/50] Final Prec@1 100.0000%
07/20 09:51:50 PM | Valid: [ 6/50] Step 000/390 Loss 4.499 Prec@(1,5) (21.9%, 46.9%)
07/20 09:51:59 PM | Valid: [ 6/50] Step 050/390 Loss 5.372 Prec@(1,5) (15.6%, 56.6%)
07/20 09:52:09 PM | Valid: [ 6/50] Step 100/390 Loss 5.340 Prec@(1,5) (15.4%, 57.2%)
07/20 09:52:18 PM | Valid: [ 6/50] Step 150/390 Loss 5.305 Prec@(1,5) (15.9%, 57.3%)
07/20 09:52:28 PM | Valid: [ 6/50] Step 200/390 Loss 5.296 Prec@(1,5) (15.7%, 57.3%)
07/20 09:52:37 PM | Valid: [ 6/50] Step 250/390 Loss 5.291 Prec@(1,5) (15.7%, 57.3%)
07/20 09:52:46 PM | Valid: [ 6/50] Step 300/390 Loss 5.288 Prec@(1,5) (15.7%, 57.2%)
07/20 09:52:56 PM | Valid: [ 6/50] Step 350/390 Loss 5.280 Prec@(1,5) (15.7%, 57.1%)
07/20 09:53:03 PM | Valid: [ 6/50] Step 390/390 Loss 5.266 Prec@(1,5) (15.7%, 57.3%)
07/20 09:53:03 PM | Valid: [ 6/50] Final Prec@1 15.7080%
07/20 09:53:03 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('dil_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 1), ('dil_conv_5x5', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('skip_connect', 2), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1252, 0.1249, 0.1248, 0.1248, 0.1253, 0.1250, 0.1251, 0.1250],
        [0.1244, 0.1245, 0.1244, 0.1255, 0.1255, 0.1252, 0.1251, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1250, 0.1249, 0.1251, 0.1252, 0.1248, 0.1252, 0.1250],
        [0.1244, 0.1241, 0.1242, 0.1256, 0.1253, 0.1253, 0.1254, 0.1257],
        [0.1245, 0.1245, 0.1244, 0.1253, 0.1257, 0.1251, 0.1254, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1245, 0.1246, 0.1250, 0.1254, 0.1255, 0.1249, 0.1255],
        [0.1244, 0.1243, 0.1244, 0.1251, 0.1253, 0.1257, 0.1256, 0.1252],
        [0.1245, 0.1245, 0.1245, 0.1251, 0.1254, 0.1251, 0.1254, 0.1255],
        [0.1245, 0.1245, 0.1244, 0.1250, 0.1255, 0.1255, 0.1254, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1246, 0.1245, 0.1243, 0.1253, 0.1254, 0.1252, 0.1251, 0.1256],
        [0.1245, 0.1245, 0.1246, 0.1250, 0.1253, 0.1253, 0.1252, 0.1256],
        [0.1245, 0.1244, 0.1243, 0.1254, 0.1253, 0.1254, 0.1253, 0.1252],
        [0.1243, 0.1244, 0.1244, 0.1258, 0.1254, 0.1255, 0.1251, 0.1253],
        [0.1245, 0.1245, 0.1245, 0.1253, 0.1252, 0.1254, 0.1253, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1250, 0.1248, 0.1245, 0.1253, 0.1253, 0.1251, 0.1251, 0.1250],
        [0.1247, 0.1244, 0.1253, 0.1252, 0.1248, 0.1250, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1247, 0.1253, 0.1251, 0.1248, 0.1250, 0.1246, 0.1251],
        [0.1246, 0.1245, 0.1254, 0.1252, 0.1254, 0.1250, 0.1249, 0.1250],
        [0.1249, 0.1245, 0.1252, 0.1250, 0.1249, 0.1247, 0.1253, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1248, 0.1250, 0.1252, 0.1250, 0.1249, 0.1250, 0.1247],
        [0.1249, 0.1246, 0.1251, 0.1252, 0.1255, 0.1247, 0.1252, 0.1247],
        [0.1253, 0.1251, 0.1251, 0.1247, 0.1253, 0.1251, 0.1249, 0.1246],
        [0.1250, 0.1249, 0.1252, 0.1251, 0.1249, 0.1250, 0.1249, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1253, 0.1251, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1245],
        [0.1251, 0.1245, 0.1249, 0.1249, 0.1250, 0.1253, 0.1253, 0.1250],
        [0.1252, 0.1250, 0.1254, 0.1250, 0.1248, 0.1246, 0.1250, 0.1251],
        [0.1248, 0.1246, 0.1248, 0.1253, 0.1250, 0.1254, 0.1251, 0.1249],
        [0.1249, 0.1249, 0.1253, 0.1248, 0.1250, 0.1249, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:53:08 PM | Train: [ 7/50] Step 000/001 Loss 0.231 Prec@(1,5) (87.5%, 100.0%)
07/20 09:53:12 PM | Train: [ 7/50] Step 001/001 Loss 0.469 Prec@(1,5) (77.8%, 100.0%)
07/20 09:53:12 PM | Train: [ 7/50] Final Prec@1 77.7778%
07/20 09:53:12 PM | Valid: [ 7/50] Step 000/390 Loss 8.826 Prec@(1,5) (9.4%, 50.0%)
07/20 09:53:22 PM | Valid: [ 7/50] Step 050/390 Loss 7.984 Prec@(1,5) (14.5%, 55.8%)
07/20 09:53:31 PM | Valid: [ 7/50] Step 100/390 Loss 8.002 Prec@(1,5) (15.0%, 56.3%)
07/20 09:53:40 PM | Valid: [ 7/50] Step 150/390 Loss 7.911 Prec@(1,5) (15.0%, 57.0%)
07/20 09:53:50 PM | Valid: [ 7/50] Step 200/390 Loss 7.799 Prec@(1,5) (15.2%, 57.4%)
07/20 09:53:59 PM | Valid: [ 7/50] Step 250/390 Loss 7.785 Prec@(1,5) (15.2%, 57.6%)
07/20 09:54:08 PM | Valid: [ 7/50] Step 300/390 Loss 7.786 Prec@(1,5) (15.1%, 57.8%)
07/20 09:54:18 PM | Valid: [ 7/50] Step 350/390 Loss 7.805 Prec@(1,5) (15.1%, 57.9%)
07/20 09:54:26 PM | Valid: [ 7/50] Step 390/390 Loss 7.816 Prec@(1,5) (15.1%, 57.9%)
07/20 09:54:26 PM | Valid: [ 7/50] Final Prec@1 15.0760%
07/20 09:54:26 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('sep_conv_3x3', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 1), ('sep_conv_5x5', 0)], [('skip_connect', 1), ('dil_conv_5x5', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('skip_connect', 2)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1252, 0.1248, 0.1248, 0.1248, 0.1253, 0.1249, 0.1252, 0.1250],
        [0.1242, 0.1244, 0.1243, 0.1255, 0.1256, 0.1252, 0.1252, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1247, 0.1249, 0.1247, 0.1251, 0.1253, 0.1249, 0.1252, 0.1251],
        [0.1243, 0.1240, 0.1241, 0.1256, 0.1253, 0.1253, 0.1255, 0.1258],
        [0.1244, 0.1243, 0.1242, 0.1254, 0.1258, 0.1251, 0.1255, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1243, 0.1244, 0.1251, 0.1255, 0.1256, 0.1250, 0.1256],
        [0.1243, 0.1241, 0.1243, 0.1252, 0.1254, 0.1257, 0.1257, 0.1253],
        [0.1244, 0.1243, 0.1244, 0.1252, 0.1255, 0.1252, 0.1254, 0.1256],
        [0.1243, 0.1243, 0.1243, 0.1251, 0.1256, 0.1256, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1244, 0.1241, 0.1254, 0.1254, 0.1253, 0.1253, 0.1257],
        [0.1243, 0.1244, 0.1245, 0.1251, 0.1254, 0.1254, 0.1253, 0.1257],
        [0.1244, 0.1243, 0.1242, 0.1255, 0.1254, 0.1255, 0.1254, 0.1253],
        [0.1242, 0.1243, 0.1242, 0.1258, 0.1255, 0.1256, 0.1251, 0.1254],
        [0.1243, 0.1244, 0.1244, 0.1253, 0.1253, 0.1255, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1251, 0.1248, 0.1244, 0.1253, 0.1253, 0.1251, 0.1251, 0.1248],
        [0.1246, 0.1243, 0.1253, 0.1253, 0.1249, 0.1248, 0.1253, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1247, 0.1254, 0.1252, 0.1249, 0.1249, 0.1245, 0.1250],
        [0.1245, 0.1244, 0.1255, 0.1252, 0.1254, 0.1251, 0.1248, 0.1251],
        [0.1248, 0.1244, 0.1252, 0.1249, 0.1249, 0.1247, 0.1254, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1248, 0.1251, 0.1251, 0.1249, 0.1250, 0.1249, 0.1247],
        [0.1248, 0.1245, 0.1252, 0.1253, 0.1256, 0.1246, 0.1253, 0.1247],
        [0.1253, 0.1250, 0.1250, 0.1246, 0.1253, 0.1252, 0.1249, 0.1246],
        [0.1249, 0.1248, 0.1251, 0.1252, 0.1250, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1251, 0.1250, 0.1249, 0.1248, 0.1252, 0.1251, 0.1244],
        [0.1251, 0.1244, 0.1249, 0.1250, 0.1250, 0.1253, 0.1255, 0.1249],
        [0.1252, 0.1249, 0.1254, 0.1250, 0.1248, 0.1247, 0.1250, 0.1250],
        [0.1247, 0.1245, 0.1248, 0.1255, 0.1250, 0.1255, 0.1251, 0.1249],
        [0.1248, 0.1248, 0.1253, 0.1248, 0.1251, 0.1248, 0.1250, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:54:30 PM | Train: [ 8/50] Step 000/001 Loss 0.060 Prec@(1,5) (100.0%, 100.0%)
07/20 09:54:34 PM | Train: [ 8/50] Step 001/001 Loss 0.262 Prec@(1,5) (100.0%, 100.0%)
07/20 09:54:34 PM | Train: [ 8/50] Final Prec@1 100.0000%
07/20 09:54:34 PM | Valid: [ 8/50] Step 000/390 Loss 19.906 Prec@(1,5) (15.6%, 64.1%)
07/20 09:54:44 PM | Valid: [ 8/50] Step 050/390 Loss 19.517 Prec@(1,5) (15.0%, 58.6%)
07/20 09:54:53 PM | Valid: [ 8/50] Step 100/390 Loss 19.341 Prec@(1,5) (15.5%, 57.8%)
07/20 09:55:02 PM | Valid: [ 8/50] Step 150/390 Loss 19.358 Prec@(1,5) (15.4%, 57.8%)
07/20 09:55:12 PM | Valid: [ 8/50] Step 200/390 Loss 19.259 Prec@(1,5) (15.3%, 57.9%)
07/20 09:55:21 PM | Valid: [ 8/50] Step 250/390 Loss 19.154 Prec@(1,5) (15.3%, 58.2%)
07/20 09:55:31 PM | Valid: [ 8/50] Step 300/390 Loss 19.137 Prec@(1,5) (15.4%, 58.3%)
07/20 09:55:40 PM | Valid: [ 8/50] Step 350/390 Loss 19.176 Prec@(1,5) (15.3%, 58.3%)
07/20 09:55:47 PM | Valid: [ 8/50] Step 390/390 Loss 19.153 Prec@(1,5) (15.2%, 58.3%)
07/20 09:55:48 PM | Valid: [ 8/50] Final Prec@1 15.2440%
07/20 09:55:48 PM | genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('sep_conv_3x3', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('skip_connect', 2)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1247, 0.1247, 0.1248, 0.1255, 0.1248, 0.1254, 0.1250],
        [0.1241, 0.1242, 0.1241, 0.1256, 0.1256, 0.1253, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1246, 0.1247, 0.1246, 0.1252, 0.1254, 0.1250, 0.1253, 0.1252],
        [0.1242, 0.1238, 0.1240, 0.1257, 0.1254, 0.1254, 0.1256, 0.1259],
        [0.1242, 0.1242, 0.1241, 0.1255, 0.1258, 0.1252, 0.1255, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1242, 0.1243, 0.1252, 0.1256, 0.1257, 0.1251, 0.1257],
        [0.1241, 0.1240, 0.1242, 0.1253, 0.1255, 0.1258, 0.1258, 0.1254],
        [0.1242, 0.1242, 0.1242, 0.1253, 0.1256, 0.1252, 0.1255, 0.1257],
        [0.1242, 0.1242, 0.1242, 0.1252, 0.1257, 0.1256, 0.1254, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1242, 0.1240, 0.1255, 0.1254, 0.1254, 0.1254, 0.1258],
        [0.1242, 0.1243, 0.1243, 0.1252, 0.1254, 0.1255, 0.1254, 0.1257],
        [0.1243, 0.1242, 0.1240, 0.1255, 0.1255, 0.1256, 0.1255, 0.1254],
        [0.1240, 0.1241, 0.1241, 0.1259, 0.1255, 0.1257, 0.1252, 0.1255],
        [0.1242, 0.1242, 0.1243, 0.1254, 0.1253, 0.1256, 0.1254, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1252, 0.1249, 0.1243, 0.1253, 0.1254, 0.1251, 0.1250, 0.1247],
        [0.1246, 0.1242, 0.1253, 0.1254, 0.1249, 0.1248, 0.1252, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1254, 0.1248, 0.1254, 0.1253, 0.1249, 0.1249, 0.1245, 0.1249],
        [0.1244, 0.1243, 0.1256, 0.1252, 0.1255, 0.1251, 0.1248, 0.1251],
        [0.1248, 0.1244, 0.1254, 0.1248, 0.1250, 0.1247, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1249, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1246],
        [0.1247, 0.1244, 0.1252, 0.1254, 0.1257, 0.1246, 0.1254, 0.1246],
        [0.1253, 0.1250, 0.1251, 0.1246, 0.1253, 0.1253, 0.1248, 0.1247],
        [0.1248, 0.1247, 0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1252, 0.1250, 0.1249, 0.1248, 0.1252, 0.1251, 0.1243],
        [0.1250, 0.1244, 0.1250, 0.1249, 0.1249, 0.1254, 0.1256, 0.1249],
        [0.1252, 0.1249, 0.1255, 0.1250, 0.1247, 0.1247, 0.1250, 0.1250],
        [0.1246, 0.1245, 0.1248, 0.1256, 0.1251, 0.1255, 0.1251, 0.1249],
        [0.1247, 0.1248, 0.1254, 0.1248, 0.1252, 0.1247, 0.1250, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:55:52 PM | Train: [ 9/50] Step 000/001 Loss 0.014 Prec@(1,5) (100.0%, 100.0%)
07/20 09:55:55 PM | Train: [ 9/50] Step 001/001 Loss 0.273 Prec@(1,5) (88.9%, 100.0%)
07/20 09:55:56 PM | Train: [ 9/50] Final Prec@1 88.8889%
07/20 09:55:56 PM | Valid: [ 9/50] Step 000/390 Loss 13.955 Prec@(1,5) (15.6%, 51.6%)
07/20 09:56:06 PM | Valid: [ 9/50] Step 050/390 Loss 13.418 Prec@(1,5) (16.6%, 59.1%)
07/20 09:56:15 PM | Valid: [ 9/50] Step 100/390 Loss 13.439 Prec@(1,5) (16.1%, 59.1%)
07/20 09:56:24 PM | Valid: [ 9/50] Step 150/390 Loss 13.451 Prec@(1,5) (16.1%, 59.1%)
07/20 09:56:34 PM | Valid: [ 9/50] Step 200/390 Loss 13.469 Prec@(1,5) (16.3%, 59.6%)
07/20 09:56:43 PM | Valid: [ 9/50] Step 250/390 Loss 13.546 Prec@(1,5) (16.1%, 59.7%)
07/20 09:56:53 PM | Valid: [ 9/50] Step 300/390 Loss 13.481 Prec@(1,5) (16.2%, 59.9%)
07/20 09:57:03 PM | Valid: [ 9/50] Step 350/390 Loss 13.460 Prec@(1,5) (16.1%, 59.9%)
07/20 09:57:10 PM | Valid: [ 9/50] Step 390/390 Loss 13.424 Prec@(1,5) (16.2%, 60.0%)
07/20 09:57:11 PM | Valid: [ 9/50] Final Prec@1 16.2240%
07/20 09:57:11 PM | genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('sep_conv_3x3', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('max_pool_3x3', 0)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1246, 0.1247, 0.1248, 0.1256, 0.1247, 0.1255, 0.1250],
        [0.1240, 0.1241, 0.1240, 0.1257, 0.1256, 0.1254, 0.1254, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1245, 0.1246, 0.1245, 0.1253, 0.1255, 0.1250, 0.1254, 0.1253],
        [0.1241, 0.1237, 0.1239, 0.1257, 0.1255, 0.1255, 0.1256, 0.1260],
        [0.1241, 0.1241, 0.1240, 0.1256, 0.1259, 0.1253, 0.1256, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1241, 0.1241, 0.1253, 0.1256, 0.1257, 0.1251, 0.1258],
        [0.1240, 0.1238, 0.1240, 0.1253, 0.1256, 0.1259, 0.1259, 0.1255],
        [0.1241, 0.1241, 0.1241, 0.1253, 0.1257, 0.1253, 0.1256, 0.1258],
        [0.1241, 0.1241, 0.1240, 0.1252, 0.1257, 0.1258, 0.1255, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1241, 0.1239, 0.1256, 0.1254, 0.1254, 0.1255, 0.1259],
        [0.1240, 0.1241, 0.1242, 0.1253, 0.1254, 0.1256, 0.1255, 0.1258],
        [0.1241, 0.1240, 0.1239, 0.1256, 0.1256, 0.1257, 0.1256, 0.1255],
        [0.1239, 0.1240, 0.1239, 0.1260, 0.1256, 0.1257, 0.1253, 0.1256],
        [0.1241, 0.1241, 0.1241, 0.1255, 0.1254, 0.1257, 0.1255, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1253, 0.1250, 0.1242, 0.1253, 0.1253, 0.1251, 0.1250, 0.1246],
        [0.1244, 0.1241, 0.1254, 0.1254, 0.1250, 0.1249, 0.1252, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1255, 0.1248, 0.1254, 0.1254, 0.1248, 0.1248, 0.1244, 0.1248],
        [0.1243, 0.1241, 0.1257, 0.1252, 0.1256, 0.1252, 0.1248, 0.1252],
        [0.1248, 0.1244, 0.1255, 0.1247, 0.1249, 0.1248, 0.1252, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1249, 0.1251, 0.1249, 0.1249, 0.1251, 0.1249, 0.1246],
        [0.1246, 0.1243, 0.1252, 0.1254, 0.1258, 0.1246, 0.1254, 0.1246],
        [0.1253, 0.1249, 0.1252, 0.1245, 0.1253, 0.1254, 0.1247, 0.1247],
        [0.1247, 0.1246, 0.1249, 0.1252, 0.1252, 0.1251, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1253, 0.1249, 0.1249, 0.1249, 0.1252, 0.1250, 0.1243],
        [0.1249, 0.1242, 0.1249, 0.1250, 0.1249, 0.1255, 0.1257, 0.1250],
        [0.1252, 0.1249, 0.1255, 0.1251, 0.1246, 0.1248, 0.1250, 0.1249],
        [0.1246, 0.1244, 0.1247, 0.1257, 0.1251, 0.1256, 0.1250, 0.1250],
        [0.1246, 0.1247, 0.1254, 0.1249, 0.1253, 0.1246, 0.1250, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:57:16 PM | Train: [10/50] Step 000/001 Loss 0.016 Prec@(1,5) (100.0%, 100.0%)
07/20 09:57:19 PM | Train: [10/50] Step 001/001 Loss 0.284 Prec@(1,5) (88.9%, 100.0%)
07/20 09:57:19 PM | Train: [10/50] Final Prec@1 88.8889%
07/20 09:57:20 PM | Valid: [10/50] Step 000/390 Loss 15.148 Prec@(1,5) (18.8%, 64.1%)
07/20 09:57:29 PM | Valid: [10/50] Step 050/390 Loss 15.317 Prec@(1,5) (16.1%, 58.3%)
07/20 09:57:38 PM | Valid: [10/50] Step 100/390 Loss 15.136 Prec@(1,5) (16.7%, 59.8%)
07/20 09:57:48 PM | Valid: [10/50] Step 150/390 Loss 15.163 Prec@(1,5) (16.6%, 59.9%)
07/20 09:57:57 PM | Valid: [10/50] Step 200/390 Loss 15.114 Prec@(1,5) (16.6%, 60.0%)
07/20 09:58:06 PM | Valid: [10/50] Step 250/390 Loss 15.157 Prec@(1,5) (16.2%, 60.3%)
07/20 09:58:16 PM | Valid: [10/50] Step 300/390 Loss 15.143 Prec@(1,5) (16.3%, 60.3%)
07/20 09:58:25 PM | Valid: [10/50] Step 350/390 Loss 15.184 Prec@(1,5) (16.2%, 60.1%)
07/20 09:58:33 PM | Valid: [10/50] Step 390/390 Loss 15.220 Prec@(1,5) (16.1%, 60.1%)
07/20 09:58:33 PM | Valid: [10/50] Final Prec@1 16.1280%
07/20 09:58:33 PM | genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1245, 0.1246, 0.1249, 0.1256, 0.1246, 0.1256, 0.1249],
        [0.1238, 0.1240, 0.1238, 0.1258, 0.1257, 0.1255, 0.1255, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1244, 0.1245, 0.1244, 0.1253, 0.1256, 0.1251, 0.1254, 0.1253],
        [0.1240, 0.1236, 0.1237, 0.1257, 0.1256, 0.1256, 0.1257, 0.1261],
        [0.1240, 0.1239, 0.1238, 0.1256, 0.1260, 0.1253, 0.1257, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1239, 0.1240, 0.1254, 0.1257, 0.1257, 0.1252, 0.1259],
        [0.1238, 0.1237, 0.1239, 0.1254, 0.1257, 0.1260, 0.1260, 0.1256],
        [0.1240, 0.1240, 0.1240, 0.1254, 0.1257, 0.1254, 0.1257, 0.1259],
        [0.1239, 0.1239, 0.1239, 0.1253, 0.1258, 0.1258, 0.1256, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1240, 0.1238, 0.1256, 0.1254, 0.1254, 0.1256, 0.1260],
        [0.1239, 0.1240, 0.1240, 0.1254, 0.1255, 0.1257, 0.1256, 0.1259],
        [0.1240, 0.1239, 0.1238, 0.1256, 0.1257, 0.1258, 0.1257, 0.1256],
        [0.1238, 0.1239, 0.1238, 0.1260, 0.1257, 0.1258, 0.1254, 0.1256],
        [0.1240, 0.1240, 0.1240, 0.1256, 0.1255, 0.1257, 0.1256, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1254, 0.1251, 0.1242, 0.1253, 0.1253, 0.1251, 0.1250, 0.1246],
        [0.1244, 0.1240, 0.1253, 0.1254, 0.1250, 0.1249, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1256, 0.1247, 0.1255, 0.1256, 0.1247, 0.1248, 0.1244, 0.1247],
        [0.1242, 0.1241, 0.1257, 0.1252, 0.1256, 0.1253, 0.1247, 0.1252],
        [0.1249, 0.1243, 0.1255, 0.1247, 0.1249, 0.1248, 0.1251, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1249, 0.1251, 0.1248, 0.1249, 0.1251, 0.1248, 0.1246],
        [0.1246, 0.1243, 0.1252, 0.1255, 0.1258, 0.1246, 0.1254, 0.1246],
        [0.1253, 0.1248, 0.1252, 0.1244, 0.1253, 0.1255, 0.1246, 0.1247],
        [0.1246, 0.1245, 0.1249, 0.1252, 0.1253, 0.1252, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1253, 0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1242],
        [0.1248, 0.1241, 0.1249, 0.1250, 0.1249, 0.1255, 0.1258, 0.1250],
        [0.1251, 0.1248, 0.1254, 0.1252, 0.1247, 0.1249, 0.1250, 0.1248],
        [0.1245, 0.1243, 0.1247, 0.1258, 0.1250, 0.1256, 0.1251, 0.1250],
        [0.1245, 0.1245, 0.1253, 0.1250, 0.1254, 0.1245, 0.1251, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 09:58:38 PM | Train: [11/50] Step 000/001 Loss 0.007 Prec@(1,5) (100.0%, 100.0%)
07/20 09:58:41 PM | Train: [11/50] Step 001/001 Loss 0.284 Prec@(1,5) (88.9%, 88.9%)
07/20 09:58:41 PM | Train: [11/50] Final Prec@1 88.8889%
07/20 09:58:42 PM | Valid: [11/50] Step 000/390 Loss 16.866 Prec@(1,5) (17.2%, 68.8%)
07/20 09:58:51 PM | Valid: [11/50] Step 050/390 Loss 16.875 Prec@(1,5) (16.7%, 62.1%)
07/20 09:59:01 PM | Valid: [11/50] Step 100/390 Loss 16.884 Prec@(1,5) (16.1%, 62.0%)
07/20 09:59:10 PM | Valid: [11/50] Step 150/390 Loss 16.894 Prec@(1,5) (15.7%, 62.0%)
07/20 09:59:19 PM | Valid: [11/50] Step 200/390 Loss 16.690 Prec@(1,5) (16.1%, 62.1%)
07/20 09:59:29 PM | Valid: [11/50] Step 250/390 Loss 16.626 Prec@(1,5) (16.1%, 61.9%)
07/20 09:59:38 PM | Valid: [11/50] Step 300/390 Loss 16.624 Prec@(1,5) (15.9%, 61.8%)
07/20 09:59:47 PM | Valid: [11/50] Step 350/390 Loss 16.580 Prec@(1,5) (16.0%, 61.9%)
07/20 09:59:55 PM | Valid: [11/50] Step 390/390 Loss 16.610 Prec@(1,5) (15.9%, 61.8%)
07/20 09:59:55 PM | Valid: [11/50] Final Prec@1 15.9120%
07/20 09:59:55 PM | genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1251, 0.1244, 0.1245, 0.1250, 0.1257, 0.1246, 0.1257, 0.1250],
        [0.1237, 0.1238, 0.1237, 0.1258, 0.1257, 0.1256, 0.1256, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1243, 0.1244, 0.1242, 0.1254, 0.1257, 0.1252, 0.1254, 0.1254],
        [0.1238, 0.1235, 0.1236, 0.1257, 0.1257, 0.1257, 0.1258, 0.1262],
        [0.1238, 0.1238, 0.1237, 0.1257, 0.1261, 0.1254, 0.1258, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1241, 0.1238, 0.1239, 0.1254, 0.1258, 0.1258, 0.1252, 0.1260],
        [0.1237, 0.1236, 0.1237, 0.1255, 0.1257, 0.1261, 0.1260, 0.1257],
        [0.1239, 0.1238, 0.1239, 0.1254, 0.1258, 0.1254, 0.1258, 0.1260],
        [0.1238, 0.1238, 0.1237, 0.1253, 0.1259, 0.1259, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1240, 0.1239, 0.1236, 0.1257, 0.1255, 0.1255, 0.1257, 0.1260],
        [0.1238, 0.1238, 0.1239, 0.1254, 0.1256, 0.1258, 0.1256, 0.1260],
        [0.1239, 0.1238, 0.1236, 0.1256, 0.1257, 0.1259, 0.1258, 0.1257],
        [0.1236, 0.1237, 0.1237, 0.1261, 0.1258, 0.1259, 0.1255, 0.1257],
        [0.1238, 0.1238, 0.1238, 0.1256, 0.1256, 0.1258, 0.1257, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1255, 0.1251, 0.1242, 0.1253, 0.1253, 0.1250, 0.1250, 0.1246],
        [0.1243, 0.1239, 0.1254, 0.1255, 0.1250, 0.1249, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1247, 0.1255, 0.1257, 0.1247, 0.1247, 0.1245, 0.1246],
        [0.1241, 0.1239, 0.1258, 0.1253, 0.1256, 0.1254, 0.1246, 0.1253],
        [0.1249, 0.1242, 0.1256, 0.1246, 0.1248, 0.1249, 0.1251, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1249, 0.1252, 0.1249, 0.1248, 0.1251, 0.1247, 0.1245],
        [0.1245, 0.1242, 0.1253, 0.1255, 0.1259, 0.1246, 0.1254, 0.1246],
        [0.1254, 0.1248, 0.1253, 0.1243, 0.1254, 0.1256, 0.1245, 0.1247],
        [0.1246, 0.1244, 0.1249, 0.1251, 0.1254, 0.1252, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1253, 0.1248, 0.1248, 0.1249, 0.1251, 0.1251, 0.1241],
        [0.1246, 0.1240, 0.1248, 0.1250, 0.1250, 0.1256, 0.1259, 0.1251],
        [0.1251, 0.1247, 0.1254, 0.1253, 0.1247, 0.1250, 0.1251, 0.1247],
        [0.1244, 0.1242, 0.1246, 0.1259, 0.1249, 0.1258, 0.1251, 0.1251],
        [0.1244, 0.1244, 0.1252, 0.1251, 0.1255, 0.1245, 0.1252, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:00:00 PM | Train: [12/50] Step 000/001 Loss 0.008 Prec@(1,5) (100.0%, 100.0%)
07/20 10:00:03 PM | Train: [12/50] Step 001/001 Loss 0.283 Prec@(1,5) (88.9%, 88.9%)
07/20 10:00:03 PM | Train: [12/50] Final Prec@1 88.8889%
07/20 10:00:04 PM | Valid: [12/50] Step 000/390 Loss 18.811 Prec@(1,5) (7.8%, 45.3%)
07/20 10:00:13 PM | Valid: [12/50] Step 050/390 Loss 18.417 Prec@(1,5) (15.9%, 62.7%)
07/20 10:00:23 PM | Valid: [12/50] Step 100/390 Loss 18.475 Prec@(1,5) (16.0%, 61.8%)
07/20 10:00:32 PM | Valid: [12/50] Step 150/390 Loss 18.516 Prec@(1,5) (15.8%, 61.3%)
07/20 10:00:41 PM | Valid: [12/50] Step 200/390 Loss 18.592 Prec@(1,5) (15.7%, 60.9%)
07/20 10:00:51 PM | Valid: [12/50] Step 250/390 Loss 18.573 Prec@(1,5) (15.8%, 60.7%)
07/20 10:01:00 PM | Valid: [12/50] Step 300/390 Loss 18.505 Prec@(1,5) (15.8%, 60.8%)
07/20 10:01:09 PM | Valid: [12/50] Step 350/390 Loss 18.476 Prec@(1,5) (15.9%, 60.8%)
07/20 10:01:17 PM | Valid: [12/50] Step 390/390 Loss 18.494 Prec@(1,5) (15.8%, 60.8%)
07/20 10:01:17 PM | Valid: [12/50] Final Prec@1 15.8440%
07/20 10:01:17 PM | genotype = Genotype(normal=[[('sep_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('sep_conv_3x3', 0)], [('sep_conv_5x5', 1), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1250, 0.1242, 0.1244, 0.1251, 0.1258, 0.1246, 0.1258, 0.1251],
        [0.1236, 0.1237, 0.1236, 0.1259, 0.1258, 0.1256, 0.1256, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1242, 0.1243, 0.1241, 0.1255, 0.1257, 0.1253, 0.1254, 0.1255],
        [0.1237, 0.1233, 0.1235, 0.1258, 0.1257, 0.1257, 0.1259, 0.1263],
        [0.1237, 0.1237, 0.1236, 0.1257, 0.1261, 0.1255, 0.1258, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1237, 0.1238, 0.1255, 0.1259, 0.1259, 0.1253, 0.1261],
        [0.1235, 0.1234, 0.1236, 0.1256, 0.1258, 0.1262, 0.1261, 0.1258],
        [0.1237, 0.1237, 0.1237, 0.1255, 0.1259, 0.1255, 0.1259, 0.1261],
        [0.1237, 0.1237, 0.1236, 0.1254, 0.1260, 0.1261, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1237, 0.1235, 0.1258, 0.1256, 0.1256, 0.1258, 0.1261],
        [0.1237, 0.1237, 0.1238, 0.1255, 0.1257, 0.1259, 0.1257, 0.1261],
        [0.1237, 0.1236, 0.1235, 0.1257, 0.1258, 0.1260, 0.1259, 0.1257],
        [0.1235, 0.1236, 0.1235, 0.1262, 0.1258, 0.1260, 0.1255, 0.1258],
        [0.1237, 0.1237, 0.1237, 0.1257, 0.1257, 0.1259, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1255, 0.1251, 0.1243, 0.1254, 0.1253, 0.1250, 0.1249, 0.1245],
        [0.1242, 0.1238, 0.1254, 0.1254, 0.1250, 0.1250, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1257, 0.1246, 0.1256, 0.1259, 0.1246, 0.1246, 0.1245, 0.1245],
        [0.1241, 0.1238, 0.1258, 0.1253, 0.1257, 0.1255, 0.1246, 0.1253],
        [0.1250, 0.1242, 0.1257, 0.1246, 0.1248, 0.1249, 0.1250, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1249, 0.1251, 0.1249, 0.1248, 0.1252, 0.1246, 0.1245],
        [0.1245, 0.1241, 0.1253, 0.1255, 0.1259, 0.1246, 0.1255, 0.1246],
        [0.1255, 0.1247, 0.1253, 0.1243, 0.1254, 0.1257, 0.1244, 0.1247],
        [0.1245, 0.1243, 0.1249, 0.1251, 0.1254, 0.1251, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1253, 0.1247, 0.1248, 0.1250, 0.1251, 0.1251, 0.1240],
        [0.1245, 0.1238, 0.1249, 0.1251, 0.1250, 0.1257, 0.1260, 0.1251],
        [0.1251, 0.1247, 0.1254, 0.1253, 0.1246, 0.1250, 0.1251, 0.1247],
        [0.1243, 0.1241, 0.1245, 0.1260, 0.1249, 0.1258, 0.1252, 0.1252],
        [0.1243, 0.1243, 0.1251, 0.1252, 0.1256, 0.1245, 0.1252, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:01:22 PM | Train: [13/50] Step 000/001 Loss 0.018 Prec@(1,5) (100.0%, 100.0%)
07/20 10:01:25 PM | Train: [13/50] Step 001/001 Loss 0.263 Prec@(1,5) (88.9%, 100.0%)
07/20 10:01:25 PM | Train: [13/50] Final Prec@1 88.8889%
07/20 10:01:26 PM | Valid: [13/50] Step 000/390 Loss 8.822 Prec@(1,5) (23.4%, 70.3%)
07/20 10:01:35 PM | Valid: [13/50] Step 050/390 Loss 9.671 Prec@(1,5) (18.7%, 62.7%)
07/20 10:01:45 PM | Valid: [13/50] Step 100/390 Loss 10.029 Prec@(1,5) (17.6%, 61.7%)
07/20 10:01:54 PM | Valid: [13/50] Step 150/390 Loss 10.073 Prec@(1,5) (17.4%, 61.8%)
07/20 10:02:04 PM | Valid: [13/50] Step 200/390 Loss 10.055 Prec@(1,5) (17.7%, 62.0%)
07/20 10:02:13 PM | Valid: [13/50] Step 250/390 Loss 10.088 Prec@(1,5) (17.8%, 62.3%)
07/20 10:02:22 PM | Valid: [13/50] Step 300/390 Loss 10.072 Prec@(1,5) (17.9%, 61.9%)
07/20 10:02:32 PM | Valid: [13/50] Step 350/390 Loss 10.021 Prec@(1,5) (18.1%, 62.2%)
07/20 10:02:40 PM | Valid: [13/50] Step 390/390 Loss 10.035 Prec@(1,5) (17.9%, 62.0%)
07/20 10:02:40 PM | Valid: [13/50] Final Prec@1 17.9400%
07/20 10:02:40 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1241, 0.1243, 0.1252, 0.1258, 0.1245, 0.1259, 0.1252],
        [0.1235, 0.1236, 0.1235, 0.1259, 0.1259, 0.1257, 0.1257, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1240, 0.1241, 0.1240, 0.1256, 0.1258, 0.1253, 0.1255, 0.1256],
        [0.1236, 0.1232, 0.1234, 0.1258, 0.1258, 0.1258, 0.1260, 0.1264],
        [0.1236, 0.1235, 0.1235, 0.1258, 0.1262, 0.1256, 0.1259, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1238, 0.1235, 0.1236, 0.1255, 0.1260, 0.1260, 0.1253, 0.1262],
        [0.1234, 0.1233, 0.1235, 0.1256, 0.1259, 0.1263, 0.1261, 0.1259],
        [0.1236, 0.1235, 0.1236, 0.1256, 0.1260, 0.1256, 0.1260, 0.1262],
        [0.1235, 0.1235, 0.1235, 0.1255, 0.1261, 0.1262, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1237, 0.1236, 0.1234, 0.1259, 0.1257, 0.1256, 0.1259, 0.1262],
        [0.1235, 0.1236, 0.1237, 0.1256, 0.1258, 0.1259, 0.1257, 0.1262],
        [0.1236, 0.1235, 0.1233, 0.1258, 0.1259, 0.1261, 0.1260, 0.1258],
        [0.1233, 0.1234, 0.1234, 0.1263, 0.1259, 0.1261, 0.1256, 0.1259],
        [0.1235, 0.1235, 0.1236, 0.1258, 0.1257, 0.1260, 0.1259, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1257, 0.1251, 0.1244, 0.1253, 0.1252, 0.1249, 0.1249, 0.1245],
        [0.1241, 0.1237, 0.1254, 0.1254, 0.1252, 0.1251, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1246, 0.1256, 0.1260, 0.1246, 0.1246, 0.1245, 0.1244],
        [0.1240, 0.1237, 0.1258, 0.1254, 0.1257, 0.1255, 0.1246, 0.1254],
        [0.1249, 0.1241, 0.1257, 0.1245, 0.1249, 0.1249, 0.1250, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1249, 0.1251, 0.1248, 0.1248, 0.1253, 0.1246, 0.1244],
        [0.1244, 0.1240, 0.1252, 0.1256, 0.1259, 0.1246, 0.1256, 0.1247],
        [0.1256, 0.1246, 0.1254, 0.1242, 0.1255, 0.1258, 0.1243, 0.1247],
        [0.1246, 0.1243, 0.1250, 0.1250, 0.1255, 0.1250, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1253, 0.1247, 0.1249, 0.1251, 0.1250, 0.1251, 0.1239],
        [0.1245, 0.1237, 0.1248, 0.1251, 0.1251, 0.1257, 0.1260, 0.1251],
        [0.1251, 0.1246, 0.1254, 0.1254, 0.1245, 0.1251, 0.1252, 0.1247],
        [0.1242, 0.1240, 0.1244, 0.1260, 0.1250, 0.1259, 0.1253, 0.1253],
        [0.1242, 0.1242, 0.1250, 0.1252, 0.1257, 0.1245, 0.1253, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:02:45 PM | Train: [14/50] Step 000/001 Loss 0.006 Prec@(1,5) (100.0%, 100.0%)
07/20 10:02:48 PM | Train: [14/50] Step 001/001 Loss 0.293 Prec@(1,5) (88.9%, 88.9%)
07/20 10:02:48 PM | Train: [14/50] Final Prec@1 88.8889%
07/20 10:02:48 PM | Valid: [14/50] Step 000/390 Loss 9.979 Prec@(1,5) (20.3%, 64.1%)
07/20 10:02:58 PM | Valid: [14/50] Step 050/390 Loss 10.110 Prec@(1,5) (17.4%, 58.8%)
07/20 10:03:07 PM | Valid: [14/50] Step 100/390 Loss 9.996 Prec@(1,5) (17.7%, 58.8%)
07/20 10:03:16 PM | Valid: [14/50] Step 150/390 Loss 9.995 Prec@(1,5) (17.2%, 58.1%)
07/20 10:03:25 PM | Valid: [14/50] Step 200/390 Loss 10.015 Prec@(1,5) (17.2%, 58.2%)
07/20 10:03:35 PM | Valid: [14/50] Step 250/390 Loss 9.975 Prec@(1,5) (17.2%, 58.5%)
07/20 10:03:44 PM | Valid: [14/50] Step 300/390 Loss 9.968 Prec@(1,5) (17.3%, 58.5%)
07/20 10:03:54 PM | Valid: [14/50] Step 350/390 Loss 9.994 Prec@(1,5) (17.1%, 58.4%)
07/20 10:04:01 PM | Valid: [14/50] Step 390/390 Loss 9.972 Prec@(1,5) (17.1%, 58.5%)
07/20 10:04:01 PM | Valid: [14/50] Final Prec@1 17.1000%
07/20 10:04:01 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1248, 0.1240, 0.1241, 0.1253, 0.1259, 0.1245, 0.1260, 0.1253],
        [0.1235, 0.1235, 0.1234, 0.1259, 0.1260, 0.1258, 0.1257, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1239, 0.1240, 0.1239, 0.1257, 0.1259, 0.1254, 0.1256, 0.1257],
        [0.1235, 0.1231, 0.1233, 0.1259, 0.1259, 0.1259, 0.1261, 0.1264],
        [0.1235, 0.1234, 0.1233, 0.1259, 0.1263, 0.1257, 0.1260, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1237, 0.1234, 0.1235, 0.1255, 0.1261, 0.1261, 0.1254, 0.1263],
        [0.1233, 0.1232, 0.1233, 0.1257, 0.1260, 0.1264, 0.1262, 0.1260],
        [0.1234, 0.1234, 0.1234, 0.1257, 0.1261, 0.1257, 0.1261, 0.1263],
        [0.1234, 0.1234, 0.1233, 0.1255, 0.1262, 0.1262, 0.1260, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1234, 0.1232, 0.1260, 0.1257, 0.1257, 0.1259, 0.1263],
        [0.1234, 0.1235, 0.1235, 0.1256, 0.1259, 0.1260, 0.1258, 0.1263],
        [0.1235, 0.1233, 0.1232, 0.1259, 0.1259, 0.1261, 0.1261, 0.1259],
        [0.1232, 0.1233, 0.1233, 0.1264, 0.1260, 0.1262, 0.1257, 0.1260],
        [0.1234, 0.1234, 0.1234, 0.1259, 0.1258, 0.1260, 0.1260, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1257, 0.1251, 0.1244, 0.1253, 0.1252, 0.1249, 0.1248, 0.1245],
        [0.1241, 0.1236, 0.1253, 0.1254, 0.1252, 0.1252, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1258, 0.1245, 0.1256, 0.1261, 0.1246, 0.1247, 0.1244, 0.1243],
        [0.1239, 0.1236, 0.1259, 0.1254, 0.1258, 0.1256, 0.1245, 0.1254],
        [0.1249, 0.1239, 0.1258, 0.1244, 0.1249, 0.1250, 0.1249, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1248, 0.1252, 0.1248, 0.1248, 0.1254, 0.1246, 0.1243],
        [0.1244, 0.1240, 0.1253, 0.1256, 0.1260, 0.1245, 0.1257, 0.1246],
        [0.1256, 0.1245, 0.1255, 0.1241, 0.1256, 0.1258, 0.1242, 0.1247],
        [0.1245, 0.1242, 0.1250, 0.1249, 0.1255, 0.1250, 0.1254, 0.1255]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1252, 0.1248, 0.1250, 0.1251, 0.1250, 0.1251, 0.1238],
        [0.1244, 0.1236, 0.1248, 0.1251, 0.1251, 0.1257, 0.1260, 0.1251],
        [0.1250, 0.1245, 0.1254, 0.1255, 0.1244, 0.1252, 0.1252, 0.1248],
        [0.1241, 0.1238, 0.1242, 0.1261, 0.1251, 0.1260, 0.1254, 0.1253],
        [0.1240, 0.1241, 0.1249, 0.1253, 0.1258, 0.1245, 0.1254, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:04:07 PM | Train: [15/50] Step 000/001 Loss 0.011 Prec@(1,5) (100.0%, 100.0%)
07/20 10:04:10 PM | Train: [15/50] Step 001/001 Loss 0.295 Prec@(1,5) (88.9%, 88.9%)
07/20 10:04:10 PM | Train: [15/50] Final Prec@1 88.8889%
07/20 10:04:11 PM | Valid: [15/50] Step 000/390 Loss 11.223 Prec@(1,5) (9.4%, 56.2%)
07/20 10:04:20 PM | Valid: [15/50] Step 050/390 Loss 11.810 Prec@(1,5) (16.9%, 56.8%)
07/20 10:04:29 PM | Valid: [15/50] Step 100/390 Loss 11.834 Prec@(1,5) (16.6%, 56.6%)
07/20 10:04:39 PM | Valid: [15/50] Step 150/390 Loss 11.836 Prec@(1,5) (16.4%, 56.8%)
07/20 10:04:49 PM | Valid: [15/50] Step 200/390 Loss 11.868 Prec@(1,5) (16.1%, 56.8%)
07/20 10:04:58 PM | Valid: [15/50] Step 250/390 Loss 11.929 Prec@(1,5) (16.2%, 56.4%)
07/20 10:05:08 PM | Valid: [15/50] Step 300/390 Loss 11.874 Prec@(1,5) (16.2%, 56.6%)
07/20 10:05:17 PM | Valid: [15/50] Step 350/390 Loss 11.857 Prec@(1,5) (16.2%, 56.6%)
07/20 10:05:25 PM | Valid: [15/50] Step 390/390 Loss 11.875 Prec@(1,5) (16.2%, 56.5%)
07/20 10:05:25 PM | Valid: [15/50] Final Prec@1 16.2400%
07/20 10:05:25 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1247, 0.1238, 0.1240, 0.1254, 0.1260, 0.1245, 0.1261, 0.1254],
        [0.1234, 0.1234, 0.1233, 0.1259, 0.1260, 0.1259, 0.1258, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1238, 0.1239, 0.1237, 0.1258, 0.1259, 0.1255, 0.1257, 0.1257],
        [0.1234, 0.1230, 0.1232, 0.1259, 0.1259, 0.1259, 0.1262, 0.1265],
        [0.1234, 0.1233, 0.1232, 0.1260, 0.1263, 0.1257, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1233, 0.1234, 0.1256, 0.1262, 0.1262, 0.1255, 0.1264],
        [0.1232, 0.1230, 0.1232, 0.1258, 0.1260, 0.1265, 0.1262, 0.1261],
        [0.1233, 0.1233, 0.1233, 0.1257, 0.1261, 0.1258, 0.1261, 0.1263],
        [0.1233, 0.1233, 0.1232, 0.1255, 0.1262, 0.1263, 0.1260, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1235, 0.1233, 0.1231, 0.1261, 0.1258, 0.1258, 0.1260, 0.1264],
        [0.1233, 0.1233, 0.1234, 0.1256, 0.1260, 0.1261, 0.1259, 0.1263],
        [0.1233, 0.1232, 0.1231, 0.1260, 0.1260, 0.1262, 0.1262, 0.1260],
        [0.1231, 0.1232, 0.1231, 0.1265, 0.1261, 0.1262, 0.1258, 0.1261],
        [0.1233, 0.1233, 0.1233, 0.1260, 0.1259, 0.1261, 0.1261, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1258, 0.1251, 0.1245, 0.1254, 0.1252, 0.1249, 0.1248, 0.1245],
        [0.1240, 0.1235, 0.1254, 0.1255, 0.1253, 0.1253, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1244, 0.1257, 0.1262, 0.1246, 0.1247, 0.1243, 0.1243],
        [0.1238, 0.1235, 0.1259, 0.1254, 0.1259, 0.1256, 0.1244, 0.1254],
        [0.1250, 0.1239, 0.1259, 0.1243, 0.1249, 0.1251, 0.1248, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1247, 0.1253, 0.1248, 0.1249, 0.1255, 0.1245, 0.1243],
        [0.1243, 0.1238, 0.1253, 0.1256, 0.1260, 0.1245, 0.1258, 0.1246],
        [0.1257, 0.1244, 0.1255, 0.1240, 0.1256, 0.1259, 0.1241, 0.1247],
        [0.1245, 0.1241, 0.1250, 0.1249, 0.1256, 0.1249, 0.1255, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1251, 0.1248, 0.1250, 0.1252, 0.1250, 0.1252, 0.1238],
        [0.1243, 0.1235, 0.1248, 0.1251, 0.1252, 0.1257, 0.1261, 0.1252],
        [0.1249, 0.1244, 0.1253, 0.1256, 0.1244, 0.1253, 0.1253, 0.1247],
        [0.1240, 0.1237, 0.1241, 0.1262, 0.1251, 0.1260, 0.1255, 0.1254],
        [0.1239, 0.1239, 0.1247, 0.1254, 0.1259, 0.1245, 0.1255, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:05:30 PM | Train: [16/50] Step 000/001 Loss 0.019 Prec@(1,5) (100.0%, 100.0%)
07/20 10:05:33 PM | Train: [16/50] Step 001/001 Loss 0.297 Prec@(1,5) (88.9%, 88.9%)
07/20 10:05:33 PM | Train: [16/50] Final Prec@1 88.8889%
07/20 10:05:34 PM | Valid: [16/50] Step 000/390 Loss 8.345 Prec@(1,5) (17.2%, 57.8%)
07/20 10:05:43 PM | Valid: [16/50] Step 050/390 Loss 7.596 Prec@(1,5) (19.6%, 61.3%)
07/20 10:05:53 PM | Valid: [16/50] Step 100/390 Loss 7.630 Prec@(1,5) (19.6%, 61.5%)
07/20 10:06:02 PM | Valid: [16/50] Step 150/390 Loss 7.650 Prec@(1,5) (19.4%, 61.3%)
07/20 10:06:11 PM | Valid: [16/50] Step 200/390 Loss 7.637 Prec@(1,5) (19.5%, 61.4%)
07/20 10:06:21 PM | Valid: [16/50] Step 250/390 Loss 7.660 Prec@(1,5) (19.4%, 61.1%)
07/20 10:06:30 PM | Valid: [16/50] Step 300/390 Loss 7.676 Prec@(1,5) (19.3%, 61.0%)
07/20 10:06:40 PM | Valid: [16/50] Step 350/390 Loss 7.696 Prec@(1,5) (19.2%, 60.7%)
07/20 10:06:47 PM | Valid: [16/50] Step 390/390 Loss 7.683 Prec@(1,5) (19.2%, 60.7%)
07/20 10:06:47 PM | Valid: [16/50] Final Prec@1 19.1640%
07/20 10:06:47 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1247, 0.1237, 0.1239, 0.1255, 0.1261, 0.1244, 0.1262, 0.1255],
        [0.1233, 0.1233, 0.1232, 0.1260, 0.1261, 0.1260, 0.1259, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1237, 0.1238, 0.1237, 0.1258, 0.1259, 0.1255, 0.1258, 0.1258],
        [0.1233, 0.1229, 0.1231, 0.1260, 0.1260, 0.1260, 0.1262, 0.1266],
        [0.1233, 0.1232, 0.1231, 0.1261, 0.1264, 0.1258, 0.1261, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1235, 0.1232, 0.1233, 0.1256, 0.1263, 0.1262, 0.1255, 0.1265],
        [0.1231, 0.1229, 0.1231, 0.1258, 0.1261, 0.1265, 0.1263, 0.1262],
        [0.1232, 0.1232, 0.1232, 0.1257, 0.1262, 0.1259, 0.1262, 0.1264],
        [0.1232, 0.1232, 0.1231, 0.1255, 0.1263, 0.1264, 0.1261, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1234, 0.1232, 0.1230, 0.1261, 0.1258, 0.1258, 0.1261, 0.1265],
        [0.1232, 0.1232, 0.1233, 0.1257, 0.1260, 0.1262, 0.1259, 0.1264],
        [0.1232, 0.1231, 0.1230, 0.1260, 0.1260, 0.1263, 0.1263, 0.1261],
        [0.1230, 0.1231, 0.1230, 0.1265, 0.1261, 0.1263, 0.1258, 0.1261],
        [0.1232, 0.1232, 0.1232, 0.1260, 0.1259, 0.1262, 0.1261, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1258, 0.1250, 0.1246, 0.1253, 0.1252, 0.1248, 0.1248, 0.1245],
        [0.1240, 0.1234, 0.1254, 0.1255, 0.1253, 0.1254, 0.1254, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1243, 0.1257, 0.1263, 0.1245, 0.1248, 0.1243, 0.1242],
        [0.1238, 0.1234, 0.1259, 0.1254, 0.1260, 0.1257, 0.1244, 0.1254],
        [0.1250, 0.1237, 0.1259, 0.1242, 0.1250, 0.1252, 0.1247, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1246, 0.1254, 0.1248, 0.1248, 0.1256, 0.1244, 0.1243],
        [0.1244, 0.1238, 0.1253, 0.1257, 0.1260, 0.1245, 0.1258, 0.1246],
        [0.1258, 0.1244, 0.1256, 0.1239, 0.1258, 0.1259, 0.1240, 0.1247],
        [0.1245, 0.1240, 0.1250, 0.1248, 0.1255, 0.1249, 0.1256, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1259, 0.1251, 0.1249, 0.1251, 0.1253, 0.1249, 0.1252, 0.1237],
        [0.1242, 0.1235, 0.1247, 0.1252, 0.1253, 0.1257, 0.1262, 0.1252],
        [0.1249, 0.1243, 0.1252, 0.1257, 0.1244, 0.1254, 0.1253, 0.1248],
        [0.1239, 0.1236, 0.1240, 0.1262, 0.1252, 0.1261, 0.1256, 0.1254],
        [0.1238, 0.1238, 0.1246, 0.1255, 0.1259, 0.1246, 0.1256, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:06:52 PM | Train: [17/50] Step 000/001 Loss 0.003 Prec@(1,5) (100.0%, 100.0%)
07/20 10:06:56 PM | Train: [17/50] Step 001/001 Loss 0.184 Prec@(1,5) (100.0%, 100.0%)
07/20 10:06:56 PM | Train: [17/50] Final Prec@1 100.0000%
07/20 10:06:56 PM | Valid: [17/50] Step 000/390 Loss 9.592 Prec@(1,5) (18.8%, 62.5%)
07/20 10:07:06 PM | Valid: [17/50] Step 050/390 Loss 9.013 Prec@(1,5) (17.5%, 61.0%)
07/20 10:07:15 PM | Valid: [17/50] Step 100/390 Loss 8.970 Prec@(1,5) (17.7%, 61.2%)
07/20 10:07:25 PM | Valid: [17/50] Step 150/390 Loss 8.991 Prec@(1,5) (17.6%, 60.6%)
07/20 10:07:34 PM | Valid: [17/50] Step 200/390 Loss 8.924 Prec@(1,5) (17.8%, 60.8%)
07/20 10:07:43 PM | Valid: [17/50] Step 250/390 Loss 8.951 Prec@(1,5) (17.9%, 60.6%)
07/20 10:07:53 PM | Valid: [17/50] Step 300/390 Loss 8.964 Prec@(1,5) (17.8%, 60.6%)
07/20 10:08:02 PM | Valid: [17/50] Step 350/390 Loss 8.929 Prec@(1,5) (17.9%, 60.8%)
07/20 10:08:09 PM | Valid: [17/50] Step 390/390 Loss 8.934 Prec@(1,5) (17.9%, 60.8%)
07/20 10:08:09 PM | Valid: [17/50] Final Prec@1 17.8560%
07/20 10:08:09 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('sep_conv_5x5', 2), ('dil_conv_5x5', 1)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1245, 0.1236, 0.1238, 0.1256, 0.1262, 0.1244, 0.1263, 0.1256],
        [0.1232, 0.1232, 0.1231, 0.1261, 0.1261, 0.1260, 0.1260, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1236, 0.1237, 0.1235, 0.1259, 0.1260, 0.1256, 0.1259, 0.1259],
        [0.1232, 0.1228, 0.1230, 0.1260, 0.1260, 0.1261, 0.1263, 0.1267],
        [0.1232, 0.1231, 0.1230, 0.1262, 0.1265, 0.1259, 0.1261, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1233, 0.1231, 0.1232, 0.1257, 0.1264, 0.1263, 0.1256, 0.1265],
        [0.1229, 0.1228, 0.1230, 0.1259, 0.1262, 0.1266, 0.1264, 0.1262],
        [0.1231, 0.1231, 0.1231, 0.1258, 0.1263, 0.1259, 0.1263, 0.1265],
        [0.1231, 0.1231, 0.1230, 0.1257, 0.1263, 0.1265, 0.1262, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1231, 0.1228, 0.1262, 0.1259, 0.1259, 0.1262, 0.1266],
        [0.1231, 0.1231, 0.1232, 0.1258, 0.1261, 0.1263, 0.1259, 0.1265],
        [0.1231, 0.1230, 0.1229, 0.1260, 0.1261, 0.1264, 0.1264, 0.1261],
        [0.1229, 0.1229, 0.1229, 0.1266, 0.1262, 0.1264, 0.1259, 0.1262],
        [0.1230, 0.1230, 0.1231, 0.1261, 0.1260, 0.1263, 0.1262, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1259, 0.1251, 0.1246, 0.1253, 0.1252, 0.1248, 0.1248, 0.1244],
        [0.1240, 0.1234, 0.1254, 0.1254, 0.1253, 0.1255, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1243, 0.1258, 0.1264, 0.1244, 0.1248, 0.1242, 0.1241],
        [0.1237, 0.1233, 0.1260, 0.1255, 0.1260, 0.1258, 0.1244, 0.1253],
        [0.1250, 0.1237, 0.1260, 0.1241, 0.1250, 0.1253, 0.1246, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1246, 0.1254, 0.1248, 0.1248, 0.1257, 0.1244, 0.1242],
        [0.1243, 0.1237, 0.1253, 0.1256, 0.1259, 0.1246, 0.1259, 0.1247],
        [0.1258, 0.1243, 0.1256, 0.1238, 0.1258, 0.1260, 0.1239, 0.1247],
        [0.1245, 0.1239, 0.1250, 0.1247, 0.1256, 0.1249, 0.1256, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1260, 0.1251, 0.1249, 0.1250, 0.1253, 0.1249, 0.1251, 0.1237],
        [0.1242, 0.1234, 0.1246, 0.1252, 0.1253, 0.1258, 0.1263, 0.1252],
        [0.1248, 0.1242, 0.1252, 0.1258, 0.1244, 0.1255, 0.1254, 0.1248],
        [0.1238, 0.1235, 0.1239, 0.1262, 0.1252, 0.1262, 0.1257, 0.1255],
        [0.1237, 0.1237, 0.1245, 0.1256, 0.1260, 0.1246, 0.1256, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:08:15 PM | Train: [18/50] Step 000/001 Loss 0.005 Prec@(1,5) (100.0%, 100.0%)
07/20 10:08:18 PM | Train: [18/50] Step 001/001 Loss 0.237 Prec@(1,5) (88.9%, 100.0%)
07/20 10:08:18 PM | Train: [18/50] Final Prec@1 88.8889%
07/20 10:08:19 PM | Valid: [18/50] Step 000/390 Loss 8.014 Prec@(1,5) (23.4%, 65.6%)
07/20 10:08:28 PM | Valid: [18/50] Step 050/390 Loss 8.513 Prec@(1,5) (18.5%, 61.0%)
07/20 10:08:38 PM | Valid: [18/50] Step 100/390 Loss 8.608 Prec@(1,5) (18.3%, 60.8%)
07/20 10:08:47 PM | Valid: [18/50] Step 150/390 Loss 8.647 Prec@(1,5) (17.9%, 60.3%)
07/20 10:08:56 PM | Valid: [18/50] Step 200/390 Loss 8.681 Prec@(1,5) (17.5%, 60.0%)
07/20 10:09:06 PM | Valid: [18/50] Step 250/390 Loss 8.692 Prec@(1,5) (17.6%, 59.9%)
07/20 10:09:15 PM | Valid: [18/50] Step 300/390 Loss 8.695 Prec@(1,5) (17.5%, 59.9%)
07/20 10:09:24 PM | Valid: [18/50] Step 350/390 Loss 8.678 Prec@(1,5) (17.5%, 59.8%)
07/20 10:09:32 PM | Valid: [18/50] Step 390/390 Loss 8.685 Prec@(1,5) (17.6%, 59.8%)
07/20 10:09:32 PM | Valid: [18/50] Final Prec@1 17.5880%
07/20 10:09:32 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1244, 0.1235, 0.1236, 0.1256, 0.1263, 0.1245, 0.1263, 0.1257],
        [0.1230, 0.1231, 0.1230, 0.1261, 0.1262, 0.1261, 0.1261, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1234, 0.1236, 0.1234, 0.1260, 0.1260, 0.1257, 0.1259, 0.1260],
        [0.1231, 0.1227, 0.1228, 0.1260, 0.1261, 0.1262, 0.1264, 0.1267],
        [0.1230, 0.1230, 0.1229, 0.1262, 0.1265, 0.1260, 0.1262, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1229, 0.1230, 0.1257, 0.1264, 0.1264, 0.1257, 0.1266],
        [0.1228, 0.1227, 0.1229, 0.1259, 0.1262, 0.1267, 0.1264, 0.1263],
        [0.1230, 0.1229, 0.1230, 0.1259, 0.1264, 0.1259, 0.1263, 0.1265],
        [0.1229, 0.1229, 0.1229, 0.1258, 0.1264, 0.1265, 0.1263, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1229, 0.1227, 0.1263, 0.1260, 0.1260, 0.1263, 0.1267],
        [0.1230, 0.1230, 0.1231, 0.1259, 0.1262, 0.1263, 0.1260, 0.1266],
        [0.1230, 0.1229, 0.1227, 0.1261, 0.1262, 0.1265, 0.1264, 0.1262],
        [0.1227, 0.1228, 0.1228, 0.1267, 0.1262, 0.1264, 0.1260, 0.1263],
        [0.1229, 0.1229, 0.1230, 0.1262, 0.1260, 0.1263, 0.1263, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1260, 0.1252, 0.1246, 0.1253, 0.1251, 0.1248, 0.1247, 0.1243],
        [0.1239, 0.1233, 0.1254, 0.1254, 0.1254, 0.1255, 0.1254, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1244, 0.1259, 0.1264, 0.1243, 0.1247, 0.1241, 0.1240],
        [0.1236, 0.1232, 0.1261, 0.1255, 0.1260, 0.1258, 0.1243, 0.1254],
        [0.1251, 0.1236, 0.1261, 0.1240, 0.1250, 0.1253, 0.1245, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1247, 0.1254, 0.1247, 0.1247, 0.1257, 0.1243, 0.1241],
        [0.1243, 0.1237, 0.1253, 0.1256, 0.1260, 0.1245, 0.1259, 0.1248],
        [0.1258, 0.1242, 0.1257, 0.1238, 0.1259, 0.1261, 0.1238, 0.1247],
        [0.1244, 0.1238, 0.1251, 0.1246, 0.1257, 0.1249, 0.1256, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1261, 0.1251, 0.1249, 0.1250, 0.1254, 0.1247, 0.1250, 0.1236],
        [0.1240, 0.1233, 0.1246, 0.1251, 0.1254, 0.1259, 0.1263, 0.1253],
        [0.1247, 0.1241, 0.1252, 0.1258, 0.1243, 0.1256, 0.1254, 0.1248],
        [0.1237, 0.1234, 0.1239, 0.1262, 0.1253, 0.1263, 0.1258, 0.1255],
        [0.1236, 0.1236, 0.1245, 0.1256, 0.1260, 0.1246, 0.1257, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:09:37 PM | Train: [19/50] Step 000/001 Loss 0.002 Prec@(1,5) (100.0%, 100.0%)
07/20 10:09:40 PM | Train: [19/50] Step 001/001 Loss 0.181 Prec@(1,5) (100.0%, 100.0%)
07/20 10:09:40 PM | Train: [19/50] Final Prec@1 100.0000%
07/20 10:09:41 PM | Valid: [19/50] Step 000/390 Loss 7.881 Prec@(1,5) (14.1%, 57.8%)
07/20 10:09:50 PM | Valid: [19/50] Step 050/390 Loss 8.155 Prec@(1,5) (19.7%, 60.2%)
07/20 10:10:00 PM | Valid: [19/50] Step 100/390 Loss 8.083 Prec@(1,5) (19.8%, 60.8%)
07/20 10:10:10 PM | Valid: [19/50] Step 150/390 Loss 8.142 Prec@(1,5) (19.7%, 60.3%)
07/20 10:10:19 PM | Valid: [19/50] Step 200/390 Loss 8.139 Prec@(1,5) (19.7%, 60.2%)
07/20 10:10:29 PM | Valid: [19/50] Step 250/390 Loss 8.118 Prec@(1,5) (19.7%, 60.5%)
07/20 10:10:39 PM | Valid: [19/50] Step 300/390 Loss 8.107 Prec@(1,5) (19.6%, 60.5%)
07/20 10:10:48 PM | Valid: [19/50] Step 350/390 Loss 8.126 Prec@(1,5) (19.5%, 60.4%)
07/20 10:10:56 PM | Valid: [19/50] Step 390/390 Loss 8.143 Prec@(1,5) (19.5%, 60.3%)
07/20 10:10:56 PM | Valid: [19/50] Final Prec@1 19.5160%
07/20 10:10:56 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1243, 0.1233, 0.1235, 0.1257, 0.1264, 0.1246, 0.1264, 0.1258],
        [0.1230, 0.1230, 0.1229, 0.1261, 0.1263, 0.1262, 0.1261, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1233, 0.1234, 0.1233, 0.1260, 0.1261, 0.1257, 0.1260, 0.1261],
        [0.1229, 0.1225, 0.1227, 0.1261, 0.1262, 0.1262, 0.1265, 0.1268],
        [0.1229, 0.1228, 0.1228, 0.1262, 0.1266, 0.1261, 0.1263, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1228, 0.1229, 0.1257, 0.1265, 0.1265, 0.1258, 0.1267],
        [0.1227, 0.1226, 0.1228, 0.1260, 0.1263, 0.1268, 0.1265, 0.1264],
        [0.1229, 0.1228, 0.1228, 0.1260, 0.1264, 0.1261, 0.1264, 0.1266],
        [0.1228, 0.1228, 0.1228, 0.1258, 0.1264, 0.1266, 0.1263, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1228, 0.1226, 0.1263, 0.1261, 0.1261, 0.1263, 0.1267],
        [0.1229, 0.1229, 0.1230, 0.1259, 0.1263, 0.1264, 0.1261, 0.1266],
        [0.1229, 0.1227, 0.1226, 0.1263, 0.1262, 0.1265, 0.1264, 0.1263],
        [0.1226, 0.1227, 0.1227, 0.1268, 0.1263, 0.1265, 0.1260, 0.1264],
        [0.1228, 0.1228, 0.1229, 0.1262, 0.1261, 0.1264, 0.1263, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1261, 0.1252, 0.1247, 0.1253, 0.1251, 0.1247, 0.1246, 0.1243],
        [0.1238, 0.1232, 0.1254, 0.1254, 0.1254, 0.1255, 0.1254, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1244, 0.1260, 0.1265, 0.1243, 0.1247, 0.1241, 0.1238],
        [0.1236, 0.1232, 0.1261, 0.1256, 0.1261, 0.1259, 0.1242, 0.1254],
        [0.1251, 0.1235, 0.1261, 0.1239, 0.1250, 0.1254, 0.1245, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1247, 0.1254, 0.1247, 0.1247, 0.1258, 0.1243, 0.1240],
        [0.1242, 0.1236, 0.1254, 0.1256, 0.1260, 0.1245, 0.1259, 0.1248],
        [0.1258, 0.1241, 0.1257, 0.1238, 0.1260, 0.1262, 0.1238, 0.1246],
        [0.1244, 0.1237, 0.1252, 0.1245, 0.1257, 0.1248, 0.1257, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1251, 0.1249, 0.1249, 0.1255, 0.1248, 0.1251, 0.1236],
        [0.1239, 0.1231, 0.1247, 0.1252, 0.1254, 0.1259, 0.1264, 0.1253],
        [0.1246, 0.1240, 0.1252, 0.1260, 0.1243, 0.1256, 0.1255, 0.1248],
        [0.1235, 0.1233, 0.1237, 0.1263, 0.1254, 0.1264, 0.1259, 0.1255],
        [0.1236, 0.1235, 0.1244, 0.1257, 0.1261, 0.1247, 0.1257, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:11:01 PM | Train: [20/50] Step 000/001 Loss 0.001 Prec@(1,5) (100.0%, 100.0%)
07/20 10:11:04 PM | Train: [20/50] Step 001/001 Loss 0.277 Prec@(1,5) (88.9%, 88.9%)
07/20 10:11:05 PM | Train: [20/50] Final Prec@1 88.8889%
07/20 10:11:05 PM | Valid: [20/50] Step 000/390 Loss 7.668 Prec@(1,5) (15.6%, 64.1%)
07/20 10:11:15 PM | Valid: [20/50] Step 050/390 Loss 7.454 Prec@(1,5) (18.6%, 59.7%)
07/20 10:11:24 PM | Valid: [20/50] Step 100/390 Loss 7.387 Prec@(1,5) (19.4%, 60.1%)
07/20 10:11:33 PM | Valid: [20/50] Step 150/390 Loss 7.311 Prec@(1,5) (19.6%, 60.0%)
07/20 10:11:43 PM | Valid: [20/50] Step 200/390 Loss 7.338 Prec@(1,5) (19.5%, 59.9%)
07/20 10:11:52 PM | Valid: [20/50] Step 250/390 Loss 7.301 Prec@(1,5) (19.6%, 59.9%)
07/20 10:12:01 PM | Valid: [20/50] Step 300/390 Loss 7.257 Prec@(1,5) (19.9%, 60.1%)
07/20 10:12:11 PM | Valid: [20/50] Step 350/390 Loss 7.250 Prec@(1,5) (19.9%, 60.0%)
07/20 10:12:18 PM | Valid: [20/50] Step 390/390 Loss 7.244 Prec@(1,5) (20.1%, 60.1%)
07/20 10:12:18 PM | Valid: [20/50] Final Prec@1 20.0640%
07/20 10:12:18 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1242, 0.1233, 0.1235, 0.1258, 0.1264, 0.1246, 0.1264, 0.1259],
        [0.1229, 0.1228, 0.1228, 0.1262, 0.1263, 0.1262, 0.1262, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1232, 0.1233, 0.1232, 0.1261, 0.1262, 0.1257, 0.1261, 0.1261],
        [0.1228, 0.1224, 0.1225, 0.1262, 0.1263, 0.1263, 0.1266, 0.1269],
        [0.1228, 0.1227, 0.1226, 0.1263, 0.1267, 0.1262, 0.1264, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1227, 0.1228, 0.1257, 0.1266, 0.1265, 0.1258, 0.1268],
        [0.1226, 0.1225, 0.1226, 0.1261, 0.1264, 0.1268, 0.1265, 0.1265],
        [0.1228, 0.1227, 0.1227, 0.1260, 0.1265, 0.1261, 0.1265, 0.1267],
        [0.1227, 0.1227, 0.1226, 0.1259, 0.1265, 0.1267, 0.1264, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1227, 0.1225, 0.1264, 0.1262, 0.1262, 0.1264, 0.1268],
        [0.1228, 0.1228, 0.1229, 0.1260, 0.1264, 0.1264, 0.1261, 0.1267],
        [0.1228, 0.1226, 0.1225, 0.1263, 0.1263, 0.1266, 0.1265, 0.1264],
        [0.1225, 0.1226, 0.1226, 0.1269, 0.1263, 0.1266, 0.1261, 0.1264],
        [0.1227, 0.1227, 0.1227, 0.1263, 0.1261, 0.1265, 0.1264, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1262, 0.1252, 0.1247, 0.1253, 0.1250, 0.1247, 0.1245, 0.1243],
        [0.1238, 0.1231, 0.1255, 0.1255, 0.1255, 0.1256, 0.1253, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1262, 0.1243, 0.1261, 0.1265, 0.1242, 0.1247, 0.1242, 0.1238],
        [0.1236, 0.1231, 0.1261, 0.1257, 0.1261, 0.1258, 0.1241, 0.1254],
        [0.1251, 0.1234, 0.1262, 0.1238, 0.1251, 0.1255, 0.1245, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1246, 0.1253, 0.1246, 0.1248, 0.1259, 0.1242, 0.1240],
        [0.1242, 0.1235, 0.1255, 0.1257, 0.1259, 0.1244, 0.1259, 0.1249],
        [0.1258, 0.1239, 0.1257, 0.1238, 0.1261, 0.1263, 0.1237, 0.1246],
        [0.1244, 0.1236, 0.1252, 0.1245, 0.1258, 0.1248, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1251, 0.1249, 0.1249, 0.1255, 0.1248, 0.1251, 0.1235],
        [0.1238, 0.1231, 0.1247, 0.1252, 0.1255, 0.1260, 0.1264, 0.1253],
        [0.1246, 0.1239, 0.1251, 0.1260, 0.1244, 0.1257, 0.1255, 0.1248],
        [0.1235, 0.1232, 0.1236, 0.1263, 0.1255, 0.1264, 0.1260, 0.1256],
        [0.1235, 0.1234, 0.1243, 0.1257, 0.1261, 0.1247, 0.1257, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:12:23 PM | Train: [21/50] Step 000/001 Loss 0.003 Prec@(1,5) (100.0%, 100.0%)
07/20 10:12:27 PM | Train: [21/50] Step 001/001 Loss 0.254 Prec@(1,5) (88.9%, 100.0%)
07/20 10:12:27 PM | Train: [21/50] Final Prec@1 88.8889%
07/20 10:12:27 PM | Valid: [21/50] Step 000/390 Loss 9.626 Prec@(1,5) (17.2%, 60.9%)
07/20 10:12:37 PM | Valid: [21/50] Step 050/390 Loss 9.302 Prec@(1,5) (16.6%, 59.3%)
07/20 10:12:46 PM | Valid: [21/50] Step 100/390 Loss 9.171 Prec@(1,5) (17.2%, 60.0%)
07/20 10:12:55 PM | Valid: [21/50] Step 150/390 Loss 9.196 Prec@(1,5) (17.2%, 59.9%)
07/20 10:13:05 PM | Valid: [21/50] Step 200/390 Loss 9.222 Prec@(1,5) (17.0%, 59.7%)
07/20 10:13:14 PM | Valid: [21/50] Step 250/390 Loss 9.167 Prec@(1,5) (17.1%, 60.0%)
07/20 10:13:23 PM | Valid: [21/50] Step 300/390 Loss 9.194 Prec@(1,5) (16.9%, 59.9%)
07/20 10:13:33 PM | Valid: [21/50] Step 350/390 Loss 9.194 Prec@(1,5) (17.0%, 59.9%)
07/20 10:13:40 PM | Valid: [21/50] Step 390/390 Loss 9.211 Prec@(1,5) (16.9%, 59.8%)
07/20 10:13:40 PM | Valid: [21/50] Final Prec@1 16.8720%
07/20 10:13:40 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1242, 0.1232, 0.1234, 0.1259, 0.1265, 0.1245, 0.1265, 0.1259],
        [0.1227, 0.1227, 0.1227, 0.1262, 0.1264, 0.1262, 0.1263, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1231, 0.1232, 0.1231, 0.1262, 0.1263, 0.1257, 0.1262, 0.1262],
        [0.1227, 0.1223, 0.1224, 0.1262, 0.1264, 0.1264, 0.1267, 0.1270],
        [0.1227, 0.1226, 0.1225, 0.1263, 0.1267, 0.1262, 0.1265, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1226, 0.1227, 0.1258, 0.1267, 0.1266, 0.1259, 0.1268],
        [0.1225, 0.1223, 0.1225, 0.1262, 0.1264, 0.1269, 0.1266, 0.1265],
        [0.1227, 0.1226, 0.1226, 0.1261, 0.1266, 0.1261, 0.1265, 0.1268],
        [0.1226, 0.1226, 0.1225, 0.1260, 0.1265, 0.1268, 0.1265, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1226, 0.1224, 0.1265, 0.1262, 0.1262, 0.1265, 0.1268],
        [0.1227, 0.1227, 0.1227, 0.1260, 0.1264, 0.1265, 0.1262, 0.1268],
        [0.1227, 0.1225, 0.1224, 0.1264, 0.1264, 0.1267, 0.1265, 0.1264],
        [0.1224, 0.1225, 0.1225, 0.1269, 0.1264, 0.1266, 0.1261, 0.1265],
        [0.1226, 0.1226, 0.1226, 0.1264, 0.1262, 0.1266, 0.1265, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1263, 0.1252, 0.1248, 0.1254, 0.1250, 0.1247, 0.1245, 0.1243],
        [0.1237, 0.1230, 0.1254, 0.1255, 0.1256, 0.1256, 0.1254, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1263, 0.1243, 0.1261, 0.1266, 0.1241, 0.1247, 0.1243, 0.1237],
        [0.1235, 0.1230, 0.1261, 0.1258, 0.1262, 0.1259, 0.1240, 0.1255],
        [0.1252, 0.1233, 0.1262, 0.1237, 0.1250, 0.1256, 0.1245, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1246, 0.1253, 0.1246, 0.1247, 0.1260, 0.1242, 0.1240],
        [0.1242, 0.1235, 0.1255, 0.1257, 0.1258, 0.1244, 0.1258, 0.1250],
        [0.1258, 0.1239, 0.1257, 0.1238, 0.1261, 0.1264, 0.1237, 0.1246],
        [0.1244, 0.1236, 0.1252, 0.1245, 0.1258, 0.1249, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1251, 0.1249, 0.1248, 0.1256, 0.1248, 0.1251, 0.1234],
        [0.1237, 0.1229, 0.1247, 0.1252, 0.1255, 0.1261, 0.1265, 0.1253],
        [0.1245, 0.1238, 0.1251, 0.1261, 0.1244, 0.1257, 0.1255, 0.1248],
        [0.1234, 0.1231, 0.1236, 0.1264, 0.1255, 0.1264, 0.1260, 0.1257],
        [0.1234, 0.1233, 0.1242, 0.1258, 0.1262, 0.1248, 0.1257, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:13:45 PM | Train: [22/50] Step 000/001 Loss 0.003 Prec@(1,5) (100.0%, 100.0%)
07/20 10:13:49 PM | Train: [22/50] Step 001/001 Loss 0.252 Prec@(1,5) (88.9%, 100.0%)
07/20 10:13:49 PM | Train: [22/50] Final Prec@1 88.8889%
07/20 10:13:49 PM | Valid: [22/50] Step 000/390 Loss 10.309 Prec@(1,5) (12.5%, 60.9%)
07/20 10:13:59 PM | Valid: [22/50] Step 050/390 Loss 10.250 Prec@(1,5) (16.2%, 59.4%)
07/20 10:14:08 PM | Valid: [22/50] Step 100/390 Loss 10.398 Prec@(1,5) (15.7%, 58.6%)
07/20 10:14:17 PM | Valid: [22/50] Step 150/390 Loss 10.462 Prec@(1,5) (15.4%, 59.2%)
07/20 10:14:27 PM | Valid: [22/50] Step 200/390 Loss 10.425 Prec@(1,5) (15.9%, 59.0%)
07/20 10:14:36 PM | Valid: [22/50] Step 250/390 Loss 10.420 Prec@(1,5) (15.8%, 59.1%)
07/20 10:14:45 PM | Valid: [22/50] Step 300/390 Loss 10.470 Prec@(1,5) (15.8%, 59.0%)
07/20 10:14:55 PM | Valid: [22/50] Step 350/390 Loss 10.444 Prec@(1,5) (15.9%, 58.8%)
07/20 10:15:02 PM | Valid: [22/50] Step 390/390 Loss 10.416 Prec@(1,5) (15.9%, 58.8%)
07/20 10:15:02 PM | Valid: [22/50] Final Prec@1 15.8880%
07/20 10:15:02 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1240, 0.1231, 0.1233, 0.1260, 0.1265, 0.1246, 0.1266, 0.1259],
        [0.1226, 0.1226, 0.1226, 0.1263, 0.1265, 0.1263, 0.1264, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1230, 0.1231, 0.1230, 0.1262, 0.1263, 0.1258, 0.1263, 0.1263],
        [0.1225, 0.1221, 0.1223, 0.1263, 0.1265, 0.1264, 0.1267, 0.1270],
        [0.1226, 0.1225, 0.1224, 0.1264, 0.1268, 0.1263, 0.1266, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1225, 0.1226, 0.1258, 0.1268, 0.1266, 0.1260, 0.1269],
        [0.1224, 0.1222, 0.1224, 0.1263, 0.1265, 0.1270, 0.1267, 0.1266],
        [0.1226, 0.1225, 0.1225, 0.1261, 0.1266, 0.1262, 0.1266, 0.1269],
        [0.1225, 0.1225, 0.1224, 0.1260, 0.1266, 0.1268, 0.1265, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1225, 0.1223, 0.1265, 0.1263, 0.1263, 0.1265, 0.1269],
        [0.1225, 0.1226, 0.1226, 0.1261, 0.1265, 0.1265, 0.1262, 0.1269],
        [0.1226, 0.1224, 0.1223, 0.1264, 0.1265, 0.1268, 0.1266, 0.1265],
        [0.1223, 0.1224, 0.1224, 0.1270, 0.1264, 0.1267, 0.1262, 0.1266],
        [0.1225, 0.1225, 0.1225, 0.1264, 0.1262, 0.1267, 0.1265, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1264, 0.1252, 0.1248, 0.1254, 0.1249, 0.1246, 0.1244, 0.1242],
        [0.1237, 0.1229, 0.1254, 0.1256, 0.1256, 0.1257, 0.1253, 0.1258]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1242, 0.1261, 0.1267, 0.1240, 0.1247, 0.1243, 0.1236],
        [0.1235, 0.1230, 0.1262, 0.1259, 0.1262, 0.1259, 0.1240, 0.1254],
        [0.1253, 0.1233, 0.1263, 0.1237, 0.1250, 0.1256, 0.1245, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1267, 0.1246, 0.1253, 0.1246, 0.1247, 0.1260, 0.1242, 0.1240],
        [0.1242, 0.1235, 0.1256, 0.1257, 0.1258, 0.1243, 0.1258, 0.1251],
        [0.1259, 0.1238, 0.1258, 0.1237, 0.1262, 0.1265, 0.1236, 0.1246],
        [0.1244, 0.1235, 0.1253, 0.1244, 0.1258, 0.1249, 0.1258, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1251, 0.1248, 0.1249, 0.1256, 0.1247, 0.1251, 0.1234],
        [0.1236, 0.1228, 0.1247, 0.1252, 0.1255, 0.1262, 0.1265, 0.1254],
        [0.1244, 0.1237, 0.1251, 0.1262, 0.1245, 0.1258, 0.1255, 0.1248],
        [0.1233, 0.1230, 0.1235, 0.1264, 0.1255, 0.1265, 0.1260, 0.1258],
        [0.1233, 0.1232, 0.1242, 0.1258, 0.1263, 0.1249, 0.1257, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:15:07 PM | Train: [23/50] Step 000/001 Loss 0.001 Prec@(1,5) (100.0%, 100.0%)
07/20 10:15:11 PM | Train: [23/50] Step 001/001 Loss 0.175 Prec@(1,5) (100.0%, 100.0%)
07/20 10:15:11 PM | Train: [23/50] Final Prec@1 100.0000%
07/20 10:15:11 PM | Valid: [23/50] Step 000/390 Loss 8.162 Prec@(1,5) (14.1%, 50.0%)
07/20 10:15:21 PM | Valid: [23/50] Step 050/390 Loss 7.409 Prec@(1,5) (20.3%, 57.0%)
07/20 10:15:30 PM | Valid: [23/50] Step 100/390 Loss 7.305 Prec@(1,5) (20.7%, 57.8%)
07/20 10:15:39 PM | Valid: [23/50] Step 150/390 Loss 7.354 Prec@(1,5) (20.4%, 58.0%)
07/20 10:15:49 PM | Valid: [23/50] Step 200/390 Loss 7.389 Prec@(1,5) (20.5%, 58.3%)
07/20 10:15:58 PM | Valid: [23/50] Step 250/390 Loss 7.411 Prec@(1,5) (20.3%, 58.0%)
07/20 10:16:08 PM | Valid: [23/50] Step 300/390 Loss 7.417 Prec@(1,5) (20.1%, 58.0%)
07/20 10:16:17 PM | Valid: [23/50] Step 350/390 Loss 7.407 Prec@(1,5) (20.1%, 57.9%)
07/20 10:16:25 PM | Valid: [23/50] Step 390/390 Loss 7.430 Prec@(1,5) (20.1%, 58.0%)
07/20 10:16:25 PM | Valid: [23/50] Final Prec@1 20.1080%
07/20 10:16:25 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1239, 0.1230, 0.1232, 0.1260, 0.1267, 0.1246, 0.1267, 0.1260],
        [0.1225, 0.1225, 0.1225, 0.1263, 0.1266, 0.1263, 0.1264, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1229, 0.1230, 0.1229, 0.1263, 0.1264, 0.1258, 0.1264, 0.1263],
        [0.1224, 0.1220, 0.1222, 0.1264, 0.1265, 0.1265, 0.1268, 0.1271],
        [0.1225, 0.1224, 0.1223, 0.1264, 0.1269, 0.1264, 0.1266, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1227, 0.1224, 0.1225, 0.1258, 0.1268, 0.1266, 0.1261, 0.1270],
        [0.1223, 0.1221, 0.1223, 0.1263, 0.1266, 0.1270, 0.1267, 0.1267],
        [0.1225, 0.1224, 0.1224, 0.1261, 0.1267, 0.1263, 0.1267, 0.1269],
        [0.1224, 0.1224, 0.1223, 0.1261, 0.1267, 0.1269, 0.1265, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1224, 0.1222, 0.1266, 0.1264, 0.1264, 0.1266, 0.1270],
        [0.1224, 0.1225, 0.1225, 0.1262, 0.1266, 0.1266, 0.1263, 0.1269],
        [0.1224, 0.1223, 0.1222, 0.1265, 0.1265, 0.1268, 0.1267, 0.1266],
        [0.1222, 0.1223, 0.1223, 0.1270, 0.1265, 0.1268, 0.1263, 0.1266],
        [0.1224, 0.1224, 0.1224, 0.1265, 0.1263, 0.1267, 0.1266, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1265, 0.1252, 0.1248, 0.1254, 0.1249, 0.1246, 0.1244, 0.1242],
        [0.1236, 0.1229, 0.1254, 0.1257, 0.1257, 0.1256, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1243, 0.1261, 0.1267, 0.1239, 0.1247, 0.1242, 0.1236],
        [0.1235, 0.1229, 0.1262, 0.1259, 0.1262, 0.1259, 0.1240, 0.1253],
        [0.1253, 0.1232, 0.1264, 0.1236, 0.1250, 0.1256, 0.1244, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1246, 0.1252, 0.1245, 0.1248, 0.1261, 0.1242, 0.1239],
        [0.1242, 0.1234, 0.1255, 0.1258, 0.1258, 0.1243, 0.1258, 0.1251],
        [0.1259, 0.1237, 0.1258, 0.1237, 0.1262, 0.1265, 0.1236, 0.1245],
        [0.1243, 0.1234, 0.1253, 0.1244, 0.1258, 0.1249, 0.1259, 0.1259]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1250, 0.1249, 0.1249, 0.1256, 0.1247, 0.1251, 0.1233],
        [0.1236, 0.1228, 0.1247, 0.1251, 0.1255, 0.1262, 0.1266, 0.1255],
        [0.1243, 0.1237, 0.1250, 0.1263, 0.1245, 0.1258, 0.1256, 0.1248],
        [0.1232, 0.1229, 0.1235, 0.1264, 0.1255, 0.1265, 0.1261, 0.1259],
        [0.1232, 0.1231, 0.1241, 0.1258, 0.1263, 0.1249, 0.1258, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:16:30 PM | Train: [24/50] Step 000/001 Loss 0.002 Prec@(1,5) (100.0%, 100.0%)
07/20 10:16:33 PM | Train: [24/50] Step 001/001 Loss 0.245 Prec@(1,5) (88.9%, 100.0%)
07/20 10:16:33 PM | Train: [24/50] Final Prec@1 88.8889%
07/20 10:16:34 PM | Valid: [24/50] Step 000/390 Loss 10.640 Prec@(1,5) (9.4%, 57.8%)
07/20 10:16:43 PM | Valid: [24/50] Step 050/390 Loss 9.759 Prec@(1,5) (15.7%, 57.9%)
07/20 10:16:52 PM | Valid: [24/50] Step 100/390 Loss 9.687 Prec@(1,5) (16.4%, 58.6%)
07/20 10:17:02 PM | Valid: [24/50] Step 150/390 Loss 9.605 Prec@(1,5) (16.3%, 58.5%)
07/20 10:17:11 PM | Valid: [24/50] Step 200/390 Loss 9.591 Prec@(1,5) (16.5%, 58.9%)
07/20 10:17:20 PM | Valid: [24/50] Step 250/390 Loss 9.563 Prec@(1,5) (16.5%, 58.8%)
07/20 10:17:30 PM | Valid: [24/50] Step 300/390 Loss 9.539 Prec@(1,5) (16.7%, 58.8%)
07/20 10:17:39 PM | Valid: [24/50] Step 350/390 Loss 9.528 Prec@(1,5) (16.7%, 58.9%)
07/20 10:17:46 PM | Valid: [24/50] Step 390/390 Loss 9.510 Prec@(1,5) (16.8%, 58.9%)
07/20 10:17:46 PM | Valid: [24/50] Final Prec@1 16.8160%
07/20 10:17:46 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1238, 0.1229, 0.1231, 0.1261, 0.1267, 0.1246, 0.1267, 0.1260],
        [0.1224, 0.1224, 0.1224, 0.1263, 0.1266, 0.1264, 0.1265, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1228, 0.1229, 0.1228, 0.1264, 0.1264, 0.1259, 0.1264, 0.1264],
        [0.1223, 0.1219, 0.1221, 0.1265, 0.1266, 0.1265, 0.1269, 0.1272],
        [0.1223, 0.1223, 0.1222, 0.1264, 0.1269, 0.1265, 0.1267, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1223, 0.1224, 0.1259, 0.1269, 0.1267, 0.1261, 0.1271],
        [0.1222, 0.1220, 0.1222, 0.1263, 0.1266, 0.1271, 0.1268, 0.1268],
        [0.1224, 0.1223, 0.1224, 0.1262, 0.1268, 0.1263, 0.1267, 0.1270],
        [0.1223, 0.1222, 0.1222, 0.1262, 0.1268, 0.1270, 0.1266, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1223, 0.1221, 0.1266, 0.1265, 0.1265, 0.1266, 0.1270],
        [0.1223, 0.1224, 0.1224, 0.1262, 0.1267, 0.1267, 0.1263, 0.1270],
        [0.1223, 0.1222, 0.1221, 0.1266, 0.1266, 0.1269, 0.1267, 0.1266],
        [0.1221, 0.1222, 0.1222, 0.1271, 0.1266, 0.1268, 0.1264, 0.1267],
        [0.1223, 0.1223, 0.1223, 0.1266, 0.1263, 0.1268, 0.1267, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1265, 0.1252, 0.1249, 0.1255, 0.1249, 0.1246, 0.1243, 0.1242],
        [0.1236, 0.1228, 0.1254, 0.1258, 0.1257, 0.1256, 0.1254, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1243, 0.1262, 0.1268, 0.1239, 0.1246, 0.1241, 0.1236],
        [0.1235, 0.1229, 0.1262, 0.1260, 0.1263, 0.1258, 0.1239, 0.1254],
        [0.1254, 0.1232, 0.1265, 0.1236, 0.1249, 0.1257, 0.1243, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1246, 0.1252, 0.1245, 0.1248, 0.1262, 0.1241, 0.1238],
        [0.1242, 0.1233, 0.1256, 0.1258, 0.1258, 0.1243, 0.1258, 0.1252],
        [0.1259, 0.1236, 0.1258, 0.1236, 0.1262, 0.1266, 0.1237, 0.1246],
        [0.1243, 0.1233, 0.1253, 0.1244, 0.1258, 0.1249, 0.1260, 0.1260]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1264, 0.1249, 0.1249, 0.1249, 0.1257, 0.1247, 0.1252, 0.1232],
        [0.1235, 0.1227, 0.1246, 0.1250, 0.1256, 0.1263, 0.1266, 0.1256],
        [0.1242, 0.1236, 0.1249, 0.1263, 0.1246, 0.1259, 0.1258, 0.1247],
        [0.1230, 0.1228, 0.1234, 0.1265, 0.1256, 0.1266, 0.1263, 0.1259],
        [0.1231, 0.1230, 0.1240, 0.1258, 0.1264, 0.1249, 0.1258, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:17:51 PM | Train: [25/50] Step 000/001 Loss 0.004 Prec@(1,5) (100.0%, 100.0%)
07/20 10:17:55 PM | Train: [25/50] Step 001/001 Loss 0.232 Prec@(1,5) (88.9%, 100.0%)
07/20 10:17:55 PM | Train: [25/50] Final Prec@1 88.8889%
07/20 10:17:55 PM | Valid: [25/50] Step 000/390 Loss 8.155 Prec@(1,5) (14.1%, 54.7%)
07/20 10:18:05 PM | Valid: [25/50] Step 050/390 Loss 7.799 Prec@(1,5) (17.1%, 60.2%)
07/20 10:18:14 PM | Valid: [25/50] Step 100/390 Loss 7.804 Prec@(1,5) (16.9%, 60.3%)
07/20 10:18:23 PM | Valid: [25/50] Step 150/390 Loss 7.848 Prec@(1,5) (17.0%, 60.3%)
07/20 10:18:32 PM | Valid: [25/50] Step 200/390 Loss 7.860 Prec@(1,5) (16.9%, 60.3%)
07/20 10:18:42 PM | Valid: [25/50] Step 250/390 Loss 7.856 Prec@(1,5) (16.9%, 60.1%)
07/20 10:18:51 PM | Valid: [25/50] Step 300/390 Loss 7.874 Prec@(1,5) (16.8%, 60.0%)
07/20 10:19:00 PM | Valid: [25/50] Step 350/390 Loss 7.867 Prec@(1,5) (17.0%, 60.0%)
07/20 10:19:08 PM | Valid: [25/50] Step 390/390 Loss 7.876 Prec@(1,5) (17.0%, 60.0%)
07/20 10:19:08 PM | Valid: [25/50] Final Prec@1 16.9760%
07/20 10:19:08 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1237, 0.1228, 0.1230, 0.1262, 0.1267, 0.1247, 0.1268, 0.1261],
        [0.1223, 0.1223, 0.1223, 0.1264, 0.1267, 0.1264, 0.1266, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1226, 0.1228, 0.1227, 0.1265, 0.1264, 0.1259, 0.1265, 0.1265],
        [0.1222, 0.1218, 0.1220, 0.1266, 0.1266, 0.1266, 0.1269, 0.1272],
        [0.1222, 0.1222, 0.1221, 0.1264, 0.1270, 0.1265, 0.1268, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1222, 0.1223, 0.1260, 0.1270, 0.1267, 0.1261, 0.1271],
        [0.1220, 0.1219, 0.1221, 0.1264, 0.1267, 0.1271, 0.1269, 0.1269],
        [0.1223, 0.1222, 0.1223, 0.1262, 0.1269, 0.1263, 0.1268, 0.1271],
        [0.1221, 0.1221, 0.1221, 0.1262, 0.1268, 0.1271, 0.1267, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1222, 0.1220, 0.1267, 0.1265, 0.1266, 0.1267, 0.1271],
        [0.1222, 0.1223, 0.1223, 0.1263, 0.1267, 0.1267, 0.1263, 0.1270],
        [0.1222, 0.1221, 0.1220, 0.1266, 0.1266, 0.1269, 0.1268, 0.1267],
        [0.1220, 0.1221, 0.1221, 0.1271, 0.1266, 0.1269, 0.1264, 0.1268],
        [0.1222, 0.1222, 0.1222, 0.1266, 0.1263, 0.1268, 0.1267, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1266, 0.1253, 0.1249, 0.1254, 0.1249, 0.1246, 0.1242, 0.1241],
        [0.1236, 0.1228, 0.1254, 0.1258, 0.1258, 0.1257, 0.1254, 0.1257]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1267, 0.1244, 0.1261, 0.1269, 0.1238, 0.1245, 0.1241, 0.1235],
        [0.1234, 0.1228, 0.1264, 0.1261, 0.1263, 0.1258, 0.1239, 0.1253],
        [0.1254, 0.1232, 0.1265, 0.1236, 0.1249, 0.1257, 0.1243, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1246, 0.1252, 0.1245, 0.1248, 0.1263, 0.1241, 0.1237],
        [0.1241, 0.1232, 0.1257, 0.1257, 0.1257, 0.1244, 0.1258, 0.1253],
        [0.1257, 0.1235, 0.1258, 0.1235, 0.1264, 0.1267, 0.1236, 0.1247],
        [0.1242, 0.1232, 0.1253, 0.1243, 0.1258, 0.1250, 0.1261, 0.1261]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1250, 0.1250, 0.1249, 0.1257, 0.1245, 0.1252, 0.1232],
        [0.1234, 0.1226, 0.1245, 0.1250, 0.1257, 0.1264, 0.1267, 0.1257],
        [0.1241, 0.1235, 0.1249, 0.1264, 0.1246, 0.1259, 0.1258, 0.1248],
        [0.1229, 0.1227, 0.1233, 0.1265, 0.1256, 0.1266, 0.1263, 0.1260],
        [0.1230, 0.1229, 0.1239, 0.1259, 0.1264, 0.1250, 0.1259, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:19:13 PM | Train: [26/50] Step 000/001 Loss 0.016 Prec@(1,5) (100.0%, 100.0%)
07/20 10:19:16 PM | Train: [26/50] Step 001/001 Loss 0.280 Prec@(1,5) (88.9%, 100.0%)
07/20 10:19:16 PM | Train: [26/50] Final Prec@1 88.8889%
07/20 10:19:17 PM | Valid: [26/50] Step 000/390 Loss 9.605 Prec@(1,5) (12.5%, 62.5%)
07/20 10:19:26 PM | Valid: [26/50] Step 050/390 Loss 9.037 Prec@(1,5) (16.5%, 59.8%)
07/20 10:19:36 PM | Valid: [26/50] Step 100/390 Loss 8.866 Prec@(1,5) (17.1%, 60.1%)
07/20 10:19:45 PM | Valid: [26/50] Step 150/390 Loss 8.810 Prec@(1,5) (17.5%, 60.5%)
07/20 10:19:54 PM | Valid: [26/50] Step 200/390 Loss 8.793 Prec@(1,5) (17.5%, 60.7%)
07/20 10:20:03 PM | Valid: [26/50] Step 250/390 Loss 8.744 Prec@(1,5) (17.6%, 61.0%)
07/20 10:20:13 PM | Valid: [26/50] Step 300/390 Loss 8.763 Prec@(1,5) (17.7%, 61.0%)
07/20 10:20:22 PM | Valid: [26/50] Step 350/390 Loss 8.795 Prec@(1,5) (17.6%, 61.0%)
07/20 10:20:29 PM | Valid: [26/50] Step 390/390 Loss 8.830 Prec@(1,5) (17.5%, 60.9%)
07/20 10:20:29 PM | Valid: [26/50] Final Prec@1 17.4760%
07/20 10:20:29 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1237, 0.1227, 0.1229, 0.1263, 0.1268, 0.1246, 0.1268, 0.1262],
        [0.1222, 0.1222, 0.1222, 0.1264, 0.1267, 0.1265, 0.1267, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1225, 0.1227, 0.1226, 0.1266, 0.1265, 0.1260, 0.1266, 0.1266],
        [0.1221, 0.1217, 0.1218, 0.1268, 0.1267, 0.1266, 0.1270, 0.1273],
        [0.1221, 0.1221, 0.1220, 0.1265, 0.1270, 0.1266, 0.1268, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1221, 0.1222, 0.1260, 0.1270, 0.1268, 0.1262, 0.1272],
        [0.1219, 0.1218, 0.1220, 0.1264, 0.1268, 0.1272, 0.1269, 0.1269],
        [0.1222, 0.1221, 0.1221, 0.1262, 0.1270, 0.1264, 0.1269, 0.1271],
        [0.1220, 0.1220, 0.1220, 0.1262, 0.1269, 0.1271, 0.1267, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1221, 0.1219, 0.1267, 0.1266, 0.1267, 0.1268, 0.1272],
        [0.1221, 0.1222, 0.1222, 0.1264, 0.1268, 0.1268, 0.1264, 0.1271],
        [0.1221, 0.1220, 0.1219, 0.1267, 0.1267, 0.1270, 0.1269, 0.1267],
        [0.1219, 0.1220, 0.1220, 0.1272, 0.1267, 0.1270, 0.1265, 0.1268],
        [0.1221, 0.1221, 0.1221, 0.1267, 0.1264, 0.1269, 0.1268, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1267, 0.1253, 0.1250, 0.1254, 0.1249, 0.1245, 0.1241, 0.1242],
        [0.1236, 0.1228, 0.1253, 0.1259, 0.1258, 0.1257, 0.1253, 0.1256]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1243, 0.1262, 0.1270, 0.1238, 0.1245, 0.1240, 0.1234],
        [0.1235, 0.1228, 0.1264, 0.1261, 0.1263, 0.1258, 0.1238, 0.1252],
        [0.1255, 0.1232, 0.1266, 0.1235, 0.1249, 0.1258, 0.1242, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1245, 0.1252, 0.1246, 0.1248, 0.1264, 0.1240, 0.1238],
        [0.1241, 0.1232, 0.1257, 0.1257, 0.1258, 0.1243, 0.1258, 0.1254],
        [0.1257, 0.1234, 0.1259, 0.1234, 0.1265, 0.1268, 0.1236, 0.1247],
        [0.1241, 0.1231, 0.1253, 0.1242, 0.1259, 0.1250, 0.1262, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1250, 0.1250, 0.1249, 0.1257, 0.1245, 0.1253, 0.1231],
        [0.1234, 0.1226, 0.1244, 0.1250, 0.1257, 0.1264, 0.1267, 0.1257],
        [0.1240, 0.1234, 0.1249, 0.1265, 0.1247, 0.1259, 0.1259, 0.1247],
        [0.1228, 0.1226, 0.1232, 0.1266, 0.1258, 0.1267, 0.1264, 0.1260],
        [0.1229, 0.1229, 0.1238, 0.1260, 0.1265, 0.1250, 0.1259, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:20:34 PM | Train: [27/50] Step 000/001 Loss 0.001 Prec@(1,5) (100.0%, 100.0%)
07/20 10:20:38 PM | Train: [27/50] Step 001/001 Loss 0.235 Prec@(1,5) (88.9%, 100.0%)
07/20 10:20:38 PM | Train: [27/50] Final Prec@1 88.8889%
07/20 10:20:38 PM | Valid: [27/50] Step 000/390 Loss 9.842 Prec@(1,5) (14.1%, 62.5%)
07/20 10:20:48 PM | Valid: [27/50] Step 050/390 Loss 9.433 Prec@(1,5) (15.7%, 57.0%)
07/20 10:20:57 PM | Valid: [27/50] Step 100/390 Loss 9.460 Prec@(1,5) (15.6%, 57.5%)
07/20 10:21:06 PM | Valid: [27/50] Step 150/390 Loss 9.367 Prec@(1,5) (15.9%, 57.6%)
07/20 10:21:16 PM | Valid: [27/50] Step 200/390 Loss 9.337 Prec@(1,5) (16.0%, 58.1%)
07/20 10:21:25 PM | Valid: [27/50] Step 250/390 Loss 9.309 Prec@(1,5) (16.2%, 58.6%)
07/20 10:21:35 PM | Valid: [27/50] Step 300/390 Loss 9.301 Prec@(1,5) (16.1%, 58.5%)
07/20 10:21:44 PM | Valid: [27/50] Step 350/390 Loss 9.302 Prec@(1,5) (16.2%, 58.5%)
07/20 10:21:51 PM | Valid: [27/50] Step 390/390 Loss 9.295 Prec@(1,5) (16.2%, 58.6%)
07/20 10:21:51 PM | Valid: [27/50] Final Prec@1 16.1520%
07/20 10:21:51 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1236, 0.1226, 0.1228, 0.1263, 0.1268, 0.1246, 0.1269, 0.1262],
        [0.1221, 0.1221, 0.1221, 0.1265, 0.1267, 0.1265, 0.1268, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1226, 0.1225, 0.1267, 0.1265, 0.1260, 0.1266, 0.1266],
        [0.1220, 0.1216, 0.1217, 0.1269, 0.1267, 0.1267, 0.1271, 0.1273],
        [0.1220, 0.1220, 0.1219, 0.1266, 0.1271, 0.1267, 0.1269, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1220, 0.1221, 0.1261, 0.1271, 0.1269, 0.1262, 0.1272],
        [0.1218, 0.1217, 0.1219, 0.1265, 0.1269, 0.1272, 0.1270, 0.1270],
        [0.1220, 0.1220, 0.1220, 0.1263, 0.1270, 0.1264, 0.1270, 0.1272],
        [0.1219, 0.1219, 0.1219, 0.1263, 0.1270, 0.1272, 0.1268, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1220, 0.1217, 0.1268, 0.1266, 0.1267, 0.1268, 0.1272],
        [0.1220, 0.1221, 0.1221, 0.1264, 0.1269, 0.1269, 0.1265, 0.1272],
        [0.1220, 0.1219, 0.1218, 0.1268, 0.1267, 0.1270, 0.1269, 0.1268],
        [0.1218, 0.1219, 0.1219, 0.1273, 0.1268, 0.1270, 0.1265, 0.1269],
        [0.1220, 0.1220, 0.1220, 0.1268, 0.1265, 0.1269, 0.1268, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1267, 0.1252, 0.1250, 0.1254, 0.1249, 0.1244, 0.1240, 0.1243],
        [0.1236, 0.1227, 0.1254, 0.1259, 0.1259, 0.1257, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1243, 0.1262, 0.1271, 0.1238, 0.1244, 0.1240, 0.1234],
        [0.1235, 0.1228, 0.1265, 0.1261, 0.1264, 0.1258, 0.1237, 0.1252],
        [0.1255, 0.1231, 0.1266, 0.1235, 0.1249, 0.1259, 0.1242, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1244, 0.1251, 0.1245, 0.1249, 0.1264, 0.1240, 0.1238],
        [0.1242, 0.1232, 0.1257, 0.1256, 0.1258, 0.1243, 0.1258, 0.1254],
        [0.1257, 0.1233, 0.1259, 0.1234, 0.1266, 0.1268, 0.1236, 0.1248],
        [0.1241, 0.1231, 0.1253, 0.1242, 0.1260, 0.1250, 0.1262, 0.1262]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1265, 0.1249, 0.1250, 0.1249, 0.1257, 0.1245, 0.1254, 0.1231],
        [0.1234, 0.1226, 0.1244, 0.1250, 0.1257, 0.1264, 0.1267, 0.1257],
        [0.1239, 0.1234, 0.1248, 0.1265, 0.1247, 0.1259, 0.1260, 0.1248],
        [0.1227, 0.1225, 0.1231, 0.1266, 0.1258, 0.1267, 0.1265, 0.1261],
        [0.1228, 0.1228, 0.1237, 0.1260, 0.1265, 0.1251, 0.1260, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:21:56 PM | Train: [28/50] Step 000/001 Loss 0.001 Prec@(1,5) (100.0%, 100.0%)
07/20 10:22:00 PM | Train: [28/50] Step 001/001 Loss 0.226 Prec@(1,5) (88.9%, 100.0%)
07/20 10:22:00 PM | Train: [28/50] Final Prec@1 88.8889%
07/20 10:22:00 PM | Valid: [28/50] Step 000/390 Loss 8.605 Prec@(1,5) (15.6%, 57.8%)
07/20 10:22:10 PM | Valid: [28/50] Step 050/390 Loss 8.506 Prec@(1,5) (16.9%, 58.5%)
07/20 10:22:19 PM | Valid: [28/50] Step 100/390 Loss 8.423 Prec@(1,5) (17.0%, 59.2%)
07/20 10:22:28 PM | Valid: [28/50] Step 150/390 Loss 8.400 Prec@(1,5) (16.6%, 59.5%)
07/20 10:22:38 PM | Valid: [28/50] Step 200/390 Loss 8.372 Prec@(1,5) (16.9%, 59.3%)
07/20 10:22:47 PM | Valid: [28/50] Step 250/390 Loss 8.376 Prec@(1,5) (16.8%, 59.2%)
07/20 10:22:56 PM | Valid: [28/50] Step 300/390 Loss 8.380 Prec@(1,5) (16.8%, 59.3%)
07/20 10:23:06 PM | Valid: [28/50] Step 350/390 Loss 8.398 Prec@(1,5) (16.9%, 59.0%)
07/20 10:23:13 PM | Valid: [28/50] Step 390/390 Loss 8.404 Prec@(1,5) (16.9%, 59.0%)
07/20 10:23:13 PM | Valid: [28/50] Final Prec@1 16.8960%
07/20 10:23:13 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1235, 0.1225, 0.1228, 0.1264, 0.1270, 0.1246, 0.1269, 0.1263],
        [0.1220, 0.1220, 0.1220, 0.1265, 0.1268, 0.1265, 0.1269, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1224, 0.1225, 0.1224, 0.1268, 0.1265, 0.1261, 0.1266, 0.1267],
        [0.1218, 0.1215, 0.1216, 0.1269, 0.1268, 0.1268, 0.1272, 0.1274],
        [0.1219, 0.1219, 0.1218, 0.1266, 0.1272, 0.1268, 0.1269, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1219, 0.1220, 0.1261, 0.1272, 0.1270, 0.1263, 0.1273],
        [0.1217, 0.1216, 0.1218, 0.1266, 0.1269, 0.1273, 0.1270, 0.1271],
        [0.1219, 0.1219, 0.1219, 0.1263, 0.1271, 0.1265, 0.1271, 0.1273],
        [0.1218, 0.1218, 0.1218, 0.1264, 0.1271, 0.1272, 0.1268, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1218, 0.1216, 0.1268, 0.1267, 0.1268, 0.1269, 0.1273],
        [0.1219, 0.1220, 0.1220, 0.1264, 0.1269, 0.1269, 0.1265, 0.1273],
        [0.1219, 0.1218, 0.1217, 0.1269, 0.1268, 0.1271, 0.1270, 0.1269],
        [0.1217, 0.1218, 0.1218, 0.1273, 0.1269, 0.1271, 0.1266, 0.1270],
        [0.1219, 0.1219, 0.1219, 0.1268, 0.1265, 0.1270, 0.1269, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1268, 0.1252, 0.1250, 0.1255, 0.1249, 0.1244, 0.1240, 0.1243],
        [0.1236, 0.1227, 0.1254, 0.1259, 0.1259, 0.1258, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1243, 0.1262, 0.1271, 0.1238, 0.1243, 0.1241, 0.1233],
        [0.1235, 0.1228, 0.1266, 0.1262, 0.1264, 0.1258, 0.1236, 0.1252],
        [0.1256, 0.1231, 0.1267, 0.1234, 0.1249, 0.1258, 0.1241, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1244, 0.1250, 0.1245, 0.1249, 0.1265, 0.1241, 0.1238],
        [0.1242, 0.1232, 0.1258, 0.1256, 0.1258, 0.1242, 0.1258, 0.1254],
        [0.1256, 0.1232, 0.1259, 0.1233, 0.1266, 0.1269, 0.1235, 0.1248],
        [0.1241, 0.1230, 0.1254, 0.1241, 0.1260, 0.1249, 0.1262, 0.1263]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1248, 0.1250, 0.1248, 0.1258, 0.1245, 0.1254, 0.1231],
        [0.1234, 0.1225, 0.1244, 0.1251, 0.1258, 0.1264, 0.1268, 0.1257],
        [0.1239, 0.1233, 0.1248, 0.1265, 0.1247, 0.1259, 0.1261, 0.1247],
        [0.1226, 0.1224, 0.1230, 0.1266, 0.1259, 0.1268, 0.1266, 0.1262],
        [0.1227, 0.1227, 0.1236, 0.1260, 0.1266, 0.1251, 0.1260, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:23:18 PM | Train: [29/50] Step 000/001 Loss 0.031 Prec@(1,5) (100.0%, 100.0%)
07/20 10:23:24 PM | Train: [29/50] Step 001/001 Loss 0.298 Prec@(1,5) (88.9%, 100.0%)
07/20 10:23:24 PM | Train: [29/50] Final Prec@1 88.8889%
07/20 10:23:24 PM | Valid: [29/50] Step 000/390 Loss 6.490 Prec@(1,5) (23.4%, 57.8%)
07/20 10:23:34 PM | Valid: [29/50] Step 050/390 Loss 7.778 Prec@(1,5) (18.0%, 59.7%)
07/20 10:23:43 PM | Valid: [29/50] Step 100/390 Loss 7.753 Prec@(1,5) (17.6%, 59.0%)
07/20 10:23:52 PM | Valid: [29/50] Step 150/390 Loss 7.682 Prec@(1,5) (17.6%, 59.2%)
07/20 10:24:02 PM | Valid: [29/50] Step 200/390 Loss 7.658 Prec@(1,5) (17.7%, 59.4%)
07/20 10:24:12 PM | Valid: [29/50] Step 250/390 Loss 7.700 Prec@(1,5) (17.5%, 59.3%)
07/20 10:24:22 PM | Valid: [29/50] Step 300/390 Loss 7.689 Prec@(1,5) (17.5%, 59.3%)
07/20 10:24:31 PM | Valid: [29/50] Step 350/390 Loss 7.668 Prec@(1,5) (17.5%, 59.2%)
07/20 10:24:39 PM | Valid: [29/50] Step 390/390 Loss 7.661 Prec@(1,5) (17.5%, 59.2%)
07/20 10:24:39 PM | Valid: [29/50] Final Prec@1 17.5000%
07/20 10:24:39 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1234, 0.1224, 0.1226, 0.1264, 0.1271, 0.1247, 0.1270, 0.1264],
        [0.1219, 0.1219, 0.1219, 0.1265, 0.1268, 0.1266, 0.1269, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1223, 0.1224, 0.1223, 0.1268, 0.1265, 0.1262, 0.1267, 0.1268],
        [0.1217, 0.1214, 0.1215, 0.1269, 0.1269, 0.1269, 0.1272, 0.1275],
        [0.1218, 0.1218, 0.1217, 0.1267, 0.1272, 0.1268, 0.1270, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1218, 0.1219, 0.1261, 0.1273, 0.1270, 0.1264, 0.1274],
        [0.1216, 0.1215, 0.1216, 0.1266, 0.1270, 0.1274, 0.1271, 0.1272],
        [0.1218, 0.1218, 0.1218, 0.1264, 0.1271, 0.1266, 0.1271, 0.1274],
        [0.1217, 0.1217, 0.1216, 0.1265, 0.1272, 0.1273, 0.1269, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1219, 0.1217, 0.1215, 0.1269, 0.1268, 0.1268, 0.1270, 0.1274],
        [0.1218, 0.1218, 0.1219, 0.1264, 0.1270, 0.1270, 0.1266, 0.1273],
        [0.1218, 0.1217, 0.1216, 0.1270, 0.1269, 0.1271, 0.1270, 0.1269],
        [0.1216, 0.1217, 0.1216, 0.1274, 0.1270, 0.1272, 0.1266, 0.1270],
        [0.1218, 0.1218, 0.1218, 0.1269, 0.1266, 0.1271, 0.1270, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1269, 0.1252, 0.1251, 0.1255, 0.1248, 0.1243, 0.1239, 0.1243],
        [0.1235, 0.1226, 0.1253, 0.1260, 0.1259, 0.1258, 0.1254, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1243, 0.1261, 0.1272, 0.1239, 0.1242, 0.1241, 0.1232],
        [0.1235, 0.1227, 0.1267, 0.1262, 0.1264, 0.1258, 0.1236, 0.1252],
        [0.1255, 0.1230, 0.1268, 0.1234, 0.1249, 0.1258, 0.1240, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1243, 0.1250, 0.1244, 0.1249, 0.1265, 0.1241, 0.1238],
        [0.1242, 0.1231, 0.1258, 0.1256, 0.1258, 0.1242, 0.1258, 0.1254],
        [0.1256, 0.1231, 0.1260, 0.1233, 0.1267, 0.1270, 0.1235, 0.1248],
        [0.1241, 0.1229, 0.1254, 0.1240, 0.1260, 0.1248, 0.1263, 0.1264]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1248, 0.1250, 0.1249, 0.1258, 0.1245, 0.1254, 0.1230],
        [0.1233, 0.1224, 0.1245, 0.1252, 0.1258, 0.1263, 0.1268, 0.1257],
        [0.1238, 0.1232, 0.1248, 0.1265, 0.1248, 0.1260, 0.1261, 0.1248],
        [0.1225, 0.1223, 0.1229, 0.1267, 0.1260, 0.1268, 0.1266, 0.1262],
        [0.1227, 0.1226, 0.1236, 0.1261, 0.1266, 0.1252, 0.1260, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:24:44 PM | Train: [30/50] Step 000/001 Loss 0.127 Prec@(1,5) (87.5%, 100.0%)
07/20 10:24:47 PM | Train: [30/50] Step 001/001 Loss 0.397 Prec@(1,5) (77.8%, 88.9%)
07/20 10:24:47 PM | Train: [30/50] Final Prec@1 77.7778%
07/20 10:24:48 PM | Valid: [30/50] Step 000/390 Loss 10.245 Prec@(1,5) (14.1%, 59.4%)
07/20 10:25:00 PM | Valid: [30/50] Step 050/390 Loss 8.821 Prec@(1,5) (16.2%, 58.5%)
07/20 10:25:12 PM | Valid: [30/50] Step 100/390 Loss 8.835 Prec@(1,5) (16.2%, 58.5%)
07/20 10:25:23 PM | Valid: [30/50] Step 150/390 Loss 8.854 Prec@(1,5) (16.0%, 58.2%)
07/20 10:25:35 PM | Valid: [30/50] Step 200/390 Loss 8.872 Prec@(1,5) (15.8%, 58.3%)
07/20 10:25:47 PM | Valid: [30/50] Step 250/390 Loss 8.888 Prec@(1,5) (15.8%, 58.2%)
07/20 10:25:59 PM | Valid: [30/50] Step 300/390 Loss 8.876 Prec@(1,5) (15.9%, 58.0%)
07/20 10:26:11 PM | Valid: [30/50] Step 350/390 Loss 8.858 Prec@(1,5) (16.0%, 58.2%)
07/20 10:26:18 PM | Valid: [30/50] Step 390/390 Loss 8.852 Prec@(1,5) (16.1%, 58.3%)
07/20 10:26:18 PM | Valid: [30/50] Final Prec@1 16.1160%
07/20 10:26:18 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1223, 0.1225, 0.1265, 0.1271, 0.1247, 0.1271, 0.1264],
        [0.1218, 0.1218, 0.1218, 0.1266, 0.1269, 0.1267, 0.1269, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1222, 0.1223, 0.1222, 0.1269, 0.1266, 0.1262, 0.1267, 0.1269],
        [0.1216, 0.1212, 0.1214, 0.1270, 0.1269, 0.1269, 0.1273, 0.1276],
        [0.1217, 0.1217, 0.1216, 0.1267, 0.1272, 0.1269, 0.1271, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1217, 0.1218, 0.1262, 0.1273, 0.1271, 0.1265, 0.1275],
        [0.1215, 0.1214, 0.1215, 0.1267, 0.1271, 0.1275, 0.1271, 0.1272],
        [0.1217, 0.1216, 0.1217, 0.1265, 0.1272, 0.1266, 0.1272, 0.1275],
        [0.1216, 0.1216, 0.1215, 0.1265, 0.1273, 0.1274, 0.1270, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1218, 0.1216, 0.1214, 0.1270, 0.1269, 0.1269, 0.1270, 0.1274],
        [0.1217, 0.1217, 0.1218, 0.1265, 0.1271, 0.1271, 0.1267, 0.1274],
        [0.1217, 0.1216, 0.1215, 0.1271, 0.1269, 0.1272, 0.1270, 0.1270],
        [0.1214, 0.1216, 0.1215, 0.1274, 0.1270, 0.1272, 0.1267, 0.1271],
        [0.1217, 0.1217, 0.1217, 0.1270, 0.1266, 0.1271, 0.1270, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1270, 0.1253, 0.1252, 0.1255, 0.1247, 0.1243, 0.1238, 0.1243],
        [0.1235, 0.1226, 0.1253, 0.1260, 0.1260, 0.1259, 0.1254, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1244, 0.1260, 0.1273, 0.1239, 0.1242, 0.1240, 0.1232],
        [0.1234, 0.1227, 0.1267, 0.1263, 0.1264, 0.1258, 0.1235, 0.1252],
        [0.1255, 0.1230, 0.1269, 0.1233, 0.1250, 0.1258, 0.1240, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1243, 0.1249, 0.1243, 0.1250, 0.1266, 0.1241, 0.1237],
        [0.1242, 0.1231, 0.1258, 0.1257, 0.1258, 0.1242, 0.1258, 0.1255],
        [0.1256, 0.1230, 0.1260, 0.1232, 0.1268, 0.1271, 0.1234, 0.1249],
        [0.1240, 0.1229, 0.1255, 0.1240, 0.1261, 0.1248, 0.1263, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1266, 0.1248, 0.1250, 0.1249, 0.1258, 0.1244, 0.1254, 0.1229],
        [0.1232, 0.1224, 0.1244, 0.1252, 0.1259, 0.1264, 0.1269, 0.1257],
        [0.1237, 0.1232, 0.1248, 0.1266, 0.1248, 0.1260, 0.1262, 0.1248],
        [0.1224, 0.1223, 0.1228, 0.1268, 0.1261, 0.1268, 0.1266, 0.1262],
        [0.1226, 0.1225, 0.1235, 0.1261, 0.1266, 0.1252, 0.1261, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:26:23 PM | Train: [31/50] Step 000/001 Loss 0.003 Prec@(1,5) (100.0%, 100.0%)
07/20 10:26:26 PM | Train: [31/50] Step 001/001 Loss 0.271 Prec@(1,5) (88.9%, 100.0%)
07/20 10:26:26 PM | Train: [31/50] Final Prec@1 88.8889%
07/20 10:26:27 PM | Valid: [31/50] Step 000/390 Loss 5.802 Prec@(1,5) (32.8%, 64.1%)
07/20 10:26:36 PM | Valid: [31/50] Step 050/390 Loss 7.173 Prec@(1,5) (18.7%, 56.8%)
07/20 10:26:46 PM | Valid: [31/50] Step 100/390 Loss 7.207 Prec@(1,5) (18.1%, 56.8%)
07/20 10:26:55 PM | Valid: [31/50] Step 150/390 Loss 7.183 Prec@(1,5) (17.9%, 57.0%)
07/20 10:27:04 PM | Valid: [31/50] Step 200/390 Loss 7.115 Prec@(1,5) (18.1%, 57.1%)
07/20 10:27:14 PM | Valid: [31/50] Step 250/390 Loss 7.094 Prec@(1,5) (18.2%, 57.0%)
07/20 10:27:23 PM | Valid: [31/50] Step 300/390 Loss 7.103 Prec@(1,5) (18.2%, 57.0%)
07/20 10:27:33 PM | Valid: [31/50] Step 350/390 Loss 7.103 Prec@(1,5) (18.4%, 56.8%)
07/20 10:27:40 PM | Valid: [31/50] Step 390/390 Loss 7.100 Prec@(1,5) (18.4%, 56.8%)
07/20 10:27:41 PM | Valid: [31/50] Final Prec@1 18.3600%
07/20 10:27:41 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1222, 0.1225, 0.1266, 0.1271, 0.1246, 0.1272, 0.1265],
        [0.1218, 0.1217, 0.1217, 0.1266, 0.1269, 0.1268, 0.1270, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1221, 0.1222, 0.1221, 0.1270, 0.1266, 0.1263, 0.1268, 0.1269],
        [0.1215, 0.1212, 0.1213, 0.1271, 0.1270, 0.1269, 0.1274, 0.1276],
        [0.1217, 0.1216, 0.1215, 0.1268, 0.1272, 0.1269, 0.1271, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1219, 0.1216, 0.1216, 0.1262, 0.1274, 0.1271, 0.1266, 0.1276],
        [0.1214, 0.1213, 0.1214, 0.1268, 0.1271, 0.1275, 0.1272, 0.1273],
        [0.1216, 0.1215, 0.1216, 0.1266, 0.1273, 0.1267, 0.1273, 0.1275],
        [0.1215, 0.1215, 0.1214, 0.1266, 0.1274, 0.1274, 0.1270, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1217, 0.1216, 0.1213, 0.1271, 0.1269, 0.1269, 0.1270, 0.1275],
        [0.1216, 0.1216, 0.1217, 0.1266, 0.1271, 0.1271, 0.1267, 0.1275],
        [0.1216, 0.1215, 0.1213, 0.1272, 0.1270, 0.1272, 0.1271, 0.1271],
        [0.1213, 0.1214, 0.1214, 0.1275, 0.1271, 0.1273, 0.1268, 0.1271],
        [0.1216, 0.1216, 0.1216, 0.1271, 0.1267, 0.1272, 0.1271, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1253, 0.1252, 0.1255, 0.1247, 0.1242, 0.1238, 0.1242],
        [0.1234, 0.1225, 0.1253, 0.1261, 0.1261, 0.1259, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1244, 0.1259, 0.1273, 0.1239, 0.1243, 0.1240, 0.1231],
        [0.1234, 0.1226, 0.1268, 0.1262, 0.1264, 0.1259, 0.1234, 0.1252],
        [0.1255, 0.1229, 0.1269, 0.1233, 0.1251, 0.1259, 0.1239, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1243, 0.1250, 0.1243, 0.1250, 0.1267, 0.1240, 0.1237],
        [0.1241, 0.1230, 0.1257, 0.1257, 0.1258, 0.1243, 0.1259, 0.1254],
        [0.1256, 0.1230, 0.1261, 0.1231, 0.1269, 0.1271, 0.1234, 0.1249],
        [0.1240, 0.1228, 0.1255, 0.1240, 0.1261, 0.1248, 0.1264, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1267, 0.1249, 0.1251, 0.1250, 0.1258, 0.1243, 0.1254, 0.1229],
        [0.1232, 0.1223, 0.1245, 0.1253, 0.1259, 0.1264, 0.1269, 0.1257],
        [0.1237, 0.1232, 0.1248, 0.1266, 0.1248, 0.1260, 0.1261, 0.1248],
        [0.1224, 0.1222, 0.1228, 0.1268, 0.1262, 0.1268, 0.1266, 0.1262],
        [0.1225, 0.1225, 0.1235, 0.1261, 0.1266, 0.1252, 0.1261, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:27:45 PM | Train: [32/50] Step 000/001 Loss 0.006 Prec@(1,5) (100.0%, 100.0%)
07/20 10:27:49 PM | Train: [32/50] Step 001/001 Loss 0.288 Prec@(1,5) (88.9%, 88.9%)
07/20 10:27:49 PM | Train: [32/50] Final Prec@1 88.8889%
07/20 10:27:49 PM | Valid: [32/50] Step 000/390 Loss 9.775 Prec@(1,5) (10.9%, 64.1%)
07/20 10:27:58 PM | Valid: [32/50] Step 050/390 Loss 8.908 Prec@(1,5) (15.5%, 56.2%)
07/20 10:28:08 PM | Valid: [32/50] Step 100/390 Loss 8.877 Prec@(1,5) (15.4%, 57.0%)
07/20 10:28:17 PM | Valid: [32/50] Step 150/390 Loss 8.806 Prec@(1,5) (15.9%, 57.3%)
07/20 10:28:26 PM | Valid: [32/50] Step 200/390 Loss 8.807 Prec@(1,5) (15.9%, 57.5%)
07/20 10:28:36 PM | Valid: [32/50] Step 250/390 Loss 8.778 Prec@(1,5) (15.9%, 57.6%)
07/20 10:28:45 PM | Valid: [32/50] Step 300/390 Loss 8.793 Prec@(1,5) (16.0%, 57.5%)
07/20 10:28:54 PM | Valid: [32/50] Step 350/390 Loss 8.790 Prec@(1,5) (15.9%, 57.5%)
07/20 10:29:01 PM | Valid: [32/50] Step 390/390 Loss 8.768 Prec@(1,5) (16.0%, 57.5%)
07/20 10:29:02 PM | Valid: [32/50] Final Prec@1 15.9640%
07/20 10:29:02 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1222, 0.1224, 0.1267, 0.1272, 0.1245, 0.1272, 0.1266],
        [0.1217, 0.1216, 0.1216, 0.1267, 0.1270, 0.1269, 0.1270, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1220, 0.1221, 0.1220, 0.1270, 0.1267, 0.1263, 0.1268, 0.1270],
        [0.1215, 0.1211, 0.1212, 0.1271, 0.1271, 0.1270, 0.1274, 0.1277],
        [0.1216, 0.1215, 0.1214, 0.1269, 0.1273, 0.1270, 0.1272, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1218, 0.1215, 0.1215, 0.1262, 0.1275, 0.1272, 0.1267, 0.1277],
        [0.1213, 0.1212, 0.1213, 0.1269, 0.1272, 0.1276, 0.1272, 0.1274],
        [0.1215, 0.1214, 0.1215, 0.1267, 0.1274, 0.1267, 0.1273, 0.1276],
        [0.1213, 0.1213, 0.1213, 0.1266, 0.1274, 0.1275, 0.1271, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1216, 0.1215, 0.1212, 0.1272, 0.1269, 0.1270, 0.1271, 0.1276],
        [0.1215, 0.1215, 0.1216, 0.1267, 0.1271, 0.1272, 0.1268, 0.1276],
        [0.1215, 0.1214, 0.1212, 0.1272, 0.1271, 0.1273, 0.1272, 0.1271],
        [0.1212, 0.1213, 0.1213, 0.1275, 0.1272, 0.1273, 0.1268, 0.1272],
        [0.1215, 0.1215, 0.1215, 0.1271, 0.1268, 0.1272, 0.1271, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1253, 0.1253, 0.1256, 0.1247, 0.1241, 0.1238, 0.1242],
        [0.1234, 0.1224, 0.1253, 0.1261, 0.1261, 0.1260, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1244, 0.1259, 0.1274, 0.1238, 0.1243, 0.1240, 0.1231],
        [0.1233, 0.1226, 0.1268, 0.1262, 0.1265, 0.1259, 0.1234, 0.1252],
        [0.1255, 0.1229, 0.1269, 0.1233, 0.1251, 0.1259, 0.1238, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1242, 0.1251, 0.1243, 0.1250, 0.1268, 0.1239, 0.1237],
        [0.1241, 0.1230, 0.1257, 0.1258, 0.1258, 0.1243, 0.1259, 0.1254],
        [0.1256, 0.1229, 0.1261, 0.1230, 0.1270, 0.1272, 0.1233, 0.1249],
        [0.1239, 0.1227, 0.1255, 0.1240, 0.1261, 0.1248, 0.1264, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1248, 0.1252, 0.1250, 0.1258, 0.1243, 0.1254, 0.1228],
        [0.1231, 0.1222, 0.1245, 0.1252, 0.1259, 0.1264, 0.1270, 0.1257],
        [0.1237, 0.1231, 0.1249, 0.1267, 0.1248, 0.1260, 0.1260, 0.1249],
        [0.1223, 0.1222, 0.1228, 0.1269, 0.1263, 0.1268, 0.1266, 0.1262],
        [0.1225, 0.1224, 0.1235, 0.1262, 0.1266, 0.1252, 0.1262, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:29:06 PM | Train: [33/50] Step 000/001 Loss 0.008 Prec@(1,5) (100.0%, 100.0%)
07/20 10:29:09 PM | Train: [33/50] Step 001/001 Loss 0.271 Prec@(1,5) (88.9%, 100.0%)
07/20 10:29:10 PM | Train: [33/50] Final Prec@1 88.8889%
07/20 10:29:10 PM | Valid: [33/50] Step 000/390 Loss 6.374 Prec@(1,5) (28.1%, 54.7%)
07/20 10:29:19 PM | Valid: [33/50] Step 050/390 Loss 6.465 Prec@(1,5) (19.1%, 57.3%)
07/20 10:29:29 PM | Valid: [33/50] Step 100/390 Loss 6.404 Prec@(1,5) (18.4%, 58.8%)
07/20 10:29:38 PM | Valid: [33/50] Step 150/390 Loss 6.429 Prec@(1,5) (18.8%, 58.7%)
07/20 10:29:47 PM | Valid: [33/50] Step 200/390 Loss 6.475 Prec@(1,5) (18.3%, 58.4%)
07/20 10:29:57 PM | Valid: [33/50] Step 250/390 Loss 6.516 Prec@(1,5) (18.2%, 58.1%)
07/20 10:30:06 PM | Valid: [33/50] Step 300/390 Loss 6.526 Prec@(1,5) (18.1%, 58.1%)
07/20 10:30:15 PM | Valid: [33/50] Step 350/390 Loss 6.516 Prec@(1,5) (18.1%, 58.2%)
07/20 10:30:22 PM | Valid: [33/50] Step 390/390 Loss 6.538 Prec@(1,5) (18.1%, 58.4%)
07/20 10:30:22 PM | Valid: [33/50] Final Prec@1 18.1280%
07/20 10:30:22 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1233, 0.1221, 0.1224, 0.1268, 0.1272, 0.1244, 0.1273, 0.1266],
        [0.1215, 0.1215, 0.1215, 0.1267, 0.1270, 0.1270, 0.1271, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1219, 0.1221, 0.1220, 0.1271, 0.1267, 0.1263, 0.1269, 0.1270],
        [0.1213, 0.1210, 0.1211, 0.1272, 0.1272, 0.1271, 0.1274, 0.1277],
        [0.1215, 0.1214, 0.1213, 0.1271, 0.1273, 0.1270, 0.1272, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1217, 0.1214, 0.1214, 0.1262, 0.1276, 0.1272, 0.1268, 0.1277],
        [0.1212, 0.1210, 0.1212, 0.1269, 0.1272, 0.1277, 0.1273, 0.1275],
        [0.1214, 0.1213, 0.1214, 0.1267, 0.1274, 0.1268, 0.1274, 0.1277],
        [0.1212, 0.1212, 0.1212, 0.1267, 0.1275, 0.1275, 0.1272, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1215, 0.1214, 0.1212, 0.1272, 0.1269, 0.1270, 0.1271, 0.1276],
        [0.1214, 0.1214, 0.1215, 0.1268, 0.1272, 0.1272, 0.1268, 0.1276],
        [0.1214, 0.1213, 0.1211, 0.1273, 0.1271, 0.1273, 0.1273, 0.1272],
        [0.1211, 0.1212, 0.1212, 0.1276, 0.1272, 0.1274, 0.1269, 0.1273],
        [0.1213, 0.1213, 0.1214, 0.1272, 0.1269, 0.1273, 0.1272, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1253, 0.1253, 0.1257, 0.1247, 0.1240, 0.1237, 0.1243],
        [0.1233, 0.1223, 0.1254, 0.1261, 0.1262, 0.1261, 0.1253, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1243, 0.1259, 0.1274, 0.1238, 0.1244, 0.1240, 0.1230],
        [0.1233, 0.1225, 0.1268, 0.1262, 0.1266, 0.1260, 0.1234, 0.1252],
        [0.1255, 0.1228, 0.1269, 0.1233, 0.1250, 0.1260, 0.1238, 0.1265]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1242, 0.1252, 0.1242, 0.1250, 0.1269, 0.1238, 0.1237],
        [0.1241, 0.1229, 0.1255, 0.1260, 0.1257, 0.1244, 0.1259, 0.1255],
        [0.1256, 0.1229, 0.1261, 0.1230, 0.1271, 0.1273, 0.1233, 0.1248],
        [0.1239, 0.1227, 0.1255, 0.1240, 0.1260, 0.1248, 0.1265, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1248, 0.1252, 0.1251, 0.1258, 0.1242, 0.1254, 0.1227],
        [0.1230, 0.1221, 0.1245, 0.1252, 0.1260, 0.1265, 0.1270, 0.1257],
        [0.1237, 0.1230, 0.1248, 0.1267, 0.1249, 0.1260, 0.1260, 0.1249],
        [0.1222, 0.1221, 0.1227, 0.1270, 0.1264, 0.1268, 0.1266, 0.1263],
        [0.1224, 0.1223, 0.1234, 0.1263, 0.1267, 0.1253, 0.1262, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:30:27 PM | Train: [34/50] Step 000/001 Loss 0.013 Prec@(1,5) (100.0%, 100.0%)
07/20 10:30:30 PM | Train: [34/50] Step 001/001 Loss 0.291 Prec@(1,5) (88.9%, 88.9%)
07/20 10:30:31 PM | Train: [34/50] Final Prec@1 88.8889%
07/20 10:30:31 PM | Valid: [34/50] Step 000/390 Loss 8.391 Prec@(1,5) (23.4%, 60.9%)
07/20 10:30:40 PM | Valid: [34/50] Step 050/390 Loss 8.409 Prec@(1,5) (16.8%, 59.0%)
07/20 10:30:50 PM | Valid: [34/50] Step 100/390 Loss 8.407 Prec@(1,5) (16.6%, 58.8%)
07/20 10:30:59 PM | Valid: [34/50] Step 150/390 Loss 8.414 Prec@(1,5) (16.5%, 58.7%)
07/20 10:31:09 PM | Valid: [34/50] Step 200/390 Loss 8.483 Prec@(1,5) (16.1%, 58.2%)
07/20 10:31:19 PM | Valid: [34/50] Step 250/390 Loss 8.582 Prec@(1,5) (15.7%, 57.7%)
07/20 10:31:28 PM | Valid: [34/50] Step 300/390 Loss 8.599 Prec@(1,5) (15.7%, 57.7%)
07/20 10:31:38 PM | Valid: [34/50] Step 350/390 Loss 8.588 Prec@(1,5) (15.8%, 57.9%)
07/20 10:31:46 PM | Valid: [34/50] Step 390/390 Loss 8.584 Prec@(1,5) (15.8%, 57.9%)
07/20 10:31:46 PM | Valid: [34/50] Final Prec@1 15.8080%
07/20 10:31:46 PM | genotype = Genotype(normal=[[('dil_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1232, 0.1221, 0.1223, 0.1269, 0.1273, 0.1243, 0.1273, 0.1266],
        [0.1214, 0.1214, 0.1214, 0.1268, 0.1271, 0.1271, 0.1271, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1218, 0.1220, 0.1219, 0.1272, 0.1267, 0.1264, 0.1269, 0.1271],
        [0.1212, 0.1208, 0.1210, 0.1273, 0.1273, 0.1271, 0.1275, 0.1278],
        [0.1213, 0.1213, 0.1212, 0.1272, 0.1274, 0.1271, 0.1273, 0.1273]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1216, 0.1213, 0.1213, 0.1263, 0.1277, 0.1272, 0.1268, 0.1278],
        [0.1210, 0.1209, 0.1211, 0.1270, 0.1273, 0.1277, 0.1274, 0.1275],
        [0.1213, 0.1212, 0.1213, 0.1267, 0.1275, 0.1268, 0.1274, 0.1278],
        [0.1211, 0.1211, 0.1211, 0.1267, 0.1276, 0.1276, 0.1272, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1214, 0.1213, 0.1211, 0.1273, 0.1269, 0.1271, 0.1272, 0.1277],
        [0.1213, 0.1213, 0.1214, 0.1268, 0.1273, 0.1273, 0.1269, 0.1277],
        [0.1212, 0.1212, 0.1210, 0.1274, 0.1272, 0.1274, 0.1274, 0.1273],
        [0.1210, 0.1211, 0.1211, 0.1276, 0.1273, 0.1274, 0.1270, 0.1274],
        [0.1212, 0.1212, 0.1213, 0.1272, 0.1270, 0.1274, 0.1273, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1252, 0.1255, 0.1257, 0.1247, 0.1238, 0.1238, 0.1243],
        [0.1231, 0.1222, 0.1254, 0.1262, 0.1263, 0.1262, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1242, 0.1259, 0.1275, 0.1237, 0.1245, 0.1240, 0.1230],
        [0.1232, 0.1224, 0.1268, 0.1263, 0.1267, 0.1261, 0.1233, 0.1253],
        [0.1255, 0.1228, 0.1270, 0.1233, 0.1249, 0.1261, 0.1238, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1242, 0.1253, 0.1241, 0.1249, 0.1270, 0.1237, 0.1236],
        [0.1240, 0.1229, 0.1255, 0.1261, 0.1257, 0.1244, 0.1259, 0.1255],
        [0.1257, 0.1228, 0.1262, 0.1228, 0.1272, 0.1273, 0.1233, 0.1247],
        [0.1239, 0.1226, 0.1255, 0.1241, 0.1260, 0.1248, 0.1265, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1247, 0.1252, 0.1252, 0.1259, 0.1242, 0.1254, 0.1227],
        [0.1228, 0.1220, 0.1245, 0.1253, 0.1261, 0.1266, 0.1271, 0.1257],
        [0.1236, 0.1229, 0.1248, 0.1268, 0.1249, 0.1261, 0.1261, 0.1249],
        [0.1221, 0.1220, 0.1226, 0.1271, 0.1265, 0.1268, 0.1266, 0.1263],
        [0.1223, 0.1222, 0.1233, 0.1264, 0.1267, 0.1254, 0.1262, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:31:51 PM | Train: [35/50] Step 000/001 Loss 0.151 Prec@(1,5) (100.0%, 100.0%)
07/20 10:31:54 PM | Train: [35/50] Step 001/001 Loss 0.399 Prec@(1,5) (88.9%, 100.0%)
07/20 10:31:54 PM | Train: [35/50] Final Prec@1 88.8889%
07/20 10:31:55 PM | Valid: [35/50] Step 000/390 Loss 8.252 Prec@(1,5) (21.9%, 50.0%)
07/20 10:32:04 PM | Valid: [35/50] Step 050/390 Loss 8.735 Prec@(1,5) (16.8%, 55.9%)
07/20 10:32:13 PM | Valid: [35/50] Step 100/390 Loss 8.744 Prec@(1,5) (16.8%, 56.1%)
07/20 10:32:22 PM | Valid: [35/50] Step 150/390 Loss 8.737 Prec@(1,5) (17.0%, 56.4%)
07/20 10:32:32 PM | Valid: [35/50] Step 200/390 Loss 8.745 Prec@(1,5) (17.1%, 57.0%)
07/20 10:32:41 PM | Valid: [35/50] Step 250/390 Loss 8.703 Prec@(1,5) (17.1%, 57.3%)
07/20 10:32:50 PM | Valid: [35/50] Step 300/390 Loss 8.733 Prec@(1,5) (16.9%, 57.2%)
07/20 10:32:59 PM | Valid: [35/50] Step 350/390 Loss 8.715 Prec@(1,5) (16.7%, 57.2%)
07/20 10:33:07 PM | Valid: [35/50] Step 390/390 Loss 8.719 Prec@(1,5) (16.6%, 57.2%)
07/20 10:33:07 PM | Valid: [35/50] Final Prec@1 16.5680%
07/20 10:33:07 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1231, 0.1220, 0.1222, 0.1270, 0.1274, 0.1243, 0.1273, 0.1268],
        [0.1213, 0.1213, 0.1213, 0.1268, 0.1272, 0.1271, 0.1271, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1217, 0.1219, 0.1218, 0.1273, 0.1268, 0.1265, 0.1269, 0.1271],
        [0.1211, 0.1208, 0.1209, 0.1273, 0.1273, 0.1272, 0.1275, 0.1279],
        [0.1212, 0.1212, 0.1211, 0.1272, 0.1274, 0.1271, 0.1273, 0.1274]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1215, 0.1212, 0.1212, 0.1263, 0.1277, 0.1273, 0.1270, 0.1278],
        [0.1209, 0.1208, 0.1210, 0.1271, 0.1273, 0.1278, 0.1274, 0.1276],
        [0.1211, 0.1211, 0.1212, 0.1268, 0.1275, 0.1269, 0.1275, 0.1278],
        [0.1210, 0.1210, 0.1210, 0.1268, 0.1277, 0.1277, 0.1273, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1213, 0.1212, 0.1210, 0.1274, 0.1270, 0.1271, 0.1272, 0.1278],
        [0.1212, 0.1212, 0.1213, 0.1269, 0.1274, 0.1273, 0.1270, 0.1278],
        [0.1211, 0.1210, 0.1209, 0.1275, 0.1272, 0.1275, 0.1275, 0.1273],
        [0.1209, 0.1210, 0.1210, 0.1277, 0.1273, 0.1275, 0.1271, 0.1274],
        [0.1211, 0.1211, 0.1212, 0.1273, 0.1270, 0.1274, 0.1273, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1252, 0.1256, 0.1256, 0.1247, 0.1238, 0.1238, 0.1243],
        [0.1230, 0.1222, 0.1254, 0.1262, 0.1264, 0.1263, 0.1252, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1242, 0.1259, 0.1275, 0.1237, 0.1245, 0.1240, 0.1230],
        [0.1231, 0.1223, 0.1268, 0.1262, 0.1268, 0.1262, 0.1233, 0.1253],
        [0.1255, 0.1228, 0.1270, 0.1232, 0.1250, 0.1262, 0.1238, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1254, 0.1240, 0.1250, 0.1271, 0.1237, 0.1235],
        [0.1239, 0.1228, 0.1255, 0.1263, 0.1257, 0.1244, 0.1260, 0.1255],
        [0.1257, 0.1228, 0.1262, 0.1228, 0.1273, 0.1273, 0.1232, 0.1246],
        [0.1238, 0.1225, 0.1255, 0.1241, 0.1260, 0.1248, 0.1265, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1268, 0.1247, 0.1252, 0.1252, 0.1259, 0.1241, 0.1254, 0.1226],
        [0.1227, 0.1219, 0.1245, 0.1253, 0.1261, 0.1267, 0.1272, 0.1257],
        [0.1235, 0.1229, 0.1248, 0.1269, 0.1249, 0.1260, 0.1261, 0.1248],
        [0.1220, 0.1219, 0.1225, 0.1271, 0.1266, 0.1268, 0.1267, 0.1264],
        [0.1222, 0.1221, 0.1232, 0.1265, 0.1267, 0.1255, 0.1262, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:33:12 PM | Train: [36/50] Step 000/001 Loss 0.029 Prec@(1,5) (100.0%, 100.0%)
07/20 10:33:15 PM | Train: [36/50] Step 001/001 Loss 0.207 Prec@(1,5) (100.0%, 100.0%)
07/20 10:33:15 PM | Train: [36/50] Final Prec@1 100.0000%
07/20 10:33:16 PM | Valid: [36/50] Step 000/390 Loss 11.803 Prec@(1,5) (7.8%, 40.6%)
07/20 10:33:25 PM | Valid: [36/50] Step 050/390 Loss 10.544 Prec@(1,5) (14.9%, 57.1%)
07/20 10:33:34 PM | Valid: [36/50] Step 100/390 Loss 10.554 Prec@(1,5) (14.4%, 56.9%)
07/20 10:33:44 PM | Valid: [36/50] Step 150/390 Loss 10.505 Prec@(1,5) (15.1%, 57.0%)
07/20 10:33:53 PM | Valid: [36/50] Step 200/390 Loss 10.492 Prec@(1,5) (15.0%, 57.4%)
07/20 10:34:02 PM | Valid: [36/50] Step 250/390 Loss 10.519 Prec@(1,5) (14.9%, 57.2%)
07/20 10:34:11 PM | Valid: [36/50] Step 300/390 Loss 10.518 Prec@(1,5) (14.9%, 56.9%)
07/20 10:34:21 PM | Valid: [36/50] Step 350/390 Loss 10.505 Prec@(1,5) (15.0%, 57.1%)
07/20 10:34:28 PM | Valid: [36/50] Step 390/390 Loss 10.506 Prec@(1,5) (15.0%, 57.2%)
07/20 10:34:28 PM | Valid: [36/50] Final Prec@1 15.0160%
07/20 10:34:28 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1230, 0.1219, 0.1221, 0.1270, 0.1274, 0.1243, 0.1274, 0.1269],
        [0.1212, 0.1213, 0.1212, 0.1268, 0.1272, 0.1272, 0.1272, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1216, 0.1218, 0.1217, 0.1274, 0.1269, 0.1265, 0.1270, 0.1272],
        [0.1210, 0.1207, 0.1208, 0.1274, 0.1274, 0.1273, 0.1276, 0.1279],
        [0.1211, 0.1211, 0.1210, 0.1273, 0.1275, 0.1272, 0.1274, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1214, 0.1211, 0.1211, 0.1264, 0.1277, 0.1273, 0.1271, 0.1279],
        [0.1208, 0.1207, 0.1209, 0.1272, 0.1274, 0.1278, 0.1275, 0.1277],
        [0.1210, 0.1210, 0.1211, 0.1269, 0.1276, 0.1269, 0.1275, 0.1279],
        [0.1209, 0.1209, 0.1209, 0.1268, 0.1278, 0.1277, 0.1274, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1212, 0.1211, 0.1209, 0.1274, 0.1270, 0.1272, 0.1273, 0.1279],
        [0.1211, 0.1211, 0.1212, 0.1269, 0.1274, 0.1274, 0.1271, 0.1278],
        [0.1210, 0.1209, 0.1208, 0.1275, 0.1273, 0.1275, 0.1275, 0.1274],
        [0.1208, 0.1209, 0.1209, 0.1277, 0.1274, 0.1275, 0.1271, 0.1275],
        [0.1210, 0.1210, 0.1211, 0.1273, 0.1271, 0.1275, 0.1274, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1251, 0.1257, 0.1256, 0.1247, 0.1238, 0.1238, 0.1243],
        [0.1230, 0.1221, 0.1254, 0.1263, 0.1264, 0.1264, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1241, 0.1258, 0.1276, 0.1237, 0.1245, 0.1240, 0.1230],
        [0.1230, 0.1223, 0.1268, 0.1262, 0.1268, 0.1263, 0.1232, 0.1254],
        [0.1255, 0.1227, 0.1271, 0.1231, 0.1250, 0.1263, 0.1238, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1255, 0.1240, 0.1250, 0.1271, 0.1236, 0.1235],
        [0.1239, 0.1227, 0.1255, 0.1263, 0.1256, 0.1244, 0.1260, 0.1255],
        [0.1257, 0.1228, 0.1262, 0.1228, 0.1274, 0.1274, 0.1232, 0.1246],
        [0.1237, 0.1224, 0.1255, 0.1242, 0.1260, 0.1249, 0.1265, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1247, 0.1252, 0.1252, 0.1260, 0.1240, 0.1254, 0.1225],
        [0.1227, 0.1218, 0.1244, 0.1253, 0.1261, 0.1267, 0.1273, 0.1257],
        [0.1234, 0.1228, 0.1248, 0.1270, 0.1250, 0.1261, 0.1261, 0.1248],
        [0.1219, 0.1218, 0.1225, 0.1272, 0.1267, 0.1268, 0.1267, 0.1264],
        [0.1222, 0.1221, 0.1232, 0.1265, 0.1268, 0.1255, 0.1261, 0.1275]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:34:33 PM | Train: [37/50] Step 000/001 Loss 0.009 Prec@(1,5) (100.0%, 100.0%)
07/20 10:34:37 PM | Train: [37/50] Step 001/001 Loss 0.266 Prec@(1,5) (88.9%, 100.0%)
07/20 10:34:37 PM | Train: [37/50] Final Prec@1 88.8889%
07/20 10:34:37 PM | Valid: [37/50] Step 000/390 Loss 6.361 Prec@(1,5) (32.8%, 62.5%)
07/20 10:34:47 PM | Valid: [37/50] Step 050/390 Loss 6.985 Prec@(1,5) (17.5%, 57.1%)
07/20 10:34:56 PM | Valid: [37/50] Step 100/390 Loss 6.861 Prec@(1,5) (17.4%, 57.2%)
07/20 10:35:05 PM | Valid: [37/50] Step 150/390 Loss 6.789 Prec@(1,5) (17.6%, 57.7%)
07/20 10:35:15 PM | Valid: [37/50] Step 200/390 Loss 6.828 Prec@(1,5) (17.6%, 57.9%)
07/20 10:35:24 PM | Valid: [37/50] Step 250/390 Loss 6.847 Prec@(1,5) (17.3%, 58.0%)
07/20 10:35:33 PM | Valid: [37/50] Step 300/390 Loss 6.845 Prec@(1,5) (17.2%, 58.0%)
07/20 10:35:43 PM | Valid: [37/50] Step 350/390 Loss 6.837 Prec@(1,5) (17.3%, 57.9%)
07/20 10:35:50 PM | Valid: [37/50] Step 390/390 Loss 6.832 Prec@(1,5) (17.3%, 58.0%)
07/20 10:35:50 PM | Valid: [37/50] Final Prec@1 17.3200%
07/20 10:35:50 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1229, 0.1218, 0.1221, 0.1271, 0.1275, 0.1243, 0.1274, 0.1269],
        [0.1211, 0.1212, 0.1211, 0.1269, 0.1273, 0.1273, 0.1272, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1215, 0.1217, 0.1216, 0.1274, 0.1269, 0.1265, 0.1270, 0.1273],
        [0.1209, 0.1206, 0.1207, 0.1274, 0.1274, 0.1273, 0.1276, 0.1280],
        [0.1210, 0.1210, 0.1209, 0.1274, 0.1275, 0.1272, 0.1275, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1213, 0.1210, 0.1210, 0.1264, 0.1278, 0.1274, 0.1271, 0.1280],
        [0.1207, 0.1206, 0.1208, 0.1272, 0.1274, 0.1279, 0.1275, 0.1278],
        [0.1209, 0.1209, 0.1210, 0.1269, 0.1277, 0.1269, 0.1276, 0.1280],
        [0.1208, 0.1208, 0.1208, 0.1269, 0.1278, 0.1278, 0.1275, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1211, 0.1210, 0.1208, 0.1275, 0.1271, 0.1273, 0.1273, 0.1280],
        [0.1210, 0.1210, 0.1211, 0.1270, 0.1275, 0.1274, 0.1272, 0.1279],
        [0.1209, 0.1208, 0.1207, 0.1276, 0.1273, 0.1276, 0.1276, 0.1275],
        [0.1207, 0.1209, 0.1208, 0.1278, 0.1275, 0.1276, 0.1272, 0.1276],
        [0.1209, 0.1209, 0.1209, 0.1274, 0.1272, 0.1275, 0.1275, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1271, 0.1251, 0.1257, 0.1255, 0.1247, 0.1237, 0.1238, 0.1243],
        [0.1229, 0.1221, 0.1255, 0.1263, 0.1264, 0.1265, 0.1251, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1241, 0.1258, 0.1276, 0.1237, 0.1245, 0.1241, 0.1230],
        [0.1230, 0.1222, 0.1268, 0.1262, 0.1268, 0.1264, 0.1232, 0.1254],
        [0.1254, 0.1226, 0.1271, 0.1230, 0.1251, 0.1263, 0.1239, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1255, 0.1240, 0.1250, 0.1272, 0.1236, 0.1235],
        [0.1238, 0.1227, 0.1254, 0.1264, 0.1256, 0.1244, 0.1261, 0.1256],
        [0.1257, 0.1227, 0.1263, 0.1227, 0.1274, 0.1274, 0.1232, 0.1245],
        [0.1236, 0.1224, 0.1254, 0.1243, 0.1260, 0.1249, 0.1266, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1269, 0.1247, 0.1253, 0.1253, 0.1259, 0.1240, 0.1254, 0.1224],
        [0.1226, 0.1218, 0.1244, 0.1253, 0.1261, 0.1268, 0.1273, 0.1257],
        [0.1234, 0.1228, 0.1248, 0.1271, 0.1250, 0.1261, 0.1261, 0.1248],
        [0.1218, 0.1218, 0.1224, 0.1272, 0.1268, 0.1268, 0.1267, 0.1264],
        [0.1221, 0.1220, 0.1232, 0.1266, 0.1268, 0.1256, 0.1261, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:35:55 PM | Train: [38/50] Step 000/001 Loss 0.524 Prec@(1,5) (87.5%, 100.0%)
07/20 10:35:58 PM | Train: [38/50] Step 001/001 Loss 0.648 Prec@(1,5) (88.9%, 100.0%)
07/20 10:35:59 PM | Train: [38/50] Final Prec@1 88.8889%
07/20 10:35:59 PM | Valid: [38/50] Step 000/390 Loss 7.650 Prec@(1,5) (15.6%, 57.8%)
07/20 10:36:08 PM | Valid: [38/50] Step 050/390 Loss 7.886 Prec@(1,5) (18.2%, 57.6%)
07/20 10:36:18 PM | Valid: [38/50] Step 100/390 Loss 7.795 Prec@(1,5) (18.3%, 58.8%)
07/20 10:36:27 PM | Valid: [38/50] Step 150/390 Loss 7.874 Prec@(1,5) (18.0%, 58.2%)
07/20 10:36:36 PM | Valid: [38/50] Step 200/390 Loss 7.929 Prec@(1,5) (17.9%, 58.6%)
07/20 10:36:46 PM | Valid: [38/50] Step 250/390 Loss 7.880 Prec@(1,5) (17.9%, 58.6%)
07/20 10:36:55 PM | Valid: [38/50] Step 300/390 Loss 7.936 Prec@(1,5) (17.6%, 58.3%)
07/20 10:37:04 PM | Valid: [38/50] Step 350/390 Loss 7.973 Prec@(1,5) (17.5%, 58.2%)
07/20 10:37:11 PM | Valid: [38/50] Step 390/390 Loss 8.006 Prec@(1,5) (17.4%, 57.9%)
07/20 10:37:12 PM | Valid: [38/50] Final Prec@1 17.4480%
07/20 10:37:12 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('dil_conv_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1229, 0.1217, 0.1220, 0.1272, 0.1276, 0.1242, 0.1275, 0.1270],
        [0.1210, 0.1211, 0.1210, 0.1269, 0.1274, 0.1273, 0.1273, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1214, 0.1216, 0.1215, 0.1275, 0.1270, 0.1266, 0.1271, 0.1273],
        [0.1208, 0.1205, 0.1206, 0.1275, 0.1275, 0.1274, 0.1277, 0.1281],
        [0.1209, 0.1209, 0.1208, 0.1274, 0.1276, 0.1273, 0.1275, 0.1276]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1212, 0.1209, 0.1209, 0.1265, 0.1279, 0.1274, 0.1272, 0.1280],
        [0.1206, 0.1205, 0.1207, 0.1273, 0.1274, 0.1280, 0.1276, 0.1278],
        [0.1208, 0.1208, 0.1209, 0.1270, 0.1278, 0.1270, 0.1276, 0.1281],
        [0.1207, 0.1207, 0.1207, 0.1270, 0.1279, 0.1278, 0.1276, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1210, 0.1209, 0.1207, 0.1276, 0.1271, 0.1274, 0.1274, 0.1280],
        [0.1209, 0.1209, 0.1210, 0.1271, 0.1275, 0.1275, 0.1273, 0.1279],
        [0.1208, 0.1207, 0.1206, 0.1277, 0.1274, 0.1276, 0.1277, 0.1275],
        [0.1206, 0.1208, 0.1207, 0.1278, 0.1275, 0.1276, 0.1272, 0.1276],
        [0.1208, 0.1208, 0.1208, 0.1274, 0.1273, 0.1276, 0.1275, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1272, 0.1251, 0.1258, 0.1256, 0.1247, 0.1237, 0.1237, 0.1242],
        [0.1229, 0.1220, 0.1254, 0.1263, 0.1265, 0.1265, 0.1250, 0.1254]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1258, 0.1277, 0.1237, 0.1245, 0.1241, 0.1229],
        [0.1229, 0.1221, 0.1269, 0.1261, 0.1268, 0.1265, 0.1232, 0.1254],
        [0.1254, 0.1226, 0.1271, 0.1230, 0.1252, 0.1264, 0.1239, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1255, 0.1239, 0.1250, 0.1272, 0.1236, 0.1235],
        [0.1238, 0.1226, 0.1253, 0.1265, 0.1256, 0.1244, 0.1262, 0.1257],
        [0.1256, 0.1227, 0.1263, 0.1227, 0.1275, 0.1275, 0.1232, 0.1246],
        [0.1235, 0.1223, 0.1253, 0.1244, 0.1261, 0.1250, 0.1267, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1247, 0.1253, 0.1255, 0.1259, 0.1239, 0.1254, 0.1224],
        [0.1226, 0.1217, 0.1245, 0.1253, 0.1261, 0.1268, 0.1274, 0.1256],
        [0.1233, 0.1227, 0.1248, 0.1272, 0.1250, 0.1260, 0.1261, 0.1248],
        [0.1218, 0.1217, 0.1224, 0.1273, 0.1269, 0.1267, 0.1267, 0.1265],
        [0.1220, 0.1220, 0.1231, 0.1266, 0.1268, 0.1257, 0.1262, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:37:16 PM | Train: [39/50] Step 000/001 Loss 0.023 Prec@(1,5) (100.0%, 100.0%)
07/20 10:37:20 PM | Train: [39/50] Step 001/001 Loss 0.201 Prec@(1,5) (100.0%, 100.0%)
07/20 10:37:20 PM | Train: [39/50] Final Prec@1 100.0000%
07/20 10:37:20 PM | Valid: [39/50] Step 000/390 Loss 9.834 Prec@(1,5) (10.9%, 42.2%)
07/20 10:37:30 PM | Valid: [39/50] Step 050/390 Loss 9.010 Prec@(1,5) (16.5%, 58.5%)
07/20 10:37:39 PM | Valid: [39/50] Step 100/390 Loss 9.076 Prec@(1,5) (16.4%, 57.7%)
07/20 10:37:48 PM | Valid: [39/50] Step 150/390 Loss 9.115 Prec@(1,5) (16.5%, 57.0%)
07/20 10:37:58 PM | Valid: [39/50] Step 200/390 Loss 9.063 Prec@(1,5) (16.4%, 57.3%)
07/20 10:38:07 PM | Valid: [39/50] Step 250/390 Loss 9.033 Prec@(1,5) (16.6%, 57.4%)
07/20 10:38:16 PM | Valid: [39/50] Step 300/390 Loss 9.049 Prec@(1,5) (16.8%, 57.4%)
07/20 10:38:25 PM | Valid: [39/50] Step 350/390 Loss 9.035 Prec@(1,5) (16.8%, 57.1%)
07/20 10:38:33 PM | Valid: [39/50] Step 390/390 Loss 9.070 Prec@(1,5) (16.7%, 56.9%)
07/20 10:38:33 PM | Valid: [39/50] Final Prec@1 16.6680%
07/20 10:38:33 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1228, 0.1216, 0.1219, 0.1273, 0.1276, 0.1242, 0.1275, 0.1271],
        [0.1209, 0.1210, 0.1209, 0.1269, 0.1274, 0.1274, 0.1273, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1213, 0.1215, 0.1214, 0.1276, 0.1270, 0.1266, 0.1271, 0.1274],
        [0.1207, 0.1204, 0.1205, 0.1276, 0.1275, 0.1274, 0.1278, 0.1281],
        [0.1208, 0.1208, 0.1207, 0.1275, 0.1277, 0.1273, 0.1276, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1211, 0.1208, 0.1208, 0.1265, 0.1279, 0.1275, 0.1273, 0.1281],
        [0.1205, 0.1204, 0.1206, 0.1274, 0.1275, 0.1280, 0.1277, 0.1279],
        [0.1207, 0.1207, 0.1208, 0.1271, 0.1279, 0.1270, 0.1277, 0.1281],
        [0.1206, 0.1206, 0.1206, 0.1270, 0.1280, 0.1279, 0.1276, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1209, 0.1208, 0.1206, 0.1276, 0.1271, 0.1275, 0.1274, 0.1281],
        [0.1208, 0.1208, 0.1209, 0.1271, 0.1275, 0.1275, 0.1274, 0.1280],
        [0.1207, 0.1206, 0.1205, 0.1277, 0.1274, 0.1277, 0.1277, 0.1276],
        [0.1205, 0.1207, 0.1206, 0.1279, 0.1276, 0.1277, 0.1273, 0.1277],
        [0.1207, 0.1207, 0.1208, 0.1275, 0.1273, 0.1276, 0.1276, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1272, 0.1252, 0.1257, 0.1255, 0.1247, 0.1237, 0.1237, 0.1242],
        [0.1229, 0.1220, 0.1255, 0.1263, 0.1265, 0.1266, 0.1249, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1241, 0.1258, 0.1278, 0.1237, 0.1245, 0.1241, 0.1229],
        [0.1228, 0.1221, 0.1269, 0.1262, 0.1268, 0.1265, 0.1232, 0.1254],
        [0.1253, 0.1225, 0.1271, 0.1229, 0.1253, 0.1265, 0.1239, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1241, 0.1255, 0.1238, 0.1251, 0.1272, 0.1236, 0.1235],
        [0.1237, 0.1226, 0.1252, 0.1265, 0.1256, 0.1244, 0.1263, 0.1257],
        [0.1255, 0.1226, 0.1263, 0.1226, 0.1276, 0.1276, 0.1232, 0.1246],
        [0.1233, 0.1222, 0.1253, 0.1244, 0.1262, 0.1251, 0.1267, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1248, 0.1253, 0.1256, 0.1259, 0.1238, 0.1253, 0.1223],
        [0.1225, 0.1217, 0.1244, 0.1253, 0.1261, 0.1268, 0.1274, 0.1256],
        [0.1232, 0.1227, 0.1248, 0.1272, 0.1250, 0.1260, 0.1261, 0.1249],
        [0.1217, 0.1217, 0.1224, 0.1273, 0.1270, 0.1266, 0.1268, 0.1265],
        [0.1219, 0.1219, 0.1231, 0.1265, 0.1269, 0.1258, 0.1262, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:38:38 PM | Train: [40/50] Step 000/001 Loss 0.006 Prec@(1,5) (100.0%, 100.0%)
07/20 10:38:41 PM | Train: [40/50] Step 001/001 Loss 0.186 Prec@(1,5) (100.0%, 100.0%)
07/20 10:38:41 PM | Train: [40/50] Final Prec@1 100.0000%
07/20 10:38:42 PM | Valid: [40/50] Step 000/390 Loss 13.719 Prec@(1,5) (14.1%, 45.3%)
07/20 10:38:51 PM | Valid: [40/50] Step 050/390 Loss 11.288 Prec@(1,5) (15.1%, 56.4%)
07/20 10:39:01 PM | Valid: [40/50] Step 100/390 Loss 11.092 Prec@(1,5) (15.3%, 57.0%)
07/20 10:39:10 PM | Valid: [40/50] Step 150/390 Loss 11.178 Prec@(1,5) (15.3%, 56.2%)
07/20 10:39:19 PM | Valid: [40/50] Step 200/390 Loss 11.239 Prec@(1,5) (15.7%, 56.1%)
07/20 10:39:28 PM | Valid: [40/50] Step 250/390 Loss 11.225 Prec@(1,5) (15.6%, 56.0%)
07/20 10:39:38 PM | Valid: [40/50] Step 300/390 Loss 11.244 Prec@(1,5) (15.5%, 56.0%)
07/20 10:39:47 PM | Valid: [40/50] Step 350/390 Loss 11.204 Prec@(1,5) (15.5%, 56.2%)
07/20 10:39:54 PM | Valid: [40/50] Step 390/390 Loss 11.207 Prec@(1,5) (15.6%, 56.2%)
07/20 10:39:55 PM | Valid: [40/50] Final Prec@1 15.5920%
07/20 10:39:55 PM | genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1226, 0.1216, 0.1218, 0.1274, 0.1277, 0.1242, 0.1276, 0.1271],
        [0.1208, 0.1209, 0.1208, 0.1270, 0.1275, 0.1275, 0.1274, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1212, 0.1214, 0.1213, 0.1276, 0.1271, 0.1267, 0.1272, 0.1274],
        [0.1206, 0.1203, 0.1204, 0.1276, 0.1276, 0.1275, 0.1278, 0.1282],
        [0.1207, 0.1207, 0.1206, 0.1276, 0.1277, 0.1274, 0.1276, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1210, 0.1207, 0.1207, 0.1266, 0.1280, 0.1275, 0.1274, 0.1282],
        [0.1204, 0.1203, 0.1205, 0.1274, 0.1275, 0.1281, 0.1278, 0.1280],
        [0.1206, 0.1206, 0.1207, 0.1271, 0.1279, 0.1271, 0.1277, 0.1282],
        [0.1205, 0.1205, 0.1205, 0.1271, 0.1281, 0.1279, 0.1277, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1208, 0.1207, 0.1205, 0.1277, 0.1271, 0.1276, 0.1275, 0.1281],
        [0.1207, 0.1207, 0.1208, 0.1272, 0.1276, 0.1276, 0.1275, 0.1281],
        [0.1206, 0.1206, 0.1204, 0.1278, 0.1275, 0.1277, 0.1278, 0.1277],
        [0.1204, 0.1206, 0.1206, 0.1280, 0.1276, 0.1277, 0.1274, 0.1278],
        [0.1206, 0.1206, 0.1207, 0.1275, 0.1274, 0.1277, 0.1276, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1272, 0.1252, 0.1257, 0.1256, 0.1247, 0.1237, 0.1237, 0.1242],
        [0.1228, 0.1220, 0.1255, 0.1263, 0.1265, 0.1266, 0.1250, 0.1253]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1240, 0.1258, 0.1278, 0.1236, 0.1245, 0.1241, 0.1229],
        [0.1228, 0.1221, 0.1270, 0.1263, 0.1267, 0.1266, 0.1232, 0.1254],
        [0.1252, 0.1224, 0.1271, 0.1229, 0.1253, 0.1265, 0.1239, 0.1266]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1241, 0.1255, 0.1237, 0.1251, 0.1273, 0.1236, 0.1235],
        [0.1236, 0.1225, 0.1252, 0.1266, 0.1257, 0.1244, 0.1263, 0.1257],
        [0.1255, 0.1225, 0.1264, 0.1226, 0.1276, 0.1276, 0.1231, 0.1247],
        [0.1233, 0.1221, 0.1253, 0.1244, 0.1262, 0.1251, 0.1267, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1270, 0.1248, 0.1252, 0.1256, 0.1260, 0.1237, 0.1253, 0.1223],
        [0.1225, 0.1217, 0.1244, 0.1254, 0.1262, 0.1269, 0.1275, 0.1256],
        [0.1231, 0.1226, 0.1248, 0.1273, 0.1251, 0.1260, 0.1262, 0.1249],
        [0.1216, 0.1216, 0.1223, 0.1274, 0.1270, 0.1267, 0.1268, 0.1266],
        [0.1218, 0.1218, 0.1231, 0.1266, 0.1269, 0.1258, 0.1262, 0.1277]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:39:59 PM | Train: [41/50] Step 000/001 Loss 0.868 Prec@(1,5) (87.5%, 100.0%)
07/20 10:40:03 PM | Train: [41/50] Step 001/001 Loss 0.999 Prec@(1,5) (77.8%, 100.0%)
07/20 10:40:03 PM | Train: [41/50] Final Prec@1 77.7778%
07/20 10:40:03 PM | Valid: [41/50] Step 000/390 Loss 12.822 Prec@(1,5) (17.2%, 59.4%)
07/20 10:40:13 PM | Valid: [41/50] Step 050/390 Loss 12.295 Prec@(1,5) (14.8%, 60.0%)
07/20 10:40:22 PM | Valid: [41/50] Step 100/390 Loss 12.158 Prec@(1,5) (15.3%, 60.7%)
07/20 10:40:31 PM | Valid: [41/50] Step 150/390 Loss 12.129 Prec@(1,5) (15.3%, 60.7%)
07/20 10:40:40 PM | Valid: [41/50] Step 200/390 Loss 12.144 Prec@(1,5) (14.9%, 60.3%)
07/20 10:40:50 PM | Valid: [41/50] Step 250/390 Loss 12.124 Prec@(1,5) (15.1%, 60.5%)
07/20 10:40:59 PM | Valid: [41/50] Step 300/390 Loss 12.143 Prec@(1,5) (14.9%, 60.4%)
07/20 10:41:08 PM | Valid: [41/50] Step 350/390 Loss 12.173 Prec@(1,5) (14.8%, 60.4%)
07/20 10:41:16 PM | Valid: [41/50] Step 390/390 Loss 12.181 Prec@(1,5) (14.8%, 60.3%)
07/20 10:41:16 PM | Valid: [41/50] Final Prec@1 14.7760%
07/20 10:41:16 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1226, 0.1215, 0.1217, 0.1275, 0.1278, 0.1242, 0.1276, 0.1272],
        [0.1207, 0.1208, 0.1207, 0.1270, 0.1275, 0.1276, 0.1275, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1212, 0.1214, 0.1212, 0.1277, 0.1271, 0.1267, 0.1272, 0.1275],
        [0.1205, 0.1202, 0.1203, 0.1277, 0.1277, 0.1276, 0.1279, 0.1283],
        [0.1206, 0.1206, 0.1205, 0.1276, 0.1278, 0.1274, 0.1277, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1208, 0.1206, 0.1206, 0.1266, 0.1280, 0.1276, 0.1275, 0.1283],
        [0.1203, 0.1202, 0.1204, 0.1275, 0.1276, 0.1281, 0.1278, 0.1280],
        [0.1205, 0.1206, 0.1206, 0.1272, 0.1280, 0.1271, 0.1278, 0.1282],
        [0.1204, 0.1204, 0.1204, 0.1271, 0.1281, 0.1280, 0.1277, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1207, 0.1206, 0.1204, 0.1277, 0.1272, 0.1277, 0.1275, 0.1282],
        [0.1206, 0.1206, 0.1207, 0.1272, 0.1277, 0.1276, 0.1275, 0.1281],
        [0.1205, 0.1205, 0.1203, 0.1278, 0.1275, 0.1278, 0.1278, 0.1277],
        [0.1203, 0.1205, 0.1205, 0.1280, 0.1277, 0.1278, 0.1274, 0.1278],
        [0.1205, 0.1205, 0.1206, 0.1276, 0.1274, 0.1278, 0.1277, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1273, 0.1252, 0.1257, 0.1256, 0.1247, 0.1236, 0.1237, 0.1242],
        [0.1228, 0.1220, 0.1256, 0.1263, 0.1265, 0.1266, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1240, 0.1259, 0.1279, 0.1236, 0.1245, 0.1241, 0.1229],
        [0.1229, 0.1221, 0.1270, 0.1263, 0.1267, 0.1266, 0.1231, 0.1253],
        [0.1252, 0.1223, 0.1271, 0.1229, 0.1253, 0.1265, 0.1239, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1241, 0.1254, 0.1236, 0.1252, 0.1272, 0.1235, 0.1235],
        [0.1235, 0.1224, 0.1252, 0.1266, 0.1258, 0.1244, 0.1263, 0.1257],
        [0.1255, 0.1225, 0.1265, 0.1225, 0.1276, 0.1276, 0.1231, 0.1247],
        [0.1232, 0.1220, 0.1253, 0.1244, 0.1262, 0.1252, 0.1268, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1271, 0.1248, 0.1252, 0.1256, 0.1260, 0.1236, 0.1253, 0.1223],
        [0.1224, 0.1216, 0.1244, 0.1254, 0.1262, 0.1269, 0.1275, 0.1255],
        [0.1231, 0.1226, 0.1248, 0.1273, 0.1252, 0.1260, 0.1262, 0.1249],
        [0.1215, 0.1216, 0.1223, 0.1274, 0.1270, 0.1267, 0.1268, 0.1267],
        [0.1218, 0.1218, 0.1230, 0.1266, 0.1270, 0.1259, 0.1261, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:41:21 PM | Train: [42/50] Step 000/001 Loss 0.005 Prec@(1,5) (100.0%, 100.0%)
07/20 10:41:24 PM | Train: [42/50] Step 001/001 Loss 0.183 Prec@(1,5) (100.0%, 100.0%)
07/20 10:41:24 PM | Train: [42/50] Final Prec@1 100.0000%
07/20 10:41:25 PM | Valid: [42/50] Step 000/390 Loss 11.278 Prec@(1,5) (21.9%, 57.8%)
07/20 10:41:34 PM | Valid: [42/50] Step 050/390 Loss 12.328 Prec@(1,5) (15.7%, 59.1%)
07/20 10:41:43 PM | Valid: [42/50] Step 100/390 Loss 12.433 Prec@(1,5) (15.5%, 58.8%)
07/20 10:41:52 PM | Valid: [42/50] Step 150/390 Loss 12.367 Prec@(1,5) (15.4%, 58.6%)
07/20 10:42:02 PM | Valid: [42/50] Step 200/390 Loss 12.327 Prec@(1,5) (15.4%, 58.9%)
07/20 10:42:11 PM | Valid: [42/50] Step 250/390 Loss 12.306 Prec@(1,5) (15.5%, 58.8%)
07/20 10:42:20 PM | Valid: [42/50] Step 300/390 Loss 12.339 Prec@(1,5) (15.3%, 58.7%)
07/20 10:42:29 PM | Valid: [42/50] Step 350/390 Loss 12.346 Prec@(1,5) (15.4%, 58.6%)
07/20 10:42:37 PM | Valid: [42/50] Step 390/390 Loss 12.341 Prec@(1,5) (15.4%, 58.6%)
07/20 10:42:37 PM | Valid: [42/50] Final Prec@1 15.4320%
07/20 10:42:37 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('dil_conv_5x5', 1), ('sep_conv_3x3', 3)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1225, 0.1214, 0.1216, 0.1275, 0.1279, 0.1242, 0.1277, 0.1273],
        [0.1207, 0.1207, 0.1206, 0.1270, 0.1276, 0.1276, 0.1276, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1211, 0.1213, 0.1211, 0.1278, 0.1272, 0.1267, 0.1272, 0.1276],
        [0.1204, 0.1201, 0.1202, 0.1277, 0.1277, 0.1276, 0.1280, 0.1283],
        [0.1205, 0.1205, 0.1204, 0.1277, 0.1279, 0.1274, 0.1278, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1207, 0.1205, 0.1205, 0.1267, 0.1281, 0.1277, 0.1275, 0.1283],
        [0.1202, 0.1202, 0.1203, 0.1276, 0.1277, 0.1282, 0.1278, 0.1281],
        [0.1204, 0.1204, 0.1205, 0.1273, 0.1281, 0.1272, 0.1278, 0.1283],
        [0.1203, 0.1203, 0.1203, 0.1272, 0.1282, 0.1280, 0.1277, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1206, 0.1205, 0.1202, 0.1278, 0.1273, 0.1278, 0.1276, 0.1282],
        [0.1205, 0.1205, 0.1206, 0.1272, 0.1278, 0.1277, 0.1276, 0.1282],
        [0.1204, 0.1204, 0.1202, 0.1279, 0.1276, 0.1278, 0.1279, 0.1278],
        [0.1202, 0.1204, 0.1203, 0.1281, 0.1277, 0.1278, 0.1275, 0.1279],
        [0.1204, 0.1204, 0.1205, 0.1276, 0.1275, 0.1278, 0.1277, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1274, 0.1252, 0.1257, 0.1255, 0.1247, 0.1236, 0.1237, 0.1242],
        [0.1228, 0.1219, 0.1256, 0.1263, 0.1266, 0.1265, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1240, 0.1258, 0.1280, 0.1235, 0.1244, 0.1242, 0.1228],
        [0.1228, 0.1220, 0.1271, 0.1264, 0.1267, 0.1266, 0.1230, 0.1253],
        [0.1252, 0.1223, 0.1272, 0.1228, 0.1254, 0.1266, 0.1238, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1242, 0.1254, 0.1235, 0.1253, 0.1272, 0.1236, 0.1234],
        [0.1235, 0.1224, 0.1252, 0.1267, 0.1258, 0.1244, 0.1263, 0.1258],
        [0.1255, 0.1224, 0.1266, 0.1225, 0.1277, 0.1276, 0.1230, 0.1247],
        [0.1231, 0.1220, 0.1253, 0.1244, 0.1262, 0.1252, 0.1269, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1272, 0.1249, 0.1252, 0.1255, 0.1260, 0.1235, 0.1253, 0.1223],
        [0.1224, 0.1216, 0.1244, 0.1254, 0.1262, 0.1269, 0.1275, 0.1255],
        [0.1231, 0.1226, 0.1249, 0.1274, 0.1251, 0.1260, 0.1262, 0.1248],
        [0.1215, 0.1215, 0.1223, 0.1274, 0.1270, 0.1268, 0.1268, 0.1267],
        [0.1217, 0.1217, 0.1230, 0.1266, 0.1270, 0.1259, 0.1262, 0.1278]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:42:42 PM | Train: [43/50] Step 000/001 Loss 0.007 Prec@(1,5) (100.0%, 100.0%)
07/20 10:42:45 PM | Train: [43/50] Step 001/001 Loss 0.230 Prec@(1,5) (88.9%, 100.0%)
07/20 10:42:45 PM | Train: [43/50] Final Prec@1 88.8889%
07/20 10:42:46 PM | Valid: [43/50] Step 000/390 Loss 9.696 Prec@(1,5) (10.9%, 51.6%)
07/20 10:42:55 PM | Valid: [43/50] Step 050/390 Loss 8.642 Prec@(1,5) (15.8%, 57.7%)
07/20 10:43:04 PM | Valid: [43/50] Step 100/390 Loss 8.658 Prec@(1,5) (15.5%, 57.4%)
07/20 10:43:14 PM | Valid: [43/50] Step 150/390 Loss 8.585 Prec@(1,5) (16.2%, 57.8%)
07/20 10:43:23 PM | Valid: [43/50] Step 200/390 Loss 8.563 Prec@(1,5) (16.5%, 58.1%)
07/20 10:43:32 PM | Valid: [43/50] Step 250/390 Loss 8.563 Prec@(1,5) (16.4%, 58.3%)
07/20 10:43:41 PM | Valid: [43/50] Step 300/390 Loss 8.593 Prec@(1,5) (16.4%, 58.2%)
07/20 10:43:50 PM | Valid: [43/50] Step 350/390 Loss 8.612 Prec@(1,5) (16.4%, 58.2%)
07/20 10:43:58 PM | Valid: [43/50] Step 390/390 Loss 8.605 Prec@(1,5) (16.5%, 58.2%)
07/20 10:43:58 PM | Valid: [43/50] Final Prec@1 16.4600%
07/20 10:43:58 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('sep_conv_5x5', 3)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1224, 0.1213, 0.1216, 0.1276, 0.1279, 0.1241, 0.1277, 0.1274],
        [0.1205, 0.1206, 0.1205, 0.1270, 0.1276, 0.1277, 0.1277, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1210, 0.1212, 0.1211, 0.1279, 0.1273, 0.1267, 0.1273, 0.1277],
        [0.1203, 0.1200, 0.1201, 0.1278, 0.1278, 0.1277, 0.1280, 0.1284],
        [0.1204, 0.1204, 0.1203, 0.1278, 0.1279, 0.1275, 0.1278, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1206, 0.1204, 0.1204, 0.1267, 0.1281, 0.1278, 0.1276, 0.1284],
        [0.1201, 0.1201, 0.1202, 0.1276, 0.1277, 0.1282, 0.1279, 0.1281],
        [0.1203, 0.1203, 0.1204, 0.1274, 0.1281, 0.1272, 0.1279, 0.1284],
        [0.1202, 0.1202, 0.1202, 0.1273, 0.1283, 0.1280, 0.1278, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1205, 0.1204, 0.1202, 0.1278, 0.1273, 0.1278, 0.1276, 0.1283],
        [0.1204, 0.1204, 0.1205, 0.1272, 0.1279, 0.1277, 0.1277, 0.1282],
        [0.1204, 0.1203, 0.1201, 0.1280, 0.1276, 0.1279, 0.1279, 0.1278],
        [0.1201, 0.1203, 0.1203, 0.1282, 0.1278, 0.1279, 0.1276, 0.1279],
        [0.1203, 0.1203, 0.1204, 0.1277, 0.1276, 0.1279, 0.1277, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1274, 0.1253, 0.1257, 0.1255, 0.1246, 0.1236, 0.1236, 0.1242],
        [0.1227, 0.1219, 0.1256, 0.1263, 0.1267, 0.1265, 0.1251, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1241, 0.1258, 0.1281, 0.1235, 0.1244, 0.1242, 0.1227],
        [0.1228, 0.1220, 0.1272, 0.1264, 0.1266, 0.1266, 0.1230, 0.1253],
        [0.1252, 0.1223, 0.1272, 0.1227, 0.1254, 0.1266, 0.1238, 0.1267]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1242, 0.1254, 0.1235, 0.1253, 0.1272, 0.1236, 0.1233],
        [0.1234, 0.1223, 0.1252, 0.1267, 0.1258, 0.1243, 0.1263, 0.1259],
        [0.1255, 0.1224, 0.1267, 0.1224, 0.1277, 0.1276, 0.1229, 0.1247],
        [0.1230, 0.1219, 0.1253, 0.1244, 0.1263, 0.1252, 0.1270, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1249, 0.1252, 0.1255, 0.1260, 0.1234, 0.1253, 0.1222],
        [0.1224, 0.1216, 0.1245, 0.1254, 0.1262, 0.1269, 0.1274, 0.1255],
        [0.1230, 0.1226, 0.1250, 0.1274, 0.1251, 0.1260, 0.1261, 0.1248],
        [0.1214, 0.1214, 0.1223, 0.1275, 0.1270, 0.1268, 0.1268, 0.1268],
        [0.1216, 0.1217, 0.1230, 0.1266, 0.1270, 0.1259, 0.1262, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:44:03 PM | Train: [44/50] Step 000/001 Loss 0.160 Prec@(1,5) (87.5%, 100.0%)
07/20 10:44:06 PM | Train: [44/50] Step 001/001 Loss 0.369 Prec@(1,5) (77.8%, 100.0%)
07/20 10:44:06 PM | Train: [44/50] Final Prec@1 77.7778%
07/20 10:44:07 PM | Valid: [44/50] Step 000/390 Loss 11.474 Prec@(1,5) (10.9%, 40.6%)
07/20 10:44:16 PM | Valid: [44/50] Step 050/390 Loss 9.967 Prec@(1,5) (16.5%, 60.1%)
07/20 10:44:25 PM | Valid: [44/50] Step 100/390 Loss 10.064 Prec@(1,5) (16.2%, 59.8%)
07/20 10:44:35 PM | Valid: [44/50] Step 150/390 Loss 10.038 Prec@(1,5) (16.2%, 60.3%)
07/20 10:44:44 PM | Valid: [44/50] Step 200/390 Loss 10.062 Prec@(1,5) (16.0%, 59.7%)
07/20 10:44:53 PM | Valid: [44/50] Step 250/390 Loss 10.099 Prec@(1,5) (15.7%, 59.6%)
07/20 10:45:02 PM | Valid: [44/50] Step 300/390 Loss 10.079 Prec@(1,5) (15.8%, 59.5%)
07/20 10:45:12 PM | Valid: [44/50] Step 350/390 Loss 10.124 Prec@(1,5) (15.7%, 59.3%)
07/20 10:45:19 PM | Valid: [44/50] Step 390/390 Loss 10.112 Prec@(1,5) (15.8%, 59.4%)
07/20 10:45:19 PM | Valid: [44/50] Final Prec@1 15.8320%
07/20 10:45:19 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1222, 0.1212, 0.1214, 0.1277, 0.1280, 0.1242, 0.1278, 0.1274],
        [0.1204, 0.1205, 0.1204, 0.1271, 0.1276, 0.1278, 0.1277, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1209, 0.1211, 0.1210, 0.1279, 0.1273, 0.1268, 0.1273, 0.1277],
        [0.1202, 0.1199, 0.1200, 0.1278, 0.1279, 0.1277, 0.1281, 0.1285],
        [0.1203, 0.1203, 0.1202, 0.1278, 0.1280, 0.1275, 0.1279, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1205, 0.1203, 0.1203, 0.1268, 0.1281, 0.1279, 0.1277, 0.1285],
        [0.1200, 0.1200, 0.1201, 0.1277, 0.1278, 0.1283, 0.1279, 0.1282],
        [0.1202, 0.1203, 0.1203, 0.1274, 0.1282, 0.1272, 0.1279, 0.1284],
        [0.1201, 0.1201, 0.1201, 0.1273, 0.1284, 0.1281, 0.1278, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1204, 0.1203, 0.1201, 0.1279, 0.1274, 0.1279, 0.1277, 0.1284],
        [0.1203, 0.1203, 0.1204, 0.1273, 0.1279, 0.1277, 0.1277, 0.1283],
        [0.1203, 0.1202, 0.1200, 0.1280, 0.1277, 0.1279, 0.1280, 0.1279],
        [0.1200, 0.1202, 0.1202, 0.1282, 0.1278, 0.1280, 0.1277, 0.1280],
        [0.1202, 0.1203, 0.1203, 0.1277, 0.1276, 0.1280, 0.1278, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1274, 0.1253, 0.1258, 0.1255, 0.1247, 0.1236, 0.1236, 0.1242],
        [0.1227, 0.1218, 0.1255, 0.1263, 0.1268, 0.1266, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1273, 0.1240, 0.1257, 0.1283, 0.1235, 0.1243, 0.1241, 0.1227],
        [0.1227, 0.1219, 0.1273, 0.1264, 0.1266, 0.1267, 0.1231, 0.1253],
        [0.1252, 0.1222, 0.1272, 0.1227, 0.1254, 0.1267, 0.1238, 0.1268]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1276, 0.1242, 0.1254, 0.1235, 0.1252, 0.1272, 0.1236, 0.1233],
        [0.1234, 0.1223, 0.1251, 0.1268, 0.1258, 0.1243, 0.1264, 0.1260],
        [0.1255, 0.1224, 0.1268, 0.1223, 0.1277, 0.1277, 0.1228, 0.1247],
        [0.1230, 0.1218, 0.1254, 0.1244, 0.1263, 0.1252, 0.1271, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1250, 0.1253, 0.1256, 0.1260, 0.1233, 0.1253, 0.1222],
        [0.1224, 0.1215, 0.1245, 0.1254, 0.1262, 0.1270, 0.1275, 0.1255],
        [0.1230, 0.1225, 0.1250, 0.1274, 0.1251, 0.1261, 0.1261, 0.1248],
        [0.1213, 0.1214, 0.1223, 0.1275, 0.1271, 0.1268, 0.1268, 0.1268],
        [0.1216, 0.1216, 0.1229, 0.1267, 0.1272, 0.1260, 0.1262, 0.1279]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:45:24 PM | Train: [45/50] Step 000/001 Loss 0.010 Prec@(1,5) (100.0%, 100.0%)
07/20 10:45:28 PM | Train: [45/50] Step 001/001 Loss 0.264 Prec@(1,5) (88.9%, 100.0%)
07/20 10:45:28 PM | Train: [45/50] Final Prec@1 88.8889%
07/20 10:45:28 PM | Valid: [45/50] Step 000/390 Loss 8.802 Prec@(1,5) (15.6%, 53.1%)
07/20 10:45:38 PM | Valid: [45/50] Step 050/390 Loss 7.759 Prec@(1,5) (16.8%, 61.3%)
07/20 10:45:47 PM | Valid: [45/50] Step 100/390 Loss 7.856 Prec@(1,5) (16.5%, 60.5%)
07/20 10:45:56 PM | Valid: [45/50] Step 150/390 Loss 7.849 Prec@(1,5) (16.4%, 60.4%)
07/20 10:46:05 PM | Valid: [45/50] Step 200/390 Loss 7.888 Prec@(1,5) (16.3%, 60.2%)
07/20 10:46:15 PM | Valid: [45/50] Step 250/390 Loss 7.907 Prec@(1,5) (16.1%, 60.1%)
07/20 10:46:24 PM | Valid: [45/50] Step 300/390 Loss 7.939 Prec@(1,5) (16.1%, 59.9%)
07/20 10:46:33 PM | Valid: [45/50] Step 350/390 Loss 7.923 Prec@(1,5) (16.2%, 60.2%)
07/20 10:46:41 PM | Valid: [45/50] Step 390/390 Loss 7.924 Prec@(1,5) (16.2%, 60.2%)
07/20 10:46:41 PM | Valid: [45/50] Final Prec@1 16.1880%
07/20 10:46:41 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('sep_conv_5x5', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1221, 0.1211, 0.1213, 0.1278, 0.1280, 0.1242, 0.1279, 0.1275],
        [0.1203, 0.1204, 0.1203, 0.1272, 0.1277, 0.1278, 0.1277, 0.1285]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1208, 0.1210, 0.1209, 0.1280, 0.1273, 0.1268, 0.1273, 0.1278],
        [0.1201, 0.1198, 0.1199, 0.1279, 0.1279, 0.1278, 0.1281, 0.1285],
        [0.1202, 0.1202, 0.1201, 0.1279, 0.1280, 0.1275, 0.1279, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1204, 0.1202, 0.1202, 0.1268, 0.1282, 0.1280, 0.1278, 0.1286],
        [0.1199, 0.1199, 0.1200, 0.1278, 0.1278, 0.1284, 0.1279, 0.1283],
        [0.1201, 0.1202, 0.1202, 0.1275, 0.1282, 0.1273, 0.1280, 0.1285],
        [0.1200, 0.1200, 0.1200, 0.1274, 0.1285, 0.1281, 0.1279, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1203, 0.1202, 0.1200, 0.1279, 0.1274, 0.1280, 0.1278, 0.1285],
        [0.1202, 0.1203, 0.1203, 0.1273, 0.1280, 0.1278, 0.1278, 0.1284],
        [0.1202, 0.1201, 0.1199, 0.1281, 0.1277, 0.1280, 0.1280, 0.1280],
        [0.1199, 0.1201, 0.1201, 0.1283, 0.1279, 0.1280, 0.1277, 0.1280],
        [0.1201, 0.1201, 0.1202, 0.1278, 0.1277, 0.1280, 0.1279, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1275, 0.1253, 0.1259, 0.1254, 0.1247, 0.1235, 0.1235, 0.1243],
        [0.1227, 0.1218, 0.1254, 0.1263, 0.1269, 0.1266, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1241, 0.1257, 0.1283, 0.1234, 0.1243, 0.1241, 0.1227],
        [0.1227, 0.1218, 0.1274, 0.1264, 0.1266, 0.1268, 0.1231, 0.1253],
        [0.1251, 0.1221, 0.1273, 0.1228, 0.1254, 0.1268, 0.1237, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1277, 0.1243, 0.1253, 0.1234, 0.1252, 0.1272, 0.1236, 0.1233],
        [0.1234, 0.1222, 0.1250, 0.1268, 0.1258, 0.1244, 0.1265, 0.1260],
        [0.1256, 0.1224, 0.1268, 0.1223, 0.1277, 0.1277, 0.1227, 0.1247],
        [0.1229, 0.1218, 0.1254, 0.1244, 0.1263, 0.1251, 0.1272, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1274, 0.1249, 0.1253, 0.1256, 0.1261, 0.1233, 0.1253, 0.1221],
        [0.1223, 0.1215, 0.1245, 0.1254, 0.1262, 0.1270, 0.1275, 0.1255],
        [0.1229, 0.1225, 0.1250, 0.1275, 0.1251, 0.1261, 0.1261, 0.1248],
        [0.1212, 0.1213, 0.1222, 0.1275, 0.1271, 0.1269, 0.1268, 0.1269],
        [0.1215, 0.1215, 0.1229, 0.1267, 0.1272, 0.1261, 0.1262, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:46:46 PM | Train: [46/50] Step 000/001 Loss 0.054 Prec@(1,5) (100.0%, 100.0%)
07/20 10:46:49 PM | Train: [46/50] Step 001/001 Loss 0.302 Prec@(1,5) (88.9%, 100.0%)
07/20 10:46:49 PM | Train: [46/50] Final Prec@1 88.8889%
07/20 10:46:50 PM | Valid: [46/50] Step 000/390 Loss 7.193 Prec@(1,5) (17.2%, 54.7%)
07/20 10:46:59 PM | Valid: [46/50] Step 050/390 Loss 7.495 Prec@(1,5) (16.8%, 60.0%)
07/20 10:47:08 PM | Valid: [46/50] Step 100/390 Loss 7.463 Prec@(1,5) (16.6%, 60.0%)
07/20 10:47:18 PM | Valid: [46/50] Step 150/390 Loss 7.495 Prec@(1,5) (16.3%, 59.6%)
07/20 10:47:27 PM | Valid: [46/50] Step 200/390 Loss 7.454 Prec@(1,5) (16.4%, 59.5%)
07/20 10:47:36 PM | Valid: [46/50] Step 250/390 Loss 7.439 Prec@(1,5) (16.3%, 59.4%)
07/20 10:47:45 PM | Valid: [46/50] Step 300/390 Loss 7.470 Prec@(1,5) (16.1%, 59.2%)
07/20 10:47:55 PM | Valid: [46/50] Step 350/390 Loss 7.480 Prec@(1,5) (16.1%, 59.0%)
07/20 10:48:02 PM | Valid: [46/50] Step 390/390 Loss 7.481 Prec@(1,5) (16.2%, 59.0%)
07/20 10:48:02 PM | Valid: [46/50] Final Prec@1 16.1560%
07/20 10:48:02 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 2)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1220, 0.1210, 0.1212, 0.1279, 0.1281, 0.1242, 0.1279, 0.1276],
        [0.1202, 0.1203, 0.1202, 0.1272, 0.1278, 0.1279, 0.1278, 0.1286]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1207, 0.1209, 0.1208, 0.1281, 0.1274, 0.1269, 0.1274, 0.1279],
        [0.1200, 0.1197, 0.1198, 0.1280, 0.1280, 0.1279, 0.1282, 0.1286],
        [0.1202, 0.1201, 0.1200, 0.1279, 0.1281, 0.1276, 0.1280, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1203, 0.1200, 0.1201, 0.1268, 0.1282, 0.1280, 0.1278, 0.1286],
        [0.1198, 0.1198, 0.1199, 0.1279, 0.1279, 0.1284, 0.1280, 0.1283],
        [0.1200, 0.1201, 0.1201, 0.1276, 0.1283, 0.1273, 0.1281, 0.1285],
        [0.1199, 0.1199, 0.1199, 0.1275, 0.1285, 0.1282, 0.1279, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1201, 0.1201, 0.1198, 0.1280, 0.1275, 0.1281, 0.1278, 0.1285],
        [0.1201, 0.1202, 0.1202, 0.1274, 0.1280, 0.1279, 0.1279, 0.1284],
        [0.1201, 0.1200, 0.1198, 0.1282, 0.1278, 0.1280, 0.1281, 0.1280],
        [0.1198, 0.1200, 0.1199, 0.1283, 0.1280, 0.1281, 0.1278, 0.1281],
        [0.1200, 0.1200, 0.1200, 0.1279, 0.1278, 0.1281, 0.1279, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1276, 0.1254, 0.1259, 0.1253, 0.1246, 0.1235, 0.1234, 0.1243],
        [0.1227, 0.1217, 0.1254, 0.1263, 0.1270, 0.1266, 0.1252, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1241, 0.1257, 0.1284, 0.1235, 0.1242, 0.1240, 0.1226],
        [0.1226, 0.1218, 0.1274, 0.1265, 0.1266, 0.1268, 0.1231, 0.1253],
        [0.1250, 0.1219, 0.1273, 0.1227, 0.1255, 0.1268, 0.1237, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1278, 0.1243, 0.1253, 0.1233, 0.1252, 0.1273, 0.1236, 0.1233],
        [0.1233, 0.1221, 0.1250, 0.1268, 0.1258, 0.1244, 0.1266, 0.1260],
        [0.1256, 0.1223, 0.1269, 0.1223, 0.1278, 0.1278, 0.1226, 0.1247],
        [0.1229, 0.1217, 0.1254, 0.1244, 0.1263, 0.1251, 0.1272, 0.1269]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1250, 0.1253, 0.1255, 0.1261, 0.1232, 0.1253, 0.1220],
        [0.1223, 0.1215, 0.1245, 0.1255, 0.1263, 0.1270, 0.1275, 0.1255],
        [0.1229, 0.1224, 0.1250, 0.1276, 0.1251, 0.1261, 0.1262, 0.1248],
        [0.1212, 0.1212, 0.1222, 0.1276, 0.1271, 0.1269, 0.1268, 0.1270],
        [0.1214, 0.1214, 0.1228, 0.1268, 0.1273, 0.1261, 0.1262, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:48:07 PM | Train: [47/50] Step 000/001 Loss 0.006 Prec@(1,5) (100.0%, 100.0%)
07/20 10:48:10 PM | Train: [47/50] Step 001/001 Loss 0.260 Prec@(1,5) (88.9%, 100.0%)
07/20 10:48:11 PM | Train: [47/50] Final Prec@1 88.8889%
07/20 10:48:11 PM | Valid: [47/50] Step 000/390 Loss 5.936 Prec@(1,5) (20.3%, 54.7%)
07/20 10:48:20 PM | Valid: [47/50] Step 050/390 Loss 7.100 Prec@(1,5) (16.1%, 59.9%)
07/20 10:48:30 PM | Valid: [47/50] Step 100/390 Loss 7.091 Prec@(1,5) (16.3%, 59.7%)
07/20 10:48:39 PM | Valid: [47/50] Step 150/390 Loss 7.111 Prec@(1,5) (16.3%, 59.1%)
07/20 10:48:48 PM | Valid: [47/50] Step 200/390 Loss 7.134 Prec@(1,5) (16.2%, 59.1%)
07/20 10:48:58 PM | Valid: [47/50] Step 250/390 Loss 7.159 Prec@(1,5) (16.0%, 59.2%)
07/20 10:49:07 PM | Valid: [47/50] Step 300/390 Loss 7.156 Prec@(1,5) (16.0%, 59.1%)
07/20 10:49:16 PM | Valid: [47/50] Step 350/390 Loss 7.142 Prec@(1,5) (16.1%, 59.0%)
07/20 10:49:24 PM | Valid: [47/50] Step 390/390 Loss 7.156 Prec@(1,5) (16.1%, 59.0%)
07/20 10:49:24 PM | Valid: [47/50] Final Prec@1 16.0800%
07/20 10:49:24 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 1)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1219, 0.1209, 0.1211, 0.1280, 0.1282, 0.1242, 0.1280, 0.1277],
        [0.1201, 0.1202, 0.1201, 0.1272, 0.1279, 0.1280, 0.1278, 0.1287]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1206, 0.1208, 0.1207, 0.1281, 0.1274, 0.1269, 0.1274, 0.1279],
        [0.1199, 0.1196, 0.1197, 0.1280, 0.1281, 0.1279, 0.1282, 0.1287],
        [0.1201, 0.1200, 0.1199, 0.1280, 0.1281, 0.1276, 0.1281, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1202, 0.1200, 0.1200, 0.1269, 0.1283, 0.1281, 0.1279, 0.1287],
        [0.1197, 0.1197, 0.1198, 0.1279, 0.1279, 0.1285, 0.1280, 0.1284],
        [0.1199, 0.1200, 0.1200, 0.1276, 0.1284, 0.1274, 0.1281, 0.1286],
        [0.1198, 0.1198, 0.1198, 0.1275, 0.1286, 0.1282, 0.1279, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1201, 0.1200, 0.1197, 0.1280, 0.1276, 0.1281, 0.1278, 0.1286],
        [0.1200, 0.1201, 0.1201, 0.1275, 0.1281, 0.1279, 0.1279, 0.1285],
        [0.1200, 0.1199, 0.1197, 0.1283, 0.1278, 0.1281, 0.1281, 0.1281],
        [0.1197, 0.1199, 0.1198, 0.1284, 0.1280, 0.1281, 0.1279, 0.1281],
        [0.1199, 0.1199, 0.1200, 0.1279, 0.1278, 0.1281, 0.1280, 0.1283]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1277, 0.1254, 0.1259, 0.1252, 0.1246, 0.1235, 0.1234, 0.1242],
        [0.1226, 0.1217, 0.1253, 0.1263, 0.1270, 0.1267, 0.1252, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1241, 0.1257, 0.1285, 0.1235, 0.1242, 0.1239, 0.1225],
        [0.1225, 0.1217, 0.1274, 0.1266, 0.1266, 0.1268, 0.1231, 0.1252],
        [0.1250, 0.1218, 0.1273, 0.1227, 0.1256, 0.1269, 0.1238, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1279, 0.1244, 0.1252, 0.1233, 0.1252, 0.1273, 0.1236, 0.1233],
        [0.1233, 0.1221, 0.1249, 0.1268, 0.1258, 0.1244, 0.1267, 0.1260],
        [0.1256, 0.1223, 0.1269, 0.1222, 0.1278, 0.1279, 0.1226, 0.1247],
        [0.1229, 0.1217, 0.1255, 0.1243, 0.1263, 0.1251, 0.1272, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1250, 0.1254, 0.1255, 0.1261, 0.1232, 0.1253, 0.1219],
        [0.1223, 0.1214, 0.1245, 0.1255, 0.1262, 0.1270, 0.1275, 0.1255],
        [0.1228, 0.1223, 0.1250, 0.1276, 0.1251, 0.1261, 0.1262, 0.1249],
        [0.1211, 0.1212, 0.1222, 0.1276, 0.1272, 0.1269, 0.1268, 0.1270],
        [0.1213, 0.1214, 0.1228, 0.1268, 0.1273, 0.1262, 0.1262, 0.1280]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:49:29 PM | Train: [48/50] Step 000/001 Loss 0.010 Prec@(1,5) (100.0%, 100.0%)
07/20 10:49:32 PM | Train: [48/50] Step 001/001 Loss 0.291 Prec@(1,5) (88.9%, 88.9%)
07/20 10:49:32 PM | Train: [48/50] Final Prec@1 88.8889%
07/20 10:49:33 PM | Valid: [48/50] Step 000/390 Loss 8.794 Prec@(1,5) (14.1%, 46.9%)
07/20 10:49:42 PM | Valid: [48/50] Step 050/390 Loss 8.077 Prec@(1,5) (16.8%, 60.3%)
07/20 10:49:53 PM | Valid: [48/50] Step 100/390 Loss 8.047 Prec@(1,5) (16.9%, 60.2%)
07/20 10:50:02 PM | Valid: [48/50] Step 150/390 Loss 8.113 Prec@(1,5) (16.9%, 59.4%)
07/20 10:50:11 PM | Valid: [48/50] Step 200/390 Loss 8.053 Prec@(1,5) (17.2%, 59.4%)
07/20 10:50:21 PM | Valid: [48/50] Step 250/390 Loss 8.031 Prec@(1,5) (17.3%, 59.6%)
07/20 10:50:30 PM | Valid: [48/50] Step 300/390 Loss 8.042 Prec@(1,5) (17.4%, 59.5%)
07/20 10:50:40 PM | Valid: [48/50] Step 350/390 Loss 8.057 Prec@(1,5) (17.3%, 59.5%)
07/20 10:50:48 PM | Valid: [48/50] Step 390/390 Loss 8.039 Prec@(1,5) (17.3%, 59.4%)
07/20 10:50:48 PM | Valid: [48/50] Final Prec@1 17.2600%
07/20 10:50:48 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 1)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1218, 0.1208, 0.1211, 0.1281, 0.1283, 0.1242, 0.1280, 0.1277],
        [0.1201, 0.1202, 0.1201, 0.1272, 0.1279, 0.1280, 0.1278, 0.1287]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1205, 0.1207, 0.1206, 0.1282, 0.1275, 0.1270, 0.1275, 0.1280],
        [0.1198, 0.1195, 0.1196, 0.1281, 0.1281, 0.1280, 0.1283, 0.1287],
        [0.1200, 0.1200, 0.1198, 0.1281, 0.1282, 0.1277, 0.1282, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1201, 0.1199, 0.1199, 0.1269, 0.1283, 0.1282, 0.1280, 0.1288],
        [0.1197, 0.1196, 0.1198, 0.1280, 0.1280, 0.1285, 0.1280, 0.1284],
        [0.1199, 0.1199, 0.1199, 0.1277, 0.1284, 0.1274, 0.1281, 0.1286],
        [0.1197, 0.1197, 0.1197, 0.1276, 0.1287, 0.1283, 0.1280, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1200, 0.1199, 0.1197, 0.1281, 0.1277, 0.1282, 0.1279, 0.1286],
        [0.1199, 0.1200, 0.1200, 0.1275, 0.1281, 0.1280, 0.1280, 0.1286],
        [0.1199, 0.1198, 0.1196, 0.1283, 0.1279, 0.1282, 0.1282, 0.1281],
        [0.1196, 0.1198, 0.1197, 0.1284, 0.1281, 0.1281, 0.1280, 0.1282],
        [0.1198, 0.1199, 0.1199, 0.1280, 0.1279, 0.1282, 0.1280, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1278, 0.1255, 0.1259, 0.1252, 0.1246, 0.1236, 0.1233, 0.1242],
        [0.1226, 0.1216, 0.1253, 0.1263, 0.1270, 0.1267, 0.1253, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1275, 0.1241, 0.1257, 0.1286, 0.1235, 0.1242, 0.1239, 0.1224],
        [0.1224, 0.1216, 0.1275, 0.1267, 0.1266, 0.1268, 0.1231, 0.1252],
        [0.1249, 0.1218, 0.1273, 0.1227, 0.1256, 0.1269, 0.1238, 0.1271]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1279, 0.1244, 0.1251, 0.1232, 0.1252, 0.1273, 0.1236, 0.1232],
        [0.1232, 0.1220, 0.1249, 0.1268, 0.1258, 0.1244, 0.1268, 0.1261],
        [0.1256, 0.1222, 0.1270, 0.1222, 0.1279, 0.1279, 0.1225, 0.1247],
        [0.1228, 0.1217, 0.1256, 0.1243, 0.1264, 0.1251, 0.1272, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1276, 0.1251, 0.1253, 0.1255, 0.1261, 0.1232, 0.1252, 0.1219],
        [0.1223, 0.1214, 0.1245, 0.1255, 0.1262, 0.1271, 0.1275, 0.1255],
        [0.1228, 0.1223, 0.1251, 0.1276, 0.1250, 0.1260, 0.1262, 0.1250],
        [0.1210, 0.1212, 0.1222, 0.1276, 0.1272, 0.1269, 0.1268, 0.1271],
        [0.1213, 0.1213, 0.1228, 0.1268, 0.1273, 0.1262, 0.1262, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:50:53 PM | Train: [49/50] Step 000/001 Loss 0.003 Prec@(1,5) (100.0%, 100.0%)
07/20 10:50:56 PM | Train: [49/50] Step 001/001 Loss 0.276 Prec@(1,5) (88.9%, 88.9%)
07/20 10:50:56 PM | Train: [49/50] Final Prec@1 88.8889%
07/20 10:50:57 PM | Valid: [49/50] Step 000/390 Loss 10.119 Prec@(1,5) (17.2%, 57.8%)
07/20 10:51:06 PM | Valid: [49/50] Step 050/390 Loss 9.855 Prec@(1,5) (17.5%, 58.3%)
07/20 10:51:15 PM | Valid: [49/50] Step 100/390 Loss 9.774 Prec@(1,5) (17.2%, 59.5%)
07/20 10:51:24 PM | Valid: [49/50] Step 150/390 Loss 9.732 Prec@(1,5) (17.2%, 59.3%)
07/20 10:51:34 PM | Valid: [49/50] Step 200/390 Loss 9.782 Prec@(1,5) (17.1%, 59.5%)
07/20 10:51:43 PM | Valid: [49/50] Step 250/390 Loss 9.763 Prec@(1,5) (17.0%, 59.3%)
07/20 10:51:52 PM | Valid: [49/50] Step 300/390 Loss 9.747 Prec@(1,5) (17.1%, 59.4%)
07/20 10:52:03 PM | Valid: [49/50] Step 350/390 Loss 9.754 Prec@(1,5) (17.0%, 59.2%)
07/20 10:52:12 PM | Valid: [49/50] Step 390/390 Loss 9.756 Prec@(1,5) (16.9%, 59.2%)
07/20 10:52:12 PM | Valid: [49/50] Final Prec@1 16.8560%
07/20 10:52:12 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 1)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
####### ALPHA #######
# Alpha - normal
tensor([[0.1217, 0.1208, 0.1210, 0.1281, 0.1283, 0.1242, 0.1281, 0.1278],
        [0.1200, 0.1201, 0.1200, 0.1273, 0.1280, 0.1281, 0.1279, 0.1288]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1205, 0.1207, 0.1206, 0.1282, 0.1276, 0.1270, 0.1275, 0.1280],
        [0.1197, 0.1194, 0.1195, 0.1281, 0.1282, 0.1280, 0.1284, 0.1287],
        [0.1199, 0.1199, 0.1198, 0.1281, 0.1282, 0.1277, 0.1282, 0.1282]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1200, 0.1198, 0.1198, 0.1270, 0.1284, 0.1283, 0.1280, 0.1288],
        [0.1196, 0.1195, 0.1197, 0.1281, 0.1280, 0.1286, 0.1281, 0.1285],
        [0.1198, 0.1198, 0.1199, 0.1277, 0.1285, 0.1275, 0.1282, 0.1287],
        [0.1196, 0.1196, 0.1196, 0.1277, 0.1287, 0.1283, 0.1280, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1199, 0.1199, 0.1196, 0.1281, 0.1277, 0.1282, 0.1279, 0.1287],
        [0.1198, 0.1199, 0.1199, 0.1276, 0.1282, 0.1280, 0.1280, 0.1286],
        [0.1198, 0.1197, 0.1196, 0.1283, 0.1280, 0.1282, 0.1282, 0.1282],
        [0.1195, 0.1197, 0.1197, 0.1285, 0.1282, 0.1282, 0.1280, 0.1283],
        [0.1197, 0.1198, 0.1198, 0.1281, 0.1280, 0.1282, 0.1280, 0.1284]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1278, 0.1255, 0.1259, 0.1251, 0.1246, 0.1236, 0.1233, 0.1242],
        [0.1226, 0.1216, 0.1252, 0.1263, 0.1271, 0.1268, 0.1253, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1276, 0.1242, 0.1256, 0.1287, 0.1234, 0.1243, 0.1239, 0.1224],
        [0.1224, 0.1215, 0.1276, 0.1268, 0.1266, 0.1269, 0.1231, 0.1251],
        [0.1249, 0.1217, 0.1273, 0.1226, 0.1256, 0.1269, 0.1237, 0.1272]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1279, 0.1244, 0.1252, 0.1232, 0.1252, 0.1273, 0.1237, 0.1231],
        [0.1232, 0.1220, 0.1250, 0.1267, 0.1258, 0.1244, 0.1268, 0.1261],
        [0.1256, 0.1222, 0.1271, 0.1221, 0.1279, 0.1279, 0.1224, 0.1247],
        [0.1228, 0.1216, 0.1256, 0.1242, 0.1264, 0.1251, 0.1272, 0.1270]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1277, 0.1251, 0.1253, 0.1255, 0.1262, 0.1231, 0.1252, 0.1218],
        [0.1222, 0.1213, 0.1245, 0.1255, 0.1262, 0.1271, 0.1276, 0.1256],
        [0.1227, 0.1223, 0.1251, 0.1276, 0.1250, 0.1260, 0.1262, 0.1250],
        [0.1209, 0.1211, 0.1221, 0.1277, 0.1273, 0.1269, 0.1268, 0.1271],
        [0.1212, 0.1213, 0.1227, 0.1268, 0.1274, 0.1263, 0.1262, 0.1281]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/20 10:52:17 PM | Train: [50/50] Step 000/001 Loss 0.001 Prec@(1,5) (100.0%, 100.0%)
07/20 10:52:21 PM | Train: [50/50] Step 001/001 Loss 0.178 Prec@(1,5) (100.0%, 100.0%)
07/20 10:52:21 PM | Train: [50/50] Final Prec@1 100.0000%
07/20 10:52:21 PM | Valid: [50/50] Step 000/390 Loss 7.532 Prec@(1,5) (12.5%, 64.1%)
07/20 10:52:31 PM | Valid: [50/50] Step 050/390 Loss 6.969 Prec@(1,5) (18.6%, 60.0%)
07/20 10:52:40 PM | Valid: [50/50] Step 100/390 Loss 7.041 Prec@(1,5) (18.1%, 59.6%)
07/20 10:52:49 PM | Valid: [50/50] Step 150/390 Loss 6.993 Prec@(1,5) (18.4%, 59.6%)
07/20 10:52:59 PM | Valid: [50/50] Step 200/390 Loss 7.007 Prec@(1,5) (18.4%, 59.5%)
07/20 10:53:08 PM | Valid: [50/50] Step 250/390 Loss 7.014 Prec@(1,5) (18.6%, 59.4%)
07/20 10:53:17 PM | Valid: [50/50] Step 300/390 Loss 7.028 Prec@(1,5) (18.4%, 59.3%)
07/20 10:53:27 PM | Valid: [50/50] Step 350/390 Loss 7.026 Prec@(1,5) (18.4%, 59.5%)
07/20 10:53:34 PM | Valid: [50/50] Step 390/390 Loss 7.036 Prec@(1,5) (18.4%, 59.5%)
07/20 10:53:34 PM | Valid: [50/50] Final Prec@1 18.3960%
07/20 10:53:34 PM | genotype = Genotype(normal=[[('dil_conv_3x3', 1), ('sep_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('sep_conv_5x5', 3), ('dil_conv_3x3', 1)], [('sep_conv_3x3', 3), ('sep_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_5x5', 1)], [('sep_conv_3x3', 0), ('skip_connect', 1)], [('dil_conv_3x3', 2), ('max_pool_3x3', 0)], [('sep_conv_3x3', 3), ('dil_conv_5x5', 1)]], reduce_concat=range(2, 6))
07/20 10:53:35 PM | Final best Prec@1 = 20.1080%
07/20 10:53:35 PM | Best Genotype = Genotype(normal=[[('sep_conv_5x5', 1), ('dil_conv_5x5', 0)], [('dil_conv_5x5', 1), ('sep_conv_5x5', 2)], [('dil_conv_3x3', 1), ('dil_conv_3x3', 3)], [('sep_conv_3x3', 3), ('dil_conv_3x3', 2)]], normal_concat=range(2, 6), reduce=[[('max_pool_3x3', 0), ('sep_conv_3x3', 1)], [('skip_connect', 2), ('sep_conv_3x3', 0)], [('max_pool_3x3', 0), ('dil_conv_3x3', 2)], [('dil_conv_5x5', 1), ('dil_conv_3x3', 3)]], reduce_concat=range(2, 6))
