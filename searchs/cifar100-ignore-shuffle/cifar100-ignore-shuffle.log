07/29 12:38:12 AM | 
07/29 12:38:12 AM | Parameters:
07/29 12:38:12 AM | ALPHA_LR=0.0003
07/29 12:38:12 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:38:12 AM | BATCH_SIZE=64
07/29 12:38:12 AM | DATA_PATH=./data/
07/29 12:38:12 AM | DATASET=cifar100
07/29 12:38:12 AM | EPOCHS=50
07/29 12:38:12 AM | GPUS=[0]
07/29 12:38:12 AM | INIT_CHANNELS=16
07/29 12:38:12 AM | LAYERS=8
07/29 12:38:12 AM | NAME=cifar100-ignore-shuffle
07/29 12:38:12 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:38:12 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:38:12 AM | PRINT_FREQ=50
07/29 12:38:12 AM | SEED=2
07/29 12:38:12 AM | W_GRAD_CLIP=5.0
07/29 12:38:12 AM | W_LR=0.025
07/29 12:38:12 AM | W_LR_MIN=0.001
07/29 12:38:12 AM | W_MOMENTUM=0.9
07/29 12:38:12 AM | W_WEIGHT_DECAY=0.0003
07/29 12:38:12 AM | WORKERS=4
07/29 12:38:12 AM | 
07/29 12:38:12 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:39:04 AM | 
07/29 12:39:04 AM | Parameters:
07/29 12:39:04 AM | ALPHA_LR=0.0003
07/29 12:39:04 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:39:04 AM | BATCH_SIZE=64
07/29 12:39:04 AM | DATA_PATH=./data/
07/29 12:39:04 AM | DATASET=cifar100
07/29 12:39:04 AM | EPOCHS=50
07/29 12:39:04 AM | GPUS=[0]
07/29 12:39:04 AM | INIT_CHANNELS=16
07/29 12:39:04 AM | LAYERS=8
07/29 12:39:04 AM | NAME=cifar100-ignore-shuffle
07/29 12:39:04 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:39:04 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:39:04 AM | PRINT_FREQ=50
07/29 12:39:04 AM | SEED=2
07/29 12:39:04 AM | W_GRAD_CLIP=5.0
07/29 12:39:04 AM | W_LR=0.025
07/29 12:39:04 AM | W_LR_MIN=0.001
07/29 12:39:04 AM | W_MOMENTUM=0.9
07/29 12:39:04 AM | W_WEIGHT_DECAY=0.0003
07/29 12:39:04 AM | WORKERS=4
07/29 12:39:04 AM | 
07/29 12:39:04 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:39:54 AM | 
07/29 12:39:54 AM | Parameters:
07/29 12:39:54 AM | ALPHA_LR=0.0003
07/29 12:39:54 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:39:54 AM | BATCH_SIZE=48
07/29 12:39:54 AM | DATA_PATH=./data/
07/29 12:39:54 AM | DATASET=cifar100
07/29 12:39:54 AM | EPOCHS=50
07/29 12:39:54 AM | GPUS=[0]
07/29 12:39:54 AM | INIT_CHANNELS=16
07/29 12:39:54 AM | LAYERS=8
07/29 12:39:54 AM | NAME=cifar100-ignore-shuffle
07/29 12:39:54 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:39:54 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:39:54 AM | PRINT_FREQ=50
07/29 12:39:54 AM | SEED=2
07/29 12:39:54 AM | W_GRAD_CLIP=5.0
07/29 12:39:54 AM | W_LR=0.025
07/29 12:39:54 AM | W_LR_MIN=0.001
07/29 12:39:54 AM | W_MOMENTUM=0.9
07/29 12:39:54 AM | W_WEIGHT_DECAY=0.0003
07/29 12:39:54 AM | WORKERS=4
07/29 12:39:54 AM | 
07/29 12:39:54 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:40:19 AM | 
07/29 12:40:19 AM | Parameters:
07/29 12:40:19 AM | ALPHA_LR=0.0003
07/29 12:40:19 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:40:19 AM | BATCH_SIZE=32
07/29 12:40:19 AM | DATA_PATH=./data/
07/29 12:40:19 AM | DATASET=cifar100
07/29 12:40:19 AM | EPOCHS=50
07/29 12:40:19 AM | GPUS=[0]
07/29 12:40:19 AM | INIT_CHANNELS=16
07/29 12:40:19 AM | LAYERS=8
07/29 12:40:19 AM | NAME=cifar100-ignore-shuffle
07/29 12:40:19 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:40:19 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:40:19 AM | PRINT_FREQ=50
07/29 12:40:19 AM | SEED=2
07/29 12:40:19 AM | W_GRAD_CLIP=5.0
07/29 12:40:19 AM | W_LR=0.025
07/29 12:40:19 AM | W_LR_MIN=0.001
07/29 12:40:19 AM | W_MOMENTUM=0.9
07/29 12:40:19 AM | W_WEIGHT_DECAY=0.0003
07/29 12:40:19 AM | WORKERS=4
07/29 12:40:19 AM | 
07/29 12:40:19 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:40:33 AM | loss = 4.765181541442871
07/29 12:41:11 AM | 
07/29 12:41:11 AM | Parameters:
07/29 12:41:11 AM | ALPHA_LR=0.0003
07/29 12:41:11 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:41:11 AM | BATCH_SIZE=32
07/29 12:41:11 AM | DATA_PATH=./data/
07/29 12:41:11 AM | DATASET=cifar100
07/29 12:41:11 AM | EPOCHS=50
07/29 12:41:11 AM | GPUS=[0]
07/29 12:41:11 AM | INIT_CHANNELS=16
07/29 12:41:11 AM | LAYERS=8
07/29 12:41:11 AM | NAME=cifar100-ignore-shuffle
07/29 12:41:11 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:41:11 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:41:11 AM | PRINT_FREQ=50
07/29 12:41:11 AM | SEED=2
07/29 12:41:11 AM | W_GRAD_CLIP=5.0
07/29 12:41:11 AM | W_LR=0.025
07/29 12:41:11 AM | W_LR_MIN=0.001
07/29 12:41:11 AM | W_MOMENTUM=0.9
07/29 12:41:11 AM | W_WEIGHT_DECAY=0.0003
07/29 12:41:11 AM | WORKERS=4
07/29 12:41:11 AM | 
07/29 12:41:11 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:41:26 AM | loss = 4.765181541442871
07/29 12:47:09 AM | 
07/29 12:47:09 AM | Parameters:
07/29 12:47:09 AM | ALPHA_LR=0.0003
07/29 12:47:09 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:47:09 AM | BATCH_SIZE=32
07/29 12:47:09 AM | DATA_PATH=./data/
07/29 12:47:09 AM | DATASET=cifar100
07/29 12:47:09 AM | EPOCHS=50
07/29 12:47:09 AM | GPUS=[0]
07/29 12:47:09 AM | INIT_CHANNELS=16
07/29 12:47:09 AM | LAYERS=8
07/29 12:47:09 AM | NAME=cifar100-ignore-shuffle
07/29 12:47:09 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:47:09 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:47:09 AM | PRINT_FREQ=50
07/29 12:47:09 AM | SEED=2
07/29 12:47:09 AM | W_GRAD_CLIP=5.0
07/29 12:47:09 AM | W_LR=0.025
07/29 12:47:09 AM | W_LR_MIN=0.001
07/29 12:47:09 AM | W_MOMENTUM=0.9
07/29 12:47:09 AM | W_WEIGHT_DECAY=0.0003
07/29 12:47:09 AM | WORKERS=4
07/29 12:47:09 AM | 
07/29 12:47:09 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:49:41 AM | 
07/29 12:49:41 AM | Parameters:
07/29 12:49:41 AM | ALPHA_LR=0.0003
07/29 12:49:41 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:49:41 AM | BATCH_SIZE=32
07/29 12:49:41 AM | DATA_PATH=./data/
07/29 12:49:41 AM | DATASET=cifar100
07/29 12:49:41 AM | EPOCHS=50
07/29 12:49:41 AM | GPUS=[0]
07/29 12:49:41 AM | INIT_CHANNELS=16
07/29 12:49:41 AM | LAYERS=8
07/29 12:49:41 AM | NAME=cifar100-ignore-shuffle
07/29 12:49:41 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:49:41 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:49:41 AM | PRINT_FREQ=50
07/29 12:49:41 AM | SEED=2
07/29 12:49:41 AM | W_GRAD_CLIP=5.0
07/29 12:49:41 AM | W_LR=0.025
07/29 12:49:41 AM | W_LR_MIN=0.001
07/29 12:49:41 AM | W_MOMENTUM=0.9
07/29 12:49:41 AM | W_WEIGHT_DECAY=0.0003
07/29 12:49:41 AM | WORKERS=4
07/29 12:49:41 AM | 
07/29 12:49:41 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:49:57 AM | loss = 4.765181541442871
07/29 12:54:29 AM | 
07/29 12:54:29 AM | Parameters:
07/29 12:54:29 AM | ALPHA_LR=0.0003
07/29 12:54:29 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:54:29 AM | BATCH_SIZE=32
07/29 12:54:29 AM | DATA_PATH=./data/
07/29 12:54:29 AM | DATASET=cifar100
07/29 12:54:29 AM | EPOCHS=50
07/29 12:54:29 AM | GPUS=[0]
07/29 12:54:29 AM | INIT_CHANNELS=16
07/29 12:54:29 AM | LAYERS=8
07/29 12:54:29 AM | NAME=cifar100-ignore-shuffle
07/29 12:54:29 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:54:29 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:54:29 AM | PRINT_FREQ=50
07/29 12:54:29 AM | SEED=2
07/29 12:54:29 AM | W_GRAD_CLIP=5.0
07/29 12:54:29 AM | W_LR=0.025
07/29 12:54:29 AM | W_LR_MIN=0.001
07/29 12:54:29 AM | W_MOMENTUM=0.9
07/29 12:54:29 AM | W_WEIGHT_DECAY=0.0003
07/29 12:54:29 AM | WORKERS=4
07/29 12:54:29 AM | 
07/29 12:54:29 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:54:44 AM | loss = 4.765181541442871
07/29 12:54:44 AM | loss = 152.48577880859375
07/29 12:56:01 AM | 
07/29 12:56:01 AM | Parameters:
07/29 12:56:01 AM | ALPHA_LR=0.0003
07/29 12:56:01 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 12:56:01 AM | BATCH_SIZE=32
07/29 12:56:01 AM | DATA_PATH=./data/
07/29 12:56:01 AM | DATASET=cifar100
07/29 12:56:01 AM | EPOCHS=50
07/29 12:56:01 AM | GPUS=[0]
07/29 12:56:01 AM | INIT_CHANNELS=16
07/29 12:56:01 AM | LAYERS=8
07/29 12:56:01 AM | NAME=cifar100-ignore-shuffle
07/29 12:56:01 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 12:56:01 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 12:56:01 AM | PRINT_FREQ=50
07/29 12:56:01 AM | SEED=2
07/29 12:56:01 AM | W_GRAD_CLIP=5.0
07/29 12:56:01 AM | W_LR=0.025
07/29 12:56:01 AM | W_LR_MIN=0.001
07/29 12:56:01 AM | W_MOMENTUM=0.9
07/29 12:56:01 AM | W_WEIGHT_DECAY=0.0003
07/29 12:56:01 AM | WORKERS=4
07/29 12:56:01 AM | 
07/29 12:56:01 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 12:56:16 AM | loss = 4.765181541442871
07/29 12:56:16 AM | loss = 152.48580932617188
07/29 12:56:16 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 12:56:17 AM | Train: [ 1/50] Step 000/781 Loss 152.486 Prec@(1,5) (0.0%, 3.1%)
07/29 12:56:21 AM | loss = 4.639216423034668
07/29 12:56:21 AM | loss = 148.41036987304688
07/29 12:56:21 AM | Likelihood = Parameter containing:
tensor([0.9997, 0.9997, 0.9997,  ..., 0.9997, 0.9997, 0.9997], device='cuda:0',
       requires_grad=True), Likelihood sum=24992.50390625, dataIndex = 64, step = 1
07/29 12:56:26 AM | loss = 4.606001853942871
07/29 12:56:26 AM | loss = 147.30123901367188
07/29 12:56:26 AM | Likelihood = Parameter containing:
tensor([0.9994, 0.9994, 0.9994,  ..., 0.9994, 0.9994, 0.9994], device='cuda:0',
       requires_grad=True), Likelihood sum=24984.59765625, dataIndex = 96, step = 2
07/29 01:09:53 AM | 
07/29 01:09:53 AM | Parameters:
07/29 01:09:53 AM | ALPHA_LR=0.0003
07/29 01:09:53 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:09:53 AM | BATCH_SIZE=32
07/29 01:09:53 AM | DATA_PATH=./data/
07/29 01:09:53 AM | DATASET=cifar100
07/29 01:09:53 AM | EPOCHS=50
07/29 01:09:53 AM | GPUS=[0]
07/29 01:09:53 AM | INIT_CHANNELS=16
07/29 01:09:53 AM | LAYERS=8
07/29 01:09:53 AM | NAME=cifar100-ignore-shuffle
07/29 01:09:53 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:09:53 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:09:53 AM | PRINT_FREQ=50
07/29 01:09:53 AM | SEED=2
07/29 01:09:53 AM | W_GRAD_CLIP=5.0
07/29 01:09:53 AM | W_LR=0.025
07/29 01:09:53 AM | W_LR_MIN=0.001
07/29 01:09:53 AM | W_MOMENTUM=0.9
07/29 01:09:53 AM | W_WEIGHT_DECAY=0.0003
07/29 01:09:53 AM | WORKERS=4
07/29 01:09:53 AM | 
07/29 01:09:53 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:10:08 AM | loss = 4.765181541442871
07/29 01:10:08 AM | loss = 0.006099431775510311
07/29 01:10:08 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 01:10:09 AM | Train: [ 1/50] Step 000/781 Loss 0.006 Prec@(1,5) (0.0%, 3.1%)
07/29 01:12:09 AM | 
07/29 01:12:09 AM | Parameters:
07/29 01:12:09 AM | ALPHA_LR=0.0003
07/29 01:12:09 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:12:09 AM | BATCH_SIZE=32
07/29 01:12:09 AM | DATA_PATH=./data/
07/29 01:12:09 AM | DATASET=cifar100
07/29 01:12:09 AM | EPOCHS=50
07/29 01:12:09 AM | GPUS=[0]
07/29 01:12:09 AM | INIT_CHANNELS=16
07/29 01:12:09 AM | LAYERS=8
07/29 01:12:09 AM | NAME=cifar100-ignore-shuffle
07/29 01:12:09 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:12:09 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:12:09 AM | PRINT_FREQ=50
07/29 01:12:09 AM | SEED=2
07/29 01:12:09 AM | W_GRAD_CLIP=5.0
07/29 01:12:09 AM | W_LR=0.025
07/29 01:12:09 AM | W_LR_MIN=0.001
07/29 01:12:09 AM | W_MOMENTUM=0.9
07/29 01:12:09 AM | W_WEIGHT_DECAY=0.0003
07/29 01:12:09 AM | WORKERS=4
07/29 01:12:09 AM | 
07/29 01:12:09 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:12:25 AM | loss = 4.765181541442871
07/29 01:12:25 AM | loss———— = 4.877191543579102
07/29 01:12:25 AM | loss———— = tensor([4.8772, 4.5715, 4.7052, 4.9290, 4.7293, 4.7218, 4.6398, 4.6100, 4.7141,
        4.6351, 4.5255, 4.5203, 4.6408, 4.5560, 4.4305, 5.2181, 4.9373, 4.6088,
        5.5133, 4.6343, 4.5341, 4.9218, 4.6411, 5.4065, 5.3654, 4.1438, 5.0394,
        4.8052, 4.4345, 5.0565, 4.6522, 4.7674], device='cuda:0',
       grad_fn=<NllLossBackward>)
07/29 01:12:25 AM | loss = 0.0060994322411715984
07/29 01:12:25 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 01:12:26 AM | Train: [ 1/50] Step 000/781 Loss 0.006 Prec@(1,5) (0.0%, 3.1%)
07/29 01:14:49 AM | 
07/29 01:14:49 AM | Parameters:
07/29 01:14:49 AM | ALPHA_LR=0.0003
07/29 01:14:49 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:14:49 AM | BATCH_SIZE=32
07/29 01:14:49 AM | DATA_PATH=./data/
07/29 01:14:49 AM | DATASET=cifar100
07/29 01:14:49 AM | EPOCHS=50
07/29 01:14:49 AM | GPUS=[0]
07/29 01:14:49 AM | INIT_CHANNELS=16
07/29 01:14:49 AM | LAYERS=8
07/29 01:14:49 AM | NAME=cifar100-ignore-shuffle
07/29 01:14:49 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:14:49 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:14:49 AM | PRINT_FREQ=50
07/29 01:14:49 AM | SEED=2
07/29 01:14:49 AM | W_GRAD_CLIP=5.0
07/29 01:14:49 AM | W_LR=0.025
07/29 01:14:49 AM | W_LR_MIN=0.001
07/29 01:14:49 AM | W_MOMENTUM=0.9
07/29 01:14:49 AM | W_WEIGHT_DECAY=0.0003
07/29 01:14:49 AM | WORKERS=4
07/29 01:14:49 AM | 
07/29 01:14:49 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:38:39 AM | 
07/29 01:38:39 AM | Parameters:
07/29 01:38:39 AM | ALPHA_LR=0.0003
07/29 01:38:39 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:38:39 AM | BATCH_SIZE=32
07/29 01:38:39 AM | DATA_PATH=./data/
07/29 01:38:39 AM | DATASET=cifar100
07/29 01:38:39 AM | EPOCHS=50
07/29 01:38:39 AM | GPUS=[0]
07/29 01:38:39 AM | INIT_CHANNELS=16
07/29 01:38:39 AM | LAYERS=8
07/29 01:38:39 AM | NAME=cifar100-ignore-shuffle
07/29 01:38:39 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:38:39 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:38:39 AM | PRINT_FREQ=50
07/29 01:38:39 AM | SEED=2
07/29 01:38:39 AM | W_GRAD_CLIP=5.0
07/29 01:38:39 AM | W_LR=0.025
07/29 01:38:39 AM | W_LR_MIN=0.001
07/29 01:38:39 AM | W_MOMENTUM=0.9
07/29 01:38:39 AM | W_WEIGHT_DECAY=0.0003
07/29 01:38:39 AM | WORKERS=4
07/29 01:38:39 AM | 
07/29 01:38:39 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:38:55 AM | loss = 4.765181541442871
07/29 01:38:55 AM | loss———— = 4.877191066741943
07/29 01:38:55 AM | loss———— = tensor([4.8772, 4.5715, 4.7052, 4.9290, 4.7293, 4.7218, 4.6398, 4.6100, 4.7141,
        4.6351, 4.5255, 4.5203, 4.6408, 4.5560, 4.4305, 5.2181, 4.9373, 4.6088,
        5.5133, 4.6343, 4.5341, 4.9218, 4.6411, 5.4065, 5.3654, 4.1438, 5.0394,
        4.8052, 4.4345, 5.0565, 4.6522, 4.7674], device='cuda:0',
       grad_fn=<NllLossBackward>)
07/29 01:38:55 AM | loss = 4.765180587768555
07/29 01:38:55 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 01:38:55 AM | Train: [ 1/50] Step 000/781 Loss 4.765 Prec@(1,5) (0.0%, 3.1%)
07/29 01:38:59 AM | loss = 4.639214515686035
07/29 01:39:00 AM | loss———— = 5.361323356628418
07/29 01:39:00 AM | loss———— = tensor([5.3613, 4.3177, 4.5239, 4.4995, 6.0953, 5.1686, 3.8511, 5.2576, 4.7543,
        4.9405, 5.3860, 4.7042, 4.3414, 4.8561, 4.5981, 4.8079, 3.9545, 4.3163,
        4.3865, 4.8795, 4.6923, 4.7720, 4.5546, 4.8497, 4.1187, 3.9263, 4.5040,
        4.0618, 3.9887, 4.9871, 4.0632, 4.9361], device='cuda:0',
       grad_fn=<NllLossBackward>)
07/29 01:39:00 AM | loss = 4.639214515686035
07/29 01:39:00 AM | Likelihood = Parameter containing:
tensor([0.9997, 1.0003, 1.0003,  ..., 0.9997, 0.9997, 0.9997], device='cuda:0',
       requires_grad=True), Likelihood sum=24992.515625, dataIndex = 64, step = 1
07/29 01:41:08 AM | 
07/29 01:41:08 AM | Parameters:
07/29 01:41:08 AM | ALPHA_LR=0.0003
07/29 01:41:08 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:41:08 AM | BATCH_SIZE=32
07/29 01:41:08 AM | DATA_PATH=./data/
07/29 01:41:08 AM | DATASET=cifar100
07/29 01:41:08 AM | EPOCHS=50
07/29 01:41:08 AM | GPUS=[0]
07/29 01:41:08 AM | INIT_CHANNELS=16
07/29 01:41:08 AM | LAYERS=8
07/29 01:41:08 AM | NAME=cifar100-ignore-shuffle
07/29 01:41:08 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:41:08 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:41:08 AM | PRINT_FREQ=50
07/29 01:41:08 AM | SEED=2
07/29 01:41:08 AM | W_GRAD_CLIP=5.0
07/29 01:41:08 AM | W_LR=0.025
07/29 01:41:08 AM | W_LR_MIN=0.001
07/29 01:41:08 AM | W_MOMENTUM=0.9
07/29 01:41:08 AM | W_WEIGHT_DECAY=0.0003
07/29 01:41:08 AM | WORKERS=4
07/29 01:41:08 AM | 
07/29 01:41:08 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:41:23 AM | loss = 4.765181541442871
07/29 01:41:23 AM | loss = 4.765181541442871
07/29 01:41:23 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 01:41:24 AM | Train: [ 1/50] Step 000/781 Loss 4.765 Prec@(1,5) (0.0%, 3.1%)
07/29 01:41:28 AM | loss = 4.639219760894775
07/29 01:41:28 AM | loss = 4.639220237731934
07/29 01:41:28 AM | Likelihood = Parameter containing:
tensor([0.9997, 1.0003, 1.0003,  ..., 0.9997, 0.9997, 0.9997], device='cuda:0',
       requires_grad=True), Likelihood sum=24992.515625, dataIndex = 64, step = 1
07/29 01:41:33 AM | loss = 4.6056318283081055
07/29 01:41:33 AM | loss = 4.605632305145264
07/29 01:41:33 AM | Likelihood = Parameter containing:
tensor([0.9994, 1.0006, 1.0004,  ..., 0.9994, 0.9994, 0.9994], device='cuda:0',
       requires_grad=True), Likelihood sum=24984.626953125, dataIndex = 96, step = 2
07/29 01:41:38 AM | loss = 4.799814701080322
07/29 01:41:38 AM | loss = 4.7998151779174805
07/29 01:41:38 AM | Likelihood = Parameter containing:
tensor([0.9991, 1.0009, 1.0002,  ..., 0.9990, 0.9990, 0.9990], device='cuda:0',
       requires_grad=True), Likelihood sum=24976.22265625, dataIndex = 128, step = 3
07/29 01:41:43 AM | loss = 4.659891605377197
07/29 01:41:43 AM | loss = 4.659892559051514
07/29 01:41:43 AM | Likelihood = Parameter containing:
tensor([0.9987, 1.0011, 0.9999,  ..., 0.9987, 0.9987, 0.9987], device='cuda:0',
       requires_grad=True), Likelihood sum=24967.3125, dataIndex = 160, step = 4
07/29 01:45:45 AM | 
07/29 01:45:45 AM | Parameters:
07/29 01:45:45 AM | ALPHA_LR=0.0003
07/29 01:45:45 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 01:45:45 AM | BATCH_SIZE=32
07/29 01:45:45 AM | DATA_PATH=./data/
07/29 01:45:45 AM | DATASET=cifar100
07/29 01:45:45 AM | EPOCHS=50
07/29 01:45:45 AM | GPUS=[0]
07/29 01:45:45 AM | INIT_CHANNELS=16
07/29 01:45:45 AM | LAYERS=8
07/29 01:45:45 AM | NAME=cifar100-ignore-shuffle
07/29 01:45:45 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 01:45:45 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 01:45:45 AM | PRINT_FREQ=50
07/29 01:45:45 AM | SEED=2
07/29 01:45:45 AM | W_GRAD_CLIP=5.0
07/29 01:45:45 AM | W_LR=0.025
07/29 01:45:45 AM | W_LR_MIN=0.001
07/29 01:45:45 AM | W_MOMENTUM=0.9
07/29 01:45:45 AM | W_WEIGHT_DECAY=0.0003
07/29 01:45:45 AM | WORKERS=4
07/29 01:45:45 AM | 
07/29 01:45:45 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 01:46:00 AM | loss = 4.765181541442871
07/29 01:46:00 AM | loss = 4.765181541442871
07/29 01:46:00 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 01:46:00 AM | Train: [ 1/50] Step 000/781 Loss 4.765 Prec@(1,5) (0.0%, 3.1%)
07/29 01:46:05 AM | loss = 4.639214515686035
07/29 01:46:05 AM | loss = 4.639214515686035
07/29 01:46:05 AM | Likelihood = Parameter containing:
tensor([0.9997, 1.0003, 1.0003,  ..., 0.9997, 0.9997, 0.9997], device='cuda:0',
       requires_grad=True), Likelihood sum=24992.515625, dataIndex = 64, step = 1
07/29 01:46:10 AM | loss = 4.606084823608398
07/29 01:46:10 AM | loss = 4.60608434677124
07/29 01:46:10 AM | Likelihood = Parameter containing:
tensor([0.9994, 1.0006, 1.0004,  ..., 0.9994, 0.9994, 0.9994], device='cuda:0',
       requires_grad=True), Likelihood sum=24984.626953125, dataIndex = 96, step = 2
07/29 01:46:15 AM | loss = 4.801674842834473
07/29 01:46:15 AM | loss = 4.801675319671631
07/29 01:46:15 AM | Likelihood = Parameter containing:
tensor([0.9991, 1.0009, 1.0002,  ..., 0.9990, 0.9990, 0.9990], device='cuda:0',
       requires_grad=True), Likelihood sum=24976.22265625, dataIndex = 128, step = 3
07/29 01:46:20 AM | loss = 4.662606716156006
07/29 01:46:20 AM | loss = 4.662607192993164
07/29 01:46:20 AM | Likelihood = Parameter containing:
tensor([0.9987, 1.0011, 0.9999,  ..., 0.9987, 0.9987, 0.9987], device='cuda:0',
       requires_grad=True), Likelihood sum=24967.3125, dataIndex = 160, step = 4
07/29 01:46:26 AM | loss = 4.599928855895996
07/29 01:46:26 AM | loss = 4.599928379058838
07/29 01:46:26 AM | Likelihood = Parameter containing:
tensor([0.9984, 1.0012, 0.9995,  ..., 0.9983, 0.9983, 0.9983], device='cuda:0',
       requires_grad=True), Likelihood sum=24957.94921875, dataIndex = 192, step = 5
07/29 01:46:31 AM | loss = 4.671505451202393
07/29 01:46:31 AM | loss = 4.671505928039551
07/29 01:46:31 AM | Likelihood = Parameter containing:
tensor([0.9980, 1.0013, 0.9991,  ..., 0.9979, 0.9979, 0.9979], device='cuda:0',
       requires_grad=True), Likelihood sum=24948.19140625, dataIndex = 224, step = 6
07/29 01:46:36 AM | loss = 4.5292158126831055
07/29 01:46:36 AM | loss = 4.529216766357422
07/29 01:46:36 AM | Likelihood = Parameter containing:
tensor([0.9977, 1.0013, 0.9987,  ..., 0.9975, 0.9975, 0.9975], device='cuda:0',
       requires_grad=True), Likelihood sum=24938.083984375, dataIndex = 256, step = 7
07/29 01:46:41 AM | loss = 4.583131790161133
07/29 01:46:41 AM | loss = 4.583131313323975
07/29 01:46:41 AM | Likelihood = Parameter containing:
tensor([0.9973, 1.0012, 0.9982,  ..., 0.9971, 0.9971, 0.9971], device='cuda:0',
       requires_grad=True), Likelihood sum=24927.7109375, dataIndex = 288, step = 8
07/29 01:46:46 AM | loss = 4.483600616455078
07/29 01:46:46 AM | loss = 4.48360013961792
07/29 01:46:46 AM | Likelihood = Parameter containing:
tensor([0.9969, 1.0010, 0.9978,  ..., 0.9967, 0.9967, 0.9967], device='cuda:0',
       requires_grad=True), Likelihood sum=24917.08203125, dataIndex = 320, step = 9
07/29 01:46:51 AM | loss = 4.552898406982422
07/29 01:46:51 AM | loss = 4.55289888381958
07/29 01:46:51 AM | Likelihood = Parameter containing:
tensor([0.9965, 1.0007, 0.9973,  ..., 0.9962, 0.9962, 0.9962], device='cuda:0',
       requires_grad=True), Likelihood sum=24906.26171875, dataIndex = 352, step = 10
07/29 01:46:56 AM | loss = 4.605632781982422
07/29 01:46:56 AM | loss = 4.60563325881958
07/29 01:46:56 AM | Likelihood = Parameter containing:
tensor([0.9961, 1.0003, 0.9968,  ..., 0.9958, 0.9958, 0.9958], device='cuda:0',
       requires_grad=True), Likelihood sum=24895.26953125, dataIndex = 384, step = 11
07/29 01:47:01 AM | loss = 4.720816612243652
07/29 01:47:01 AM | loss = 4.7208170890808105
07/29 01:47:01 AM | Likelihood = Parameter containing:
tensor([0.9957, 0.9999, 0.9964,  ..., 0.9953, 0.9953, 0.9953], device='cuda:0',
       requires_grad=True), Likelihood sum=24884.126953125, dataIndex = 416, step = 12
07/29 01:47:06 AM | loss = 4.541263580322266
07/29 01:47:06 AM | loss = 4.541263580322266
07/29 01:47:06 AM | Likelihood = Parameter containing:
tensor([0.9953, 0.9994, 0.9959,  ..., 0.9949, 0.9949, 0.9949], device='cuda:0',
       requires_grad=True), Likelihood sum=24872.875, dataIndex = 448, step = 13
07/29 01:47:11 AM | loss = 4.68174934387207
07/29 01:47:11 AM | loss = 4.681748867034912
07/29 01:47:11 AM | Likelihood = Parameter containing:
tensor([0.9948, 0.9990, 0.9954,  ..., 0.9944, 0.9944, 0.9944], device='cuda:0',
       requires_grad=True), Likelihood sum=24861.498046875, dataIndex = 480, step = 14
07/29 01:47:16 AM | loss = 4.218100070953369
07/29 01:47:16 AM | loss = 4.218100070953369
07/29 01:47:16 AM | Likelihood = Parameter containing:
tensor([0.9944, 0.9985, 0.9949,  ..., 0.9940, 0.9940, 0.9940], device='cuda:0',
       requires_grad=True), Likelihood sum=24850.0390625, dataIndex = 512, step = 15
07/29 01:47:21 AM | loss = 5.107339859008789
07/29 01:47:21 AM | loss = 5.107340335845947
07/29 01:47:21 AM | Likelihood = Parameter containing:
tensor([0.9940, 0.9979, 0.9944,  ..., 0.9935, 0.9935, 0.9935], device='cuda:0',
       requires_grad=True), Likelihood sum=24838.48828125, dataIndex = 544, step = 16
07/29 01:47:26 AM | loss = 4.46967887878418
07/29 01:47:26 AM | loss = 4.46967887878418
07/29 01:47:26 AM | Likelihood = Parameter containing:
tensor([0.9936, 0.9974, 0.9939,  ..., 0.9930, 0.9930, 0.9930], device='cuda:0',
       requires_grad=True), Likelihood sum=24826.876953125, dataIndex = 576, step = 17
07/29 01:47:31 AM | loss = 4.85128927230835
07/29 01:47:31 AM | loss = 4.85128927230835
07/29 01:47:31 AM | Likelihood = Parameter containing:
tensor([0.9931, 0.9969, 0.9934,  ..., 0.9926, 0.9926, 0.9926], device='cuda:0',
       requires_grad=True), Likelihood sum=24815.203125, dataIndex = 608, step = 18
07/29 01:47:36 AM | loss = 4.60801362991333
07/29 01:47:36 AM | loss = 4.60801362991333
07/29 01:47:36 AM | Likelihood = Parameter containing:
tensor([0.9927, 0.9964, 0.9930,  ..., 0.9921, 0.9921, 0.9921], device='cuda:0',
       requires_grad=True), Likelihood sum=24803.462890625, dataIndex = 640, step = 19
07/29 01:47:41 AM | loss = 4.511218547821045
07/29 01:47:41 AM | loss = 4.511218547821045
07/29 01:47:41 AM | Likelihood = Parameter containing:
tensor([0.9922, 0.9958, 0.9925,  ..., 0.9916, 0.9916, 0.9916], device='cuda:0',
       requires_grad=True), Likelihood sum=24791.673828125, dataIndex = 672, step = 20
07/29 01:47:46 AM | loss = 4.631910800933838
07/29 01:47:46 AM | loss = 4.631911277770996
07/29 01:47:46 AM | Likelihood = Parameter containing:
tensor([0.9918, 0.9953, 0.9920,  ..., 0.9912, 0.9912, 0.9912], device='cuda:0',
       requires_grad=True), Likelihood sum=24779.837890625, dataIndex = 704, step = 21
07/29 01:47:51 AM | loss = 4.6030731201171875
07/29 01:47:51 AM | loss = 4.603073596954346
07/29 01:47:51 AM | Likelihood = Parameter containing:
tensor([0.9913, 0.9948, 0.9915,  ..., 0.9907, 0.9907, 0.9907], device='cuda:0',
       requires_grad=True), Likelihood sum=24767.962890625, dataIndex = 736, step = 22
07/29 01:47:56 AM | loss = 4.698084831237793
07/29 01:47:56 AM | loss = 4.698084354400635
07/29 01:47:56 AM | Likelihood = Parameter containing:
tensor([0.9909, 0.9942, 0.9910,  ..., 0.9902, 0.9902, 0.9902], device='cuda:0',
       requires_grad=True), Likelihood sum=24756.041015625, dataIndex = 768, step = 23
07/29 01:48:01 AM | loss = 4.59483003616333
07/29 01:48:01 AM | loss = 4.594829082489014
07/29 01:48:01 AM | Likelihood = Parameter containing:
tensor([0.9904, 0.9937, 0.9905,  ..., 0.9897, 0.9897, 0.9897], device='cuda:0',
       requires_grad=True), Likelihood sum=24744.0859375, dataIndex = 800, step = 24
07/29 01:48:06 AM | loss = 4.496162414550781
07/29 01:48:06 AM | loss = 4.4961628913879395
07/29 01:48:06 AM | Likelihood = Parameter containing:
tensor([0.9900, 0.9932, 0.9900,  ..., 0.9892, 0.9892, 0.9892], device='cuda:0',
       requires_grad=True), Likelihood sum=24732.099609375, dataIndex = 832, step = 25
07/29 01:48:11 AM | loss = 4.6323018074035645
07/29 01:48:11 AM | loss = 4.6323018074035645
07/29 01:48:11 AM | Likelihood = Parameter containing:
tensor([0.9895, 0.9926, 0.9895,  ..., 0.9887, 0.9887, 0.9887], device='cuda:0',
       requires_grad=True), Likelihood sum=24720.080078125, dataIndex = 864, step = 26
07/29 01:48:15 AM | loss = 4.565403461456299
07/29 01:48:15 AM | loss = 4.565403461456299
07/29 01:48:15 AM | Likelihood = Parameter containing:
tensor([0.9891, 0.9921, 0.9890,  ..., 0.9883, 0.9883, 0.9883], device='cuda:0',
       requires_grad=True), Likelihood sum=24708.03515625, dataIndex = 896, step = 27
07/29 01:48:20 AM | loss = 4.798392295837402
07/29 01:48:20 AM | loss = 4.798391342163086
07/29 01:48:20 AM | Likelihood = Parameter containing:
tensor([0.9886, 0.9916, 0.9885,  ..., 0.9878, 0.9878, 0.9878], device='cuda:0',
       requires_grad=True), Likelihood sum=24695.9609375, dataIndex = 928, step = 28
07/29 01:48:25 AM | loss = 4.582348823547363
07/29 01:48:25 AM | loss = 4.582348346710205
07/29 01:48:25 AM | Likelihood = Parameter containing:
tensor([0.9881, 0.9910, 0.9880,  ..., 0.9873, 0.9873, 0.9873], device='cuda:0',
       requires_grad=True), Likelihood sum=24683.865234375, dataIndex = 960, step = 29
07/29 01:48:30 AM | loss = 4.869866847991943
07/29 01:48:30 AM | loss = 4.869866371154785
07/29 01:48:30 AM | Likelihood = Parameter containing:
tensor([0.9877, 0.9905, 0.9875,  ..., 0.9868, 0.9868, 0.9868], device='cuda:0',
       requires_grad=True), Likelihood sum=24671.75, dataIndex = 992, step = 30
07/29 01:48:35 AM | loss = 4.5584940910339355
07/29 01:48:35 AM | loss = 4.5584940910339355
07/29 01:48:35 AM | Likelihood = Parameter containing:
tensor([0.9872, 0.9900, 0.9870,  ..., 0.9863, 0.9863, 0.9863], device='cuda:0',
       requires_grad=True), Likelihood sum=24659.609375, dataIndex = 1024, step = 31
07/29 01:48:40 AM | loss = 4.420591354370117
07/29 01:48:40 AM | loss = 4.420591354370117
07/29 01:48:40 AM | Likelihood = Parameter containing:
tensor([0.9867, 0.9894, 0.9865,  ..., 0.9858, 0.9858, 0.9858], device='cuda:0',
       requires_grad=True), Likelihood sum=24647.45703125, dataIndex = 1056, step = 32
07/29 01:48:45 AM | loss = 4.571456432342529
07/29 01:48:45 AM | loss = 4.571455955505371
07/29 01:48:45 AM | Likelihood = Parameter containing:
tensor([0.9863, 0.9889, 0.9860,  ..., 0.9853, 0.9853, 0.9853], device='cuda:0',
       requires_grad=True), Likelihood sum=24635.275390625, dataIndex = 1088, step = 33
07/29 01:48:50 AM | loss = 4.315451145172119
07/29 01:48:50 AM | loss = 4.315451622009277
07/29 01:48:50 AM | Likelihood = Parameter containing:
tensor([0.9858, 0.9884, 0.9855,  ..., 0.9848, 0.9848, 0.9848], device='cuda:0',
       requires_grad=True), Likelihood sum=24623.083984375, dataIndex = 1120, step = 34
07/29 01:48:55 AM | loss = 4.739249229431152
07/29 01:48:55 AM | loss = 4.739249229431152
07/29 01:48:55 AM | Likelihood = Parameter containing:
tensor([0.9853, 0.9878, 0.9850,  ..., 0.9844, 0.9844, 0.9844], device='cuda:0',
       requires_grad=True), Likelihood sum=24610.87890625, dataIndex = 1152, step = 35
07/29 01:49:00 AM | loss = 4.535521984100342
07/29 01:49:00 AM | loss = 4.535521984100342
07/29 01:49:00 AM | Likelihood = Parameter containing:
tensor([0.9848, 0.9873, 0.9845,  ..., 0.9839, 0.9839, 0.9839], device='cuda:0',
       requires_grad=True), Likelihood sum=24598.65234375, dataIndex = 1184, step = 36
07/29 01:49:05 AM | loss = 4.508396625518799
07/29 01:49:05 AM | loss = 4.508396625518799
07/29 01:49:05 AM | Likelihood = Parameter containing:
tensor([0.9844, 0.9868, 0.9840,  ..., 0.9834, 0.9834, 0.9834], device='cuda:0',
       requires_grad=True), Likelihood sum=24586.4140625, dataIndex = 1216, step = 37
07/29 01:49:10 AM | loss = 4.628266334533691
07/29 01:49:10 AM | loss = 4.628266334533691
07/29 01:49:10 AM | Likelihood = Parameter containing:
tensor([0.9839, 0.9862, 0.9834,  ..., 0.9829, 0.9829, 0.9829], device='cuda:0',
       requires_grad=True), Likelihood sum=24574.16015625, dataIndex = 1248, step = 38
07/29 01:49:14 AM | loss = 4.4219889640808105
07/29 01:49:14 AM | loss = 4.421989917755127
07/29 01:49:14 AM | Likelihood = Parameter containing:
tensor([0.9834, 0.9857, 0.9829,  ..., 0.9824, 0.9824, 0.9824], device='cuda:0',
       requires_grad=True), Likelihood sum=24561.896484375, dataIndex = 1280, step = 39
07/29 01:49:19 AM | loss = 4.464897632598877
07/29 01:49:19 AM | loss = 4.464897632598877
07/29 01:49:19 AM | Likelihood = Parameter containing:
tensor([0.9830, 0.9852, 0.9824,  ..., 0.9819, 0.9819, 0.9819], device='cuda:0',
       requires_grad=True), Likelihood sum=24549.6171875, dataIndex = 1312, step = 40
07/29 01:49:24 AM | loss = 4.312629699707031
07/29 01:49:24 AM | loss = 4.312629222869873
07/29 01:49:24 AM | Likelihood = Parameter containing:
tensor([0.9825, 0.9846, 0.9819,  ..., 0.9814, 0.9814, 0.9814], device='cuda:0',
       requires_grad=True), Likelihood sum=24537.33203125, dataIndex = 1344, step = 41
07/29 01:49:29 AM | loss = 4.54291296005249
07/29 01:49:29 AM | loss = 4.542912006378174
07/29 01:49:29 AM | Likelihood = Parameter containing:
tensor([0.9820, 0.9841, 0.9814,  ..., 0.9809, 0.9809, 0.9809], device='cuda:0',
       requires_grad=True), Likelihood sum=24525.037109375, dataIndex = 1376, step = 42
07/29 01:49:34 AM | loss = 4.853958606719971
07/29 01:49:34 AM | loss = 4.853958606719971
07/29 01:49:34 AM | Likelihood = Parameter containing:
tensor([0.9815, 0.9836, 0.9809,  ..., 0.9804, 0.9804, 0.9804], device='cuda:0',
       requires_grad=True), Likelihood sum=24512.7265625, dataIndex = 1408, step = 43
07/29 01:49:39 AM | loss = 4.429619789123535
07/29 01:49:39 AM | loss = 4.429619312286377
07/29 01:49:39 AM | Likelihood = Parameter containing:
tensor([0.9810, 0.9831, 0.9804,  ..., 0.9799, 0.9799, 0.9799], device='cuda:0',
       requires_grad=True), Likelihood sum=24500.4140625, dataIndex = 1440, step = 44
07/29 01:49:44 AM | loss = 4.4794440269470215
07/29 01:49:44 AM | loss = 4.47944450378418
07/29 01:49:44 AM | Likelihood = Parameter containing:
tensor([0.9806, 0.9825, 0.9799,  ..., 0.9794, 0.9794, 0.9794], device='cuda:0',
       requires_grad=True), Likelihood sum=24488.08984375, dataIndex = 1472, step = 45
07/29 01:49:49 AM | loss = 4.1964263916015625
07/29 01:49:49 AM | loss = 4.196426868438721
07/29 01:49:49 AM | Likelihood = Parameter containing:
tensor([0.9801, 0.9820, 0.9794,  ..., 0.9789, 0.9789, 0.9789], device='cuda:0',
       requires_grad=True), Likelihood sum=24475.75, dataIndex = 1504, step = 46
07/29 01:49:54 AM | loss = 4.554599285125732
07/29 01:49:54 AM | loss = 4.554599285125732
07/29 01:49:54 AM | Likelihood = Parameter containing:
tensor([0.9796, 0.9815, 0.9789,  ..., 0.9784, 0.9784, 0.9784], device='cuda:0',
       requires_grad=True), Likelihood sum=24463.412109375, dataIndex = 1536, step = 47
07/29 01:49:59 AM | loss = 4.185050010681152
07/29 01:49:59 AM | loss = 4.185049533843994
07/29 01:49:59 AM | Likelihood = Parameter containing:
tensor([0.9791, 0.9809, 0.9784,  ..., 0.9779, 0.9779, 0.9779], device='cuda:0',
       requires_grad=True), Likelihood sum=24451.060546875, dataIndex = 1568, step = 48
07/29 01:50:04 AM | loss = 4.476311683654785
07/29 01:50:04 AM | loss = 4.476311683654785
07/29 01:50:04 AM | Likelihood = Parameter containing:
tensor([0.9786, 0.9804, 0.9779,  ..., 0.9774, 0.9774, 0.9774], device='cuda:0',
       requires_grad=True), Likelihood sum=24438.703125, dataIndex = 1600, step = 49
07/29 01:50:09 AM | loss = 4.60679292678833
07/29 01:50:09 AM | loss = 4.60679292678833
07/29 01:50:09 AM | Likelihood = Parameter containing:
tensor([0.9782, 0.9799, 0.9774,  ..., 0.9769, 0.9769, 0.9769], device='cuda:0',
       requires_grad=True), Likelihood sum=24426.33203125, dataIndex = 1632, step = 50
07/29 01:50:10 AM | Train: [ 1/50] Step 050/781 Loss 4.578 Prec@(1,5) (3.3%, 12.4%)
07/29 01:50:14 AM | loss = 4.598150730133057
07/29 01:50:14 AM | loss = 4.598151206970215
07/29 01:50:14 AM | Likelihood = Parameter containing:
tensor([0.9777, 0.9794, 0.9769,  ..., 0.9764, 0.9764, 0.9764], device='cuda:0',
       requires_grad=True), Likelihood sum=24413.9609375, dataIndex = 1664, step = 51
07/29 01:50:19 AM | loss = 4.646825313568115
07/29 01:50:19 AM | loss = 4.646826267242432
07/29 01:50:19 AM | Likelihood = Parameter containing:
tensor([0.9772, 0.9788, 0.9764,  ..., 0.9759, 0.9759, 0.9759], device='cuda:0',
       requires_grad=True), Likelihood sum=24401.580078125, dataIndex = 1696, step = 52
07/29 01:50:24 AM | loss = 4.676219463348389
07/29 01:50:24 AM | loss = 4.676219463348389
07/29 01:50:24 AM | Likelihood = Parameter containing:
tensor([0.9767, 0.9783, 0.9759,  ..., 0.9754, 0.9754, 0.9754], device='cuda:0',
       requires_grad=True), Likelihood sum=24389.1953125, dataIndex = 1728, step = 53
07/29 01:50:29 AM | loss = 4.47804069519043
07/29 01:50:29 AM | loss = 4.47804069519043
07/29 01:50:29 AM | Likelihood = Parameter containing:
tensor([0.9762, 0.9778, 0.9754,  ..., 0.9749, 0.9749, 0.9749], device='cuda:0',
       requires_grad=True), Likelihood sum=24376.80078125, dataIndex = 1760, step = 54
07/29 01:50:34 AM | loss = 4.442516803741455
07/29 01:50:34 AM | loss = 4.442516803741455
07/29 01:50:34 AM | Likelihood = Parameter containing:
tensor([0.9757, 0.9773, 0.9749,  ..., 0.9744, 0.9744, 0.9744], device='cuda:0',
       requires_grad=True), Likelihood sum=24364.3984375, dataIndex = 1792, step = 55
07/29 01:50:39 AM | loss = 4.220759868621826
07/29 01:50:39 AM | loss = 4.220759391784668
07/29 01:50:39 AM | Likelihood = Parameter containing:
tensor([0.9753, 0.9767, 0.9743,  ..., 0.9739, 0.9739, 0.9739], device='cuda:0',
       requires_grad=True), Likelihood sum=24352.0, dataIndex = 1824, step = 56
07/29 01:50:44 AM | loss = 4.25173807144165
07/29 01:50:44 AM | loss = 4.251739025115967
07/29 01:50:44 AM | Likelihood = Parameter containing:
tensor([0.9748, 0.9762, 0.9738,  ..., 0.9734, 0.9734, 0.9734], device='cuda:0',
       requires_grad=True), Likelihood sum=24339.58984375, dataIndex = 1856, step = 57
07/29 01:50:49 AM | loss = 4.305534839630127
07/29 01:50:49 AM | loss = 4.305534839630127
07/29 01:50:49 AM | Likelihood = Parameter containing:
tensor([0.9743, 0.9757, 0.9733,  ..., 0.9729, 0.9729, 0.9729], device='cuda:0',
       requires_grad=True), Likelihood sum=24327.171875, dataIndex = 1888, step = 58
07/29 01:50:54 AM | loss = 4.443601608276367
07/29 01:50:54 AM | loss = 4.443601608276367
07/29 01:50:54 AM | Likelihood = Parameter containing:
tensor([0.9738, 0.9752, 0.9728,  ..., 0.9724, 0.9724, 0.9724], device='cuda:0',
       requires_grad=True), Likelihood sum=24314.75390625, dataIndex = 1920, step = 59
07/29 01:51:00 AM | loss = 4.480190277099609
07/29 01:51:00 AM | loss = 4.480189800262451
07/29 01:51:00 AM | Likelihood = Parameter containing:
tensor([0.9733, 0.9746, 0.9723,  ..., 0.9719, 0.9719, 0.9719], device='cuda:0',
       requires_grad=True), Likelihood sum=24302.328125, dataIndex = 1952, step = 60
07/29 01:51:05 AM | loss = 4.677202224731445
07/29 01:51:05 AM | loss = 4.677202224731445
07/29 01:51:05 AM | Likelihood = Parameter containing:
tensor([0.9728, 0.9741, 0.9718,  ..., 0.9714, 0.9714, 0.9714], device='cuda:0',
       requires_grad=True), Likelihood sum=24289.904296875, dataIndex = 1984, step = 61
07/29 01:51:10 AM | loss = 4.5372538566589355
07/29 01:51:10 AM | loss = 4.537254333496094
07/29 01:51:10 AM | Likelihood = Parameter containing:
tensor([0.9723, 0.9736, 0.9713,  ..., 0.9709, 0.9709, 0.9709], device='cuda:0',
       requires_grad=True), Likelihood sum=24277.470703125, dataIndex = 2016, step = 62
07/29 01:51:15 AM | loss = 4.195268154144287
07/29 01:51:15 AM | loss = 4.195267677307129
07/29 01:51:15 AM | Likelihood = Parameter containing:
tensor([0.9718, 0.9731, 0.9708,  ..., 0.9704, 0.9704, 0.9704], device='cuda:0',
       requires_grad=True), Likelihood sum=24265.03125, dataIndex = 2048, step = 63
07/29 01:51:20 AM | loss = 4.139466285705566
07/29 01:51:20 AM | loss = 4.139466762542725
07/29 01:51:20 AM | Likelihood = Parameter containing:
tensor([0.9714, 0.9725, 0.9703,  ..., 0.9699, 0.9699, 0.9699], device='cuda:0',
       requires_grad=True), Likelihood sum=24252.59375, dataIndex = 2080, step = 64
07/29 01:51:25 AM | loss = 4.589001655578613
07/29 01:51:25 AM | loss = 4.589001178741455
07/29 01:51:25 AM | Likelihood = Parameter containing:
tensor([0.9709, 0.9720, 0.9698,  ..., 0.9694, 0.9694, 0.9694], device='cuda:0',
       requires_grad=True), Likelihood sum=24240.1484375, dataIndex = 2112, step = 65
07/29 01:51:30 AM | loss = 4.24416446685791
07/29 01:51:30 AM | loss = 4.24416446685791
07/29 01:51:30 AM | Likelihood = Parameter containing:
tensor([0.9704, 0.9715, 0.9693,  ..., 0.9689, 0.9689, 0.9689], device='cuda:0',
       requires_grad=True), Likelihood sum=24227.69921875, dataIndex = 2144, step = 66
07/29 01:51:35 AM | loss = 4.252354621887207
07/29 01:51:35 AM | loss = 4.252355098724365
07/29 01:51:35 AM | Likelihood = Parameter containing:
tensor([0.9699, 0.9710, 0.9688,  ..., 0.9684, 0.9684, 0.9684], device='cuda:0',
       requires_grad=True), Likelihood sum=24215.25, dataIndex = 2176, step = 67
07/29 01:51:40 AM | loss = 4.1849470138549805
07/29 01:51:40 AM | loss = 4.184946537017822
07/29 01:51:40 AM | Likelihood = Parameter containing:
tensor([0.9694, 0.9704, 0.9683,  ..., 0.9679, 0.9679, 0.9679], device='cuda:0',
       requires_grad=True), Likelihood sum=24202.79296875, dataIndex = 2208, step = 68
07/29 01:51:45 AM | loss = 4.234949588775635
07/29 01:51:45 AM | loss = 4.234949588775635
07/29 01:51:45 AM | Likelihood = Parameter containing:
tensor([0.9689, 0.9699, 0.9678,  ..., 0.9674, 0.9674, 0.9674], device='cuda:0',
       requires_grad=True), Likelihood sum=24190.337890625, dataIndex = 2240, step = 69
07/29 01:51:50 AM | loss = 4.698971748352051
07/29 01:51:50 AM | loss = 4.698971271514893
07/29 01:51:50 AM | Likelihood = Parameter containing:
tensor([0.9684, 0.9694, 0.9673,  ..., 0.9669, 0.9669, 0.9669], device='cuda:0',
       requires_grad=True), Likelihood sum=24177.875, dataIndex = 2272, step = 70
07/29 02:01:36 AM | 
07/29 02:01:36 AM | Parameters:
07/29 02:01:36 AM | ALPHA_LR=0.0003
07/29 02:01:36 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 02:01:36 AM | BATCH_SIZE=32
07/29 02:01:36 AM | DATA_PATH=./data/
07/29 02:01:36 AM | DATASET=cifar100
07/29 02:01:36 AM | EPOCHS=50
07/29 02:01:36 AM | GPUS=[0]
07/29 02:01:36 AM | INIT_CHANNELS=16
07/29 02:01:36 AM | LAYERS=8
07/29 02:01:36 AM | NAME=cifar100-ignore-shuffle
07/29 02:01:36 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 02:01:36 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 02:01:36 AM | PRINT_FREQ=50
07/29 02:01:36 AM | SEED=2
07/29 02:01:36 AM | W_GRAD_CLIP=5.0
07/29 02:01:36 AM | W_LR=0.025
07/29 02:01:36 AM | W_LR_MIN=0.001
07/29 02:01:36 AM | W_MOMENTUM=0.9
07/29 02:01:36 AM | W_WEIGHT_DECAY=0.0003
07/29 02:01:36 AM | WORKERS=4
07/29 02:01:36 AM | 
07/29 02:01:36 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 02:01:51 AM | standard loss = 4.765181064605713
07/29 02:01:51 AM | weighted loss = 4.765181064605713
07/29 02:01:51 AM | Likelihood = Parameter containing:
tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0', requires_grad=True), Likelihood sum=25000.0, dataIndex = 32, step = 0
07/29 02:01:52 AM | Train: [ 1/50] Step 000/781 Loss 4.765 Prec@(1,5) (0.0%, 3.1%)
07/29 02:01:56 AM | standard loss = 4.639214992523193
07/29 02:01:56 AM | weighted loss = 4.639215469360352
07/29 02:01:56 AM | Likelihood = Parameter containing:
tensor([0.9997, 1.0003, 0.9997,  ..., 0.9997, 0.9997, 0.9997], device='cuda:0',
       requires_grad=True), Likelihood sum=24992.51171875, dataIndex = 64, step = 1
07/29 02:02:01 AM | standard loss = 4.606244087219238
07/29 02:02:01 AM | weighted loss = 4.606244087219238
07/29 02:02:01 AM | Likelihood = Parameter containing:
tensor([0.9994, 1.0003, 0.9994,  ..., 0.9994, 0.9994, 0.9994], device='cuda:0',
       requires_grad=True), Likelihood sum=24984.61328125, dataIndex = 96, step = 2
07/29 02:02:06 AM | standard loss = 4.806174278259277
07/29 02:02:06 AM | weighted loss = 4.806173801422119
07/29 02:02:06 AM | Likelihood = Parameter containing:
tensor([0.9991, 1.0000, 0.9990,  ..., 0.9990, 0.9990, 0.9990], device='cuda:0',
       requires_grad=True), Likelihood sum=24976.1953125, dataIndex = 128, step = 3
07/29 02:02:11 AM | standard loss = 4.658764362335205
07/29 02:02:11 AM | weighted loss = 4.658763885498047
07/29 02:02:11 AM | Likelihood = Parameter containing:
tensor([0.9987, 0.9997, 0.9987,  ..., 0.9987, 0.9987, 0.9987], device='cuda:0',
       requires_grad=True), Likelihood sum=24967.263671875, dataIndex = 160, step = 4
07/29 02:02:51 AM | 
07/29 02:02:51 AM | Parameters:
07/29 02:02:51 AM | ALPHA_LR=0.0003
07/29 02:02:51 AM | ALPHA_WEIGHT_DECAY=0.001
07/29 02:02:51 AM | BATCH_SIZE=32
07/29 02:02:51 AM | DATA_PATH=./data/
07/29 02:02:51 AM | DATASET=cifar100
07/29 02:02:51 AM | EPOCHS=50
07/29 02:02:51 AM | GPUS=[0]
07/29 02:02:51 AM | INIT_CHANNELS=16
07/29 02:02:51 AM | LAYERS=8
07/29 02:02:51 AM | NAME=cifar100-ignore-shuffle
07/29 02:02:51 AM | PATH=searchs/cifar100-ignore-shuffle
07/29 02:02:51 AM | PLOT_PATH=searchs/cifar100-ignore-shuffle/plots
07/29 02:02:51 AM | PRINT_FREQ=50
07/29 02:02:51 AM | SEED=2
07/29 02:02:51 AM | W_GRAD_CLIP=5.0
07/29 02:02:51 AM | W_LR=0.025
07/29 02:02:51 AM | W_LR_MIN=0.001
07/29 02:02:51 AM | W_MOMENTUM=0.9
07/29 02:02:51 AM | W_WEIGHT_DECAY=0.0003
07/29 02:02:51 AM | WORKERS=4
07/29 02:02:51 AM | 
07/29 02:02:51 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/29 02:03:07 AM | standard loss = 4.765181541442871
07/29 02:03:07 AM | weighted loss = 4.765181064605713
07/29 02:03:07 AM | Likelihood = tensor([0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18276.46484375, dataIndex = 32, step = 0
07/29 02:03:07 AM | Train: [ 1/50] Step 000/781 Loss 4.765 Prec@(1,5) (0.0%, 3.1%)
07/29 02:03:12 AM | standard loss = 4.639200210571289
07/29 02:03:12 AM | weighted loss = 4.639200687408447
07/29 02:03:12 AM | Likelihood = tensor([0.7310, 0.7311, 0.7310,  ..., 0.7310, 0.7310, 0.7310], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18274.9921875, dataIndex = 64, step = 1
07/29 02:03:17 AM | standard loss = 4.606217384338379
07/29 02:03:17 AM | weighted loss = 4.606217384338379
07/29 02:03:17 AM | Likelihood = tensor([0.7309, 0.7311, 0.7309,  ..., 0.7309, 0.7309, 0.7309], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18273.4375, dataIndex = 96, step = 2
07/29 02:03:22 AM | standard loss = 4.798958778381348
07/29 02:03:22 AM | weighted loss = 4.798959255218506
07/29 02:03:22 AM | Likelihood = tensor([0.7309, 0.7311, 0.7309,  ..., 0.7309, 0.7309, 0.7309], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18271.78515625, dataIndex = 128, step = 3
07/29 02:03:27 AM | standard loss = 4.667043209075928
07/29 02:03:27 AM | weighted loss = 4.667043209075928
07/29 02:03:27 AM | Likelihood = tensor([0.7308, 0.7310, 0.7308,  ..., 0.7308, 0.7308, 0.7308], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18270.025390625, dataIndex = 160, step = 4
07/29 02:03:31 AM | standard loss = 4.5853424072265625
07/29 02:03:32 AM | weighted loss = 4.585343360900879
07/29 02:03:32 AM | Likelihood = tensor([0.7307, 0.7309, 0.7307,  ..., 0.7307, 0.7307, 0.7307], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18268.1796875, dataIndex = 192, step = 5
07/29 02:03:37 AM | standard loss = 4.6808624267578125
07/29 02:03:37 AM | weighted loss = 4.680861949920654
07/29 02:03:37 AM | Likelihood = tensor([0.7307, 0.7308, 0.7306,  ..., 0.7306, 0.7306, 0.7306], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18266.25, dataIndex = 224, step = 6
07/29 02:03:41 AM | standard loss = 4.529829978942871
07/29 02:03:41 AM | weighted loss = 4.529829025268555
07/29 02:03:41 AM | Likelihood = tensor([0.7306, 0.7308, 0.7306,  ..., 0.7306, 0.7306, 0.7306], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18264.2578125, dataIndex = 256, step = 7
07/29 02:03:46 AM | standard loss = 4.587820053100586
07/29 02:03:46 AM | weighted loss = 4.587819576263428
07/29 02:03:46 AM | Likelihood = tensor([0.7305, 0.7307, 0.7305,  ..., 0.7305, 0.7305, 0.7305], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18262.20703125, dataIndex = 288, step = 8
07/29 02:03:51 AM | standard loss = 4.560356140136719
07/29 02:03:51 AM | weighted loss = 4.560356140136719
07/29 02:03:51 AM | Likelihood = tensor([0.7304, 0.7306, 0.7304,  ..., 0.7304, 0.7304, 0.7304], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18260.103515625, dataIndex = 320, step = 9
07/29 02:03:56 AM | standard loss = 4.592841148376465
07/29 02:03:56 AM | weighted loss = 4.592841148376465
07/29 02:03:56 AM | Likelihood = tensor([0.7303, 0.7305, 0.7303,  ..., 0.7303, 0.7303, 0.7303], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18257.966796875, dataIndex = 352, step = 10
07/29 02:04:01 AM | standard loss = 4.586538791656494
07/29 02:04:01 AM | weighted loss = 4.586538791656494
07/29 02:04:01 AM | Likelihood = tensor([0.7303, 0.7304, 0.7302,  ..., 0.7302, 0.7302, 0.7302], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18255.79296875, dataIndex = 384, step = 11
07/29 02:04:06 AM | standard loss = 4.742664813995361
07/29 02:04:06 AM | weighted loss = 4.742665767669678
07/29 02:04:06 AM | Likelihood = tensor([0.7302, 0.7303, 0.7301,  ..., 0.7301, 0.7301, 0.7301], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18253.5859375, dataIndex = 416, step = 12
07/29 02:04:11 AM | standard loss = 4.497931480407715
07/29 02:04:11 AM | weighted loss = 4.497931957244873
07/29 02:04:11 AM | Likelihood = tensor([0.7301, 0.7302, 0.7300,  ..., 0.7301, 0.7301, 0.7301], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18251.35546875, dataIndex = 448, step = 13
07/29 02:04:16 AM | standard loss = 4.708481788635254
07/29 02:04:16 AM | weighted loss = 4.708481788635254
07/29 02:04:16 AM | Likelihood = tensor([0.7300, 0.7301, 0.7299,  ..., 0.7300, 0.7300, 0.7300], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18249.10546875, dataIndex = 480, step = 14
07/29 02:04:21 AM | standard loss = 4.327406883239746
07/29 02:04:21 AM | weighted loss = 4.327407360076904
07/29 02:04:21 AM | Likelihood = tensor([0.7299, 0.7300, 0.7299,  ..., 0.7299, 0.7299, 0.7299], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18246.8359375, dataIndex = 512, step = 15
07/29 02:04:26 AM | standard loss = 4.9483771324157715
07/29 02:04:26 AM | weighted loss = 4.9483771324157715
07/29 02:04:26 AM | Likelihood = tensor([0.7298, 0.7299, 0.7298,  ..., 0.7298, 0.7298, 0.7298], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18244.55078125, dataIndex = 544, step = 16
07/29 02:04:31 AM | standard loss = 4.3480963706970215
07/29 02:04:31 AM | weighted loss = 4.3480963706970215
07/29 02:04:31 AM | Likelihood = tensor([0.7297, 0.7298, 0.7297,  ..., 0.7297, 0.7297, 0.7297], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18242.2421875, dataIndex = 576, step = 17
07/29 02:04:36 AM | standard loss = 4.839781761169434
07/29 02:04:36 AM | weighted loss = 4.839781761169434
07/29 02:04:36 AM | Likelihood = tensor([0.7296, 0.7297, 0.7296,  ..., 0.7296, 0.7296, 0.7296], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18239.9296875, dataIndex = 608, step = 18
07/29 02:04:41 AM | standard loss = 4.565685749053955
07/29 02:04:41 AM | weighted loss = 4.565686225891113
07/29 02:04:41 AM | Likelihood = tensor([0.7295, 0.7296, 0.7295,  ..., 0.7295, 0.7295, 0.7295], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18237.6015625, dataIndex = 640, step = 19
07/29 02:04:46 AM | standard loss = 4.641505718231201
07/29 02:04:46 AM | weighted loss = 4.641505241394043
07/29 02:04:46 AM | Likelihood = tensor([0.7294, 0.7295, 0.7294,  ..., 0.7294, 0.7294, 0.7294], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18235.2578125, dataIndex = 672, step = 20
07/29 02:04:51 AM | standard loss = 4.6530985832214355
07/29 02:04:51 AM | weighted loss = 4.6530985832214355
07/29 02:04:51 AM | Likelihood = tensor([0.7294, 0.7294, 0.7293,  ..., 0.7293, 0.7293, 0.7293], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18232.9140625, dataIndex = 704, step = 21
07/29 02:04:56 AM | standard loss = 4.394197940826416
07/29 02:04:56 AM | weighted loss = 4.394197463989258
07/29 02:04:56 AM | Likelihood = tensor([0.7293, 0.7293, 0.7292,  ..., 0.7292, 0.7292, 0.7292], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18230.5546875, dataIndex = 736, step = 22
07/29 02:05:01 AM | standard loss = 4.804932117462158
07/29 02:05:01 AM | weighted loss = 4.804932594299316
07/29 02:05:01 AM | Likelihood = tensor([0.7292, 0.7292, 0.7291,  ..., 0.7291, 0.7291, 0.7291], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18228.1875, dataIndex = 768, step = 23
07/29 02:05:06 AM | standard loss = 4.4492011070251465
07/29 02:05:06 AM | weighted loss = 4.449200630187988
07/29 02:05:06 AM | Likelihood = tensor([0.7291, 0.7291, 0.7290,  ..., 0.7290, 0.7290, 0.7290], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18225.8125, dataIndex = 800, step = 24
07/29 02:05:10 AM | standard loss = 4.481184005737305
07/29 02:05:10 AM | weighted loss = 4.481184482574463
07/29 02:05:10 AM | Likelihood = tensor([0.7290, 0.7291, 0.7289,  ..., 0.7289, 0.7289, 0.7289], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18223.435546875, dataIndex = 832, step = 25
07/29 02:05:15 AM | standard loss = 4.540788173675537
07/29 02:05:15 AM | weighted loss = 4.540787696838379
07/29 02:05:15 AM | Likelihood = tensor([0.7289, 0.7290, 0.7288,  ..., 0.7288, 0.7288, 0.7288], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18221.046875, dataIndex = 864, step = 26
07/29 02:05:20 AM | standard loss = 4.424163341522217
07/29 02:05:20 AM | weighted loss = 4.424163341522217
07/29 02:05:20 AM | Likelihood = tensor([0.7288, 0.7289, 0.7287,  ..., 0.7287, 0.7287, 0.7287], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18218.6484375, dataIndex = 896, step = 27
07/29 02:05:25 AM | standard loss = 4.697443008422852
07/29 02:05:25 AM | weighted loss = 4.69744348526001
07/29 02:05:25 AM | Likelihood = tensor([0.7287, 0.7288, 0.7286,  ..., 0.7286, 0.7286, 0.7286], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18216.25, dataIndex = 928, step = 28
07/29 02:05:30 AM | standard loss = 4.585752964019775
07/29 02:05:30 AM | weighted loss = 4.585752487182617
07/29 02:05:30 AM | Likelihood = tensor([0.7286, 0.7287, 0.7285,  ..., 0.7286, 0.7286, 0.7286], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18213.84765625, dataIndex = 960, step = 29
07/29 02:05:35 AM | standard loss = 4.849341869354248
07/29 02:05:35 AM | weighted loss = 4.849341869354248
07/29 02:05:35 AM | Likelihood = tensor([0.7285, 0.7286, 0.7284,  ..., 0.7285, 0.7285, 0.7285], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18211.43359375, dataIndex = 992, step = 30
07/29 02:05:41 AM | standard loss = 4.620637893676758
07/29 02:05:41 AM | weighted loss = 4.620638370513916
07/29 02:05:41 AM | Likelihood = tensor([0.7284, 0.7285, 0.7283,  ..., 0.7284, 0.7284, 0.7284], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18209.01953125, dataIndex = 1024, step = 31
07/29 02:05:46 AM | standard loss = 4.560348033905029
07/29 02:05:46 AM | weighted loss = 4.560348033905029
07/29 02:05:46 AM | Likelihood = tensor([0.7283, 0.7284, 0.7282,  ..., 0.7283, 0.7283, 0.7283], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18206.6015625, dataIndex = 1056, step = 32
07/29 02:05:51 AM | standard loss = 4.724398612976074
07/29 02:05:51 AM | weighted loss = 4.724398612976074
07/29 02:05:51 AM | Likelihood = tensor([0.7282, 0.7283, 0.7281,  ..., 0.7282, 0.7282, 0.7282], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18204.177734375, dataIndex = 1088, step = 33
07/29 02:05:56 AM | standard loss = 4.440653324127197
07/29 02:05:56 AM | weighted loss = 4.440652847290039
07/29 02:05:56 AM | Likelihood = tensor([0.7281, 0.7282, 0.7280,  ..., 0.7281, 0.7281, 0.7281], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18201.748046875, dataIndex = 1120, step = 34
07/29 02:06:00 AM | standard loss = 4.643097877502441
07/29 02:06:00 AM | weighted loss = 4.6430983543396
07/29 02:06:00 AM | Likelihood = tensor([0.7280, 0.7281, 0.7279,  ..., 0.7280, 0.7280, 0.7280], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18199.318359375, dataIndex = 1152, step = 35
07/29 02:06:06 AM | standard loss = 4.590634822845459
07/29 02:06:06 AM | weighted loss = 4.590634346008301
07/29 02:06:06 AM | Likelihood = tensor([0.7279, 0.7280, 0.7278,  ..., 0.7279, 0.7279, 0.7279], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18196.884765625, dataIndex = 1184, step = 36
07/29 02:06:11 AM | standard loss = 4.355470180511475
07/29 02:06:11 AM | weighted loss = 4.355469703674316
07/29 02:06:11 AM | Likelihood = tensor([0.7278, 0.7279, 0.7277,  ..., 0.7278, 0.7278, 0.7278], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18194.4453125, dataIndex = 1216, step = 37
07/29 02:06:16 AM | standard loss = 4.599956512451172
07/29 02:06:16 AM | weighted loss = 4.599956512451172
07/29 02:06:16 AM | Likelihood = tensor([0.7277, 0.7278, 0.7276,  ..., 0.7277, 0.7277, 0.7277], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18192.0078125, dataIndex = 1248, step = 38
07/29 02:06:20 AM | standard loss = 4.3998870849609375
07/29 02:06:20 AM | weighted loss = 4.399886608123779
07/29 02:06:20 AM | Likelihood = tensor([0.7276, 0.7277, 0.7275,  ..., 0.7276, 0.7276, 0.7276], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18189.564453125, dataIndex = 1280, step = 39
07/29 02:06:25 AM | standard loss = 4.192822456359863
07/29 02:06:25 AM | weighted loss = 4.192821979522705
07/29 02:06:25 AM | Likelihood = tensor([0.7275, 0.7276, 0.7274,  ..., 0.7275, 0.7275, 0.7275], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18187.11328125, dataIndex = 1312, step = 40
07/29 02:06:31 AM | standard loss = 4.381722927093506
07/29 02:06:31 AM | weighted loss = 4.381722450256348
07/29 02:06:31 AM | Likelihood = tensor([0.7275, 0.7275, 0.7273,  ..., 0.7274, 0.7274, 0.7274], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18184.66796875, dataIndex = 1344, step = 41
07/29 02:06:35 AM | standard loss = 4.3571295738220215
07/29 02:06:35 AM | weighted loss = 4.3571295738220215
07/29 02:06:35 AM | Likelihood = tensor([0.7274, 0.7274, 0.7273,  ..., 0.7273, 0.7273, 0.7273], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18182.21484375, dataIndex = 1376, step = 42
07/29 02:06:40 AM | standard loss = 4.678647994995117
07/29 02:06:40 AM | weighted loss = 4.678647994995117
07/29 02:06:40 AM | Likelihood = tensor([0.7273, 0.7273, 0.7272,  ..., 0.7272, 0.7272, 0.7272], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18179.7578125, dataIndex = 1408, step = 43
07/29 02:06:45 AM | standard loss = 4.461726665496826
07/29 02:06:45 AM | weighted loss = 4.461726665496826
07/29 02:06:45 AM | Likelihood = tensor([0.7272, 0.7272, 0.7271,  ..., 0.7271, 0.7271, 0.7271], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18177.30078125, dataIndex = 1440, step = 44
07/29 02:06:51 AM | standard loss = 4.579215049743652
07/29 02:06:51 AM | weighted loss = 4.579214572906494
07/29 02:06:51 AM | Likelihood = tensor([0.7271, 0.7271, 0.7270,  ..., 0.7270, 0.7270, 0.7270], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18174.83984375, dataIndex = 1472, step = 45
07/29 02:06:55 AM | standard loss = 4.449709415435791
07/29 02:06:55 AM | weighted loss = 4.449709415435791
07/29 02:06:55 AM | Likelihood = tensor([0.7270, 0.7270, 0.7269,  ..., 0.7269, 0.7269, 0.7269], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18172.380859375, dataIndex = 1504, step = 46
07/29 02:07:00 AM | standard loss = 4.6842546463012695
07/29 02:07:00 AM | weighted loss = 4.6842546463012695
07/29 02:07:00 AM | Likelihood = tensor([0.7269, 0.7269, 0.7268,  ..., 0.7268, 0.7268, 0.7268], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18169.916015625, dataIndex = 1536, step = 47
07/29 02:07:05 AM | standard loss = 4.201228618621826
07/29 02:07:05 AM | weighted loss = 4.201228141784668
07/29 02:07:05 AM | Likelihood = tensor([0.7268, 0.7268, 0.7267,  ..., 0.7267, 0.7267, 0.7267], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18167.44921875, dataIndex = 1568, step = 48
07/29 02:07:10 AM | standard loss = 4.457237243652344
07/29 02:07:10 AM | weighted loss = 4.457237720489502
07/29 02:07:10 AM | Likelihood = tensor([0.7267, 0.7267, 0.7266,  ..., 0.7266, 0.7266, 0.7266], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18164.98046875, dataIndex = 1600, step = 49
07/29 02:07:15 AM | standard loss = 4.730497360229492
07/29 02:07:15 AM | weighted loss = 4.730497360229492
07/29 02:07:15 AM | Likelihood = tensor([0.7266, 0.7266, 0.7265,  ..., 0.7265, 0.7265, 0.7265], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18162.51171875, dataIndex = 1632, step = 50
07/29 02:07:16 AM | Train: [ 1/50] Step 050/781 Loss 4.573 Prec@(1,5) (3.1%, 10.6%)
07/29 02:07:20 AM | standard loss = 4.640944957733154
07/29 02:07:20 AM | weighted loss = 4.640944957733154
07/29 02:07:20 AM | Likelihood = tensor([0.7265, 0.7265, 0.7264,  ..., 0.7264, 0.7264, 0.7264], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18160.041015625, dataIndex = 1664, step = 51
07/29 02:07:25 AM | standard loss = 4.614774703979492
07/29 02:07:25 AM | weighted loss = 4.614773750305176
07/29 02:07:25 AM | Likelihood = tensor([0.7264, 0.7264, 0.7263,  ..., 0.7263, 0.7263, 0.7263], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18157.56640625, dataIndex = 1696, step = 52
07/29 02:07:30 AM | standard loss = 4.571804046630859
07/29 02:07:30 AM | weighted loss = 4.571804046630859
07/29 02:07:30 AM | Likelihood = tensor([0.7263, 0.7263, 0.7262,  ..., 0.7262, 0.7262, 0.7262], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18155.09375, dataIndex = 1728, step = 53
07/29 02:07:35 AM | standard loss = 4.464752197265625
07/29 02:07:35 AM | weighted loss = 4.464751720428467
07/29 02:07:35 AM | Likelihood = tensor([0.7262, 0.7262, 0.7261,  ..., 0.7261, 0.7261, 0.7261], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18152.6171875, dataIndex = 1760, step = 54
07/29 02:07:40 AM | standard loss = 4.6359663009643555
07/29 02:07:40 AM | weighted loss = 4.635966777801514
07/29 02:07:40 AM | Likelihood = tensor([0.7261, 0.7261, 0.7260,  ..., 0.7260, 0.7260, 0.7260], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18150.13671875, dataIndex = 1792, step = 55
07/29 02:07:45 AM | standard loss = 4.197896480560303
07/29 02:07:45 AM | weighted loss = 4.197895526885986
07/29 02:07:45 AM | Likelihood = tensor([0.7260, 0.7260, 0.7259,  ..., 0.7259, 0.7259, 0.7259], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18147.65625, dataIndex = 1824, step = 56
07/29 02:07:50 AM | standard loss = 4.1999006271362305
07/29 02:07:50 AM | weighted loss = 4.199901103973389
07/29 02:07:50 AM | Likelihood = tensor([0.7259, 0.7259, 0.7258,  ..., 0.7258, 0.7258, 0.7258], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18145.1796875, dataIndex = 1856, step = 57
07/29 02:07:55 AM | standard loss = 4.080347061157227
07/29 02:07:55 AM | weighted loss = 4.080346584320068
07/29 02:07:55 AM | Likelihood = tensor([0.7258, 0.7258, 0.7257,  ..., 0.7257, 0.7257, 0.7257], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18142.697265625, dataIndex = 1888, step = 58
07/29 02:08:00 AM | standard loss = 4.215429782867432
07/29 02:08:00 AM | weighted loss = 4.215429782867432
07/29 02:08:00 AM | Likelihood = tensor([0.7257, 0.7257, 0.7256,  ..., 0.7256, 0.7256, 0.7256], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18140.2109375, dataIndex = 1920, step = 59
07/29 02:08:05 AM | standard loss = 4.477303504943848
07/29 02:08:05 AM | weighted loss = 4.477303504943848
07/29 02:08:05 AM | Likelihood = tensor([0.7256, 0.7256, 0.7255,  ..., 0.7255, 0.7255, 0.7255], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18137.7265625, dataIndex = 1952, step = 60
07/29 02:08:10 AM | standard loss = 4.613365173339844
07/29 02:08:10 AM | weighted loss = 4.613365173339844
07/29 02:08:10 AM | Likelihood = tensor([0.7255, 0.7255, 0.7254,  ..., 0.7254, 0.7254, 0.7254], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18135.23828125, dataIndex = 1984, step = 61
07/29 02:08:15 AM | standard loss = 4.312921524047852
07/29 02:08:15 AM | weighted loss = 4.312921524047852
07/29 02:08:15 AM | Likelihood = tensor([0.7254, 0.7254, 0.7253,  ..., 0.7253, 0.7253, 0.7253], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18132.748046875, dataIndex = 2016, step = 62
07/29 02:08:20 AM | standard loss = 4.098700523376465
07/29 02:08:20 AM | weighted loss = 4.098700523376465
07/29 02:08:20 AM | Likelihood = tensor([0.7253, 0.7253, 0.7252,  ..., 0.7252, 0.7252, 0.7252], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18130.259765625, dataIndex = 2048, step = 63
07/29 02:08:25 AM | standard loss = 4.318161964416504
07/29 02:08:25 AM | weighted loss = 4.318161964416504
07/29 02:08:25 AM | Likelihood = tensor([0.7252, 0.7252, 0.7251,  ..., 0.7251, 0.7251, 0.7251], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18127.7734375, dataIndex = 2080, step = 64
07/29 02:08:30 AM | standard loss = 4.457206726074219
07/29 02:08:30 AM | weighted loss = 4.457206726074219
07/29 02:08:30 AM | Likelihood = tensor([0.7251, 0.7251, 0.7250,  ..., 0.7250, 0.7250, 0.7250], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18125.27734375, dataIndex = 2112, step = 65
07/29 02:08:35 AM | standard loss = 4.508142471313477
07/29 02:08:35 AM | weighted loss = 4.508142471313477
07/29 02:08:35 AM | Likelihood = tensor([0.7250, 0.7250, 0.7249,  ..., 0.7249, 0.7249, 0.7249], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18122.7890625, dataIndex = 2144, step = 66
07/29 02:08:40 AM | standard loss = 4.186059474945068
07/29 02:08:40 AM | weighted loss = 4.186059474945068
07/29 02:08:40 AM | Likelihood = tensor([0.7249, 0.7249, 0.7248,  ..., 0.7248, 0.7248, 0.7248], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18120.29296875, dataIndex = 2176, step = 67
07/29 02:08:45 AM | standard loss = 4.316173076629639
07/29 02:08:45 AM | weighted loss = 4.3161725997924805
07/29 02:08:45 AM | Likelihood = tensor([0.7248, 0.7248, 0.7247,  ..., 0.7247, 0.7247, 0.7247], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18117.798828125, dataIndex = 2208, step = 68
07/29 02:08:50 AM | standard loss = 4.176729679107666
07/29 02:08:50 AM | weighted loss = 4.176730155944824
07/29 02:08:50 AM | Likelihood = tensor([0.7247, 0.7247, 0.7246,  ..., 0.7246, 0.7246, 0.7246], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18115.3046875, dataIndex = 2240, step = 69
07/29 02:08:55 AM | standard loss = 4.573009967803955
07/29 02:08:55 AM | weighted loss = 4.573009490966797
07/29 02:08:55 AM | Likelihood = tensor([0.7246, 0.7246, 0.7245,  ..., 0.7245, 0.7245, 0.7245], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18112.8046875, dataIndex = 2272, step = 70
07/29 02:09:00 AM | standard loss = 4.476071834564209
07/29 02:09:00 AM | weighted loss = 4.476070880889893
07/29 02:09:00 AM | Likelihood = tensor([0.7245, 0.7244, 0.7244,  ..., 0.7244, 0.7244, 0.7244], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18110.310546875, dataIndex = 2304, step = 71
07/29 02:09:05 AM | standard loss = 4.457482814788818
07/29 02:09:05 AM | weighted loss = 4.457483291625977
07/29 02:09:05 AM | Likelihood = tensor([0.7244, 0.7243, 0.7243,  ..., 0.7243, 0.7243, 0.7243], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18107.810546875, dataIndex = 2336, step = 72
07/29 02:09:10 AM | standard loss = 4.7843122482299805
07/29 02:09:10 AM | weighted loss = 4.784311294555664
07/29 02:09:10 AM | Likelihood = tensor([0.7243, 0.7242, 0.7242,  ..., 0.7242, 0.7242, 0.7242], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18105.30859375, dataIndex = 2368, step = 73
07/29 02:09:14 AM | standard loss = 4.1768798828125
07/29 02:09:15 AM | weighted loss = 4.176880359649658
07/29 02:09:15 AM | Likelihood = tensor([0.7242, 0.7241, 0.7241,  ..., 0.7241, 0.7241, 0.7241], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18102.8125, dataIndex = 2400, step = 74
07/29 02:09:19 AM | standard loss = 4.117604732513428
07/29 02:09:19 AM | weighted loss = 4.1176042556762695
07/29 02:09:19 AM | Likelihood = tensor([0.7241, 0.7240, 0.7240,  ..., 0.7240, 0.7240, 0.7240], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18100.3125, dataIndex = 2432, step = 75
07/29 02:09:25 AM | standard loss = 4.570287227630615
07/29 02:09:25 AM | weighted loss = 4.570288181304932
07/29 02:09:25 AM | Likelihood = tensor([0.7240, 0.7239, 0.7239,  ..., 0.7239, 0.7239, 0.7239], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18097.80859375, dataIndex = 2464, step = 76
07/29 02:09:29 AM | standard loss = 4.308359622955322
07/29 02:09:29 AM | weighted loss = 4.308359622955322
07/29 02:09:29 AM | Likelihood = tensor([0.7239, 0.7238, 0.7238,  ..., 0.7238, 0.7238, 0.7238], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18095.3046875, dataIndex = 2496, step = 77
07/29 02:09:35 AM | standard loss = 4.6202216148376465
07/29 02:09:35 AM | weighted loss = 4.6202216148376465
07/29 02:09:35 AM | Likelihood = tensor([0.7238, 0.7237, 0.7237,  ..., 0.7237, 0.7237, 0.7237], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18092.80078125, dataIndex = 2528, step = 78
07/29 02:09:39 AM | standard loss = 4.606075763702393
07/29 02:09:39 AM | weighted loss = 4.606076240539551
07/29 02:09:40 AM | Likelihood = tensor([0.7237, 0.7236, 0.7236,  ..., 0.7236, 0.7236, 0.7236], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18090.296875, dataIndex = 2560, step = 79
07/29 02:09:44 AM | standard loss = 4.311644554138184
07/29 02:09:44 AM | weighted loss = 4.311645030975342
07/29 02:09:44 AM | Likelihood = tensor([0.7236, 0.7235, 0.7235,  ..., 0.7235, 0.7235, 0.7235], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18087.7890625, dataIndex = 2592, step = 80
07/29 02:09:49 AM | standard loss = 4.398396968841553
07/29 02:09:49 AM | weighted loss = 4.398396968841553
07/29 02:09:49 AM | Likelihood = tensor([0.7235, 0.7234, 0.7234,  ..., 0.7234, 0.7234, 0.7234], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18085.283203125, dataIndex = 2624, step = 81
07/29 02:09:54 AM | standard loss = 4.210344314575195
07/29 02:09:54 AM | weighted loss = 4.210343837738037
07/29 02:09:54 AM | Likelihood = tensor([0.7234, 0.7233, 0.7233,  ..., 0.7233, 0.7233, 0.7233], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18082.77734375, dataIndex = 2656, step = 82
07/29 02:09:59 AM | standard loss = 4.244410037994385
07/29 02:09:59 AM | weighted loss = 4.244410514831543
07/29 02:09:59 AM | Likelihood = tensor([0.7233, 0.7232, 0.7232,  ..., 0.7232, 0.7232, 0.7232], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18080.265625, dataIndex = 2688, step = 83
07/29 02:10:04 AM | standard loss = 4.349637031555176
07/29 02:10:04 AM | weighted loss = 4.349636077880859
07/29 02:10:04 AM | Likelihood = tensor([0.7232, 0.7231, 0.7231,  ..., 0.7231, 0.7231, 0.7231], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18077.759765625, dataIndex = 2720, step = 84
07/29 02:10:09 AM | standard loss = 4.516696453094482
07/29 02:10:09 AM | weighted loss = 4.516695976257324
07/29 02:10:09 AM | Likelihood = tensor([0.7231, 0.7230, 0.7230,  ..., 0.7230, 0.7230, 0.7230], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18075.25390625, dataIndex = 2752, step = 85
07/29 02:10:14 AM | standard loss = 4.256391525268555
07/29 02:10:14 AM | weighted loss = 4.256392002105713
07/29 02:10:14 AM | Likelihood = tensor([0.7230, 0.7229, 0.7229,  ..., 0.7229, 0.7229, 0.7229], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18072.7421875, dataIndex = 2784, step = 86
07/29 02:10:19 AM | standard loss = 4.161148548126221
07/29 02:10:19 AM | weighted loss = 4.1611480712890625
07/29 02:10:19 AM | Likelihood = tensor([0.7229, 0.7228, 0.7228,  ..., 0.7228, 0.7228, 0.7228], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18070.228515625, dataIndex = 2816, step = 87
07/29 02:10:24 AM | standard loss = 4.317872047424316
07/29 02:10:24 AM | weighted loss = 4.317871570587158
07/29 02:10:24 AM | Likelihood = tensor([0.7228, 0.7227, 0.7227,  ..., 0.7227, 0.7227, 0.7227], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18067.72265625, dataIndex = 2848, step = 88
07/29 02:10:29 AM | standard loss = 4.0189032554626465
07/29 02:10:29 AM | weighted loss = 4.018903732299805
07/29 02:10:29 AM | Likelihood = tensor([0.7227, 0.7226, 0.7226,  ..., 0.7226, 0.7226, 0.7226], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18065.20703125, dataIndex = 2880, step = 89
07/29 02:10:34 AM | standard loss = 4.367849349975586
07/29 02:10:34 AM | weighted loss = 4.367849826812744
07/29 02:10:34 AM | Likelihood = tensor([0.7226, 0.7225, 0.7225,  ..., 0.7225, 0.7225, 0.7225], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18062.6953125, dataIndex = 2912, step = 90
07/29 02:10:39 AM | standard loss = 4.584033012390137
07/29 02:10:39 AM | weighted loss = 4.584033012390137
07/29 02:10:39 AM | Likelihood = tensor([0.7225, 0.7224, 0.7224,  ..., 0.7224, 0.7224, 0.7224], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18060.185546875, dataIndex = 2944, step = 91
07/29 02:10:44 AM | standard loss = 4.6437087059021
07/29 02:10:44 AM | weighted loss = 4.6437087059021
07/29 02:10:44 AM | Likelihood = tensor([0.7224, 0.7223, 0.7222,  ..., 0.7223, 0.7223, 0.7223], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18057.666015625, dataIndex = 2976, step = 92
07/29 02:10:49 AM | standard loss = 4.129917621612549
07/29 02:10:49 AM | weighted loss = 4.129917621612549
07/29 02:10:49 AM | Likelihood = tensor([0.7223, 0.7222, 0.7221,  ..., 0.7222, 0.7222, 0.7222], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18055.15625, dataIndex = 3008, step = 93
07/29 02:10:54 AM | standard loss = 4.247622489929199
07/29 02:10:54 AM | weighted loss = 4.247622489929199
07/29 02:10:54 AM | Likelihood = tensor([0.7222, 0.7221, 0.7220,  ..., 0.7221, 0.7221, 0.7221], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18052.640625, dataIndex = 3040, step = 94
07/29 02:10:59 AM | standard loss = 4.423639297485352
07/29 02:10:59 AM | weighted loss = 4.423638343811035
07/29 02:10:59 AM | Likelihood = tensor([0.7221, 0.7220, 0.7219,  ..., 0.7220, 0.7220, 0.7220], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18050.125, dataIndex = 3072, step = 95
07/29 02:11:04 AM | standard loss = 4.318562984466553
07/29 02:11:04 AM | weighted loss = 4.318562984466553
07/29 02:11:04 AM | Likelihood = tensor([0.7220, 0.7219, 0.7218,  ..., 0.7219, 0.7219, 0.7219], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18047.60546875, dataIndex = 3104, step = 96
07/29 02:11:09 AM | standard loss = 4.346613883972168
07/29 02:11:09 AM | weighted loss = 4.34661340713501
07/29 02:11:09 AM | Likelihood = tensor([0.7219, 0.7218, 0.7217,  ..., 0.7218, 0.7218, 0.7218], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18045.08984375, dataIndex = 3136, step = 97
07/29 02:11:14 AM | standard loss = 4.146839618682861
07/29 02:11:14 AM | weighted loss = 4.146839618682861
07/29 02:11:14 AM | Likelihood = tensor([0.7218, 0.7217, 0.7216,  ..., 0.7217, 0.7217, 0.7217], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18042.57421875, dataIndex = 3168, step = 98
07/29 02:11:19 AM | standard loss = 4.03348970413208
07/29 02:11:19 AM | weighted loss = 4.03348970413208
07/29 02:11:19 AM | Likelihood = tensor([0.7217, 0.7216, 0.7215,  ..., 0.7216, 0.7216, 0.7216], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18040.056640625, dataIndex = 3200, step = 99
07/29 02:11:24 AM | standard loss = 4.227550983428955
07/29 02:11:24 AM | weighted loss = 4.227550983428955
07/29 02:11:24 AM | Likelihood = tensor([0.7216, 0.7215, 0.7214,  ..., 0.7215, 0.7215, 0.7215], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18037.5390625, dataIndex = 3232, step = 100
07/29 02:11:25 AM | Train: [ 1/50] Step 100/781 Loss 4.468 Prec@(1,5) (3.5%, 13.9%)
07/29 02:11:29 AM | standard loss = 4.104478359222412
07/29 02:11:29 AM | weighted loss = 4.10447883605957
07/29 02:11:29 AM | Likelihood = tensor([0.7215, 0.7214, 0.7213,  ..., 0.7214, 0.7214, 0.7214], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18035.017578125, dataIndex = 3264, step = 101
07/29 02:11:34 AM | standard loss = 4.268180847167969
07/29 02:11:34 AM | weighted loss = 4.2681803703308105
07/29 02:11:34 AM | Likelihood = tensor([0.7214, 0.7213, 0.7212,  ..., 0.7213, 0.7213, 0.7213], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18032.5, dataIndex = 3296, step = 102
07/29 02:11:39 AM | standard loss = 4.231121063232422
07/29 02:11:39 AM | weighted loss = 4.231121063232422
07/29 02:11:39 AM | Likelihood = tensor([0.7213, 0.7212, 0.7211,  ..., 0.7212, 0.7212, 0.7212], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18029.98046875, dataIndex = 3328, step = 103
07/29 02:11:44 AM | standard loss = 4.147678375244141
07/29 02:11:44 AM | weighted loss = 4.147678852081299
07/29 02:11:44 AM | Likelihood = tensor([0.7212, 0.7211, 0.7210,  ..., 0.7211, 0.7211, 0.7211], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18027.45703125, dataIndex = 3360, step = 104
07/29 02:11:49 AM | standard loss = 3.9647164344787598
07/29 02:11:49 AM | weighted loss = 3.9647164344787598
07/29 02:11:49 AM | Likelihood = tensor([0.7211, 0.7210, 0.7209,  ..., 0.7210, 0.7210, 0.7210], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18024.94140625, dataIndex = 3392, step = 105
07/29 02:11:55 AM | standard loss = 4.160099983215332
07/29 02:11:55 AM | weighted loss = 4.160099983215332
07/29 02:11:55 AM | Likelihood = tensor([0.7210, 0.7209, 0.7208,  ..., 0.7209, 0.7209, 0.7209], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18022.41796875, dataIndex = 3424, step = 106
07/29 02:12:00 AM | standard loss = 3.754876136779785
07/29 02:12:00 AM | weighted loss = 3.754875898361206
07/29 02:12:00 AM | Likelihood = tensor([0.7209, 0.7208, 0.7207,  ..., 0.7208, 0.7208, 0.7208], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18019.8984375, dataIndex = 3456, step = 107
07/29 02:12:04 AM | standard loss = 4.366893768310547
07/29 02:12:04 AM | weighted loss = 4.366893291473389
07/29 02:12:04 AM | Likelihood = tensor([0.7208, 0.7207, 0.7206,  ..., 0.7207, 0.7207, 0.7207], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18017.373046875, dataIndex = 3488, step = 108
07/29 02:12:09 AM | standard loss = 4.1767425537109375
07/29 02:12:09 AM | weighted loss = 4.1767425537109375
07/29 02:12:09 AM | Likelihood = tensor([0.7207, 0.7206, 0.7205,  ..., 0.7206, 0.7206, 0.7206], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18014.84765625, dataIndex = 3520, step = 109
07/29 02:12:14 AM | standard loss = 4.331785202026367
07/29 02:12:14 AM | weighted loss = 4.331785202026367
07/29 02:12:14 AM | Likelihood = tensor([0.7206, 0.7205, 0.7204,  ..., 0.7205, 0.7205, 0.7205], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18012.328125, dataIndex = 3552, step = 110
07/29 02:12:19 AM | standard loss = 4.200184345245361
07/29 02:12:19 AM | weighted loss = 4.2001848220825195
07/29 02:12:19 AM | Likelihood = tensor([0.7205, 0.7204, 0.7203,  ..., 0.7204, 0.7204, 0.7204], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18009.8046875, dataIndex = 3584, step = 111
07/29 02:12:23 AM | standard loss = 4.324409008026123
07/29 02:12:23 AM | weighted loss = 4.324408531188965
07/29 02:12:23 AM | Likelihood = tensor([0.7204, 0.7203, 0.7202,  ..., 0.7203, 0.7203, 0.7203], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18007.279296875, dataIndex = 3616, step = 112
07/29 02:12:28 AM | standard loss = 4.256756782531738
07/29 02:12:28 AM | weighted loss = 4.2567572593688965
07/29 02:12:28 AM | Likelihood = tensor([0.7203, 0.7202, 0.7201,  ..., 0.7202, 0.7202, 0.7202], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18004.7578125, dataIndex = 3648, step = 113
07/29 02:12:33 AM | standard loss = 3.841296434402466
07/29 02:12:33 AM | weighted loss = 3.841296672821045
07/29 02:12:33 AM | Likelihood = tensor([0.7202, 0.7201, 0.7200,  ..., 0.7201, 0.7201, 0.7201], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=18002.23046875, dataIndex = 3680, step = 114
07/29 02:12:38 AM | standard loss = 4.280038356781006
07/29 02:12:38 AM | weighted loss = 4.280037879943848
07/29 02:12:38 AM | Likelihood = tensor([0.7201, 0.7200, 0.7199,  ..., 0.7200, 0.7200, 0.7200], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17999.705078125, dataIndex = 3712, step = 115
07/29 02:12:43 AM | standard loss = 3.984659194946289
07/29 02:12:43 AM | weighted loss = 3.984659194946289
07/29 02:12:43 AM | Likelihood = tensor([0.7200, 0.7199, 0.7198,  ..., 0.7199, 0.7199, 0.7199], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17997.177734375, dataIndex = 3744, step = 116
07/29 02:12:48 AM | standard loss = 4.047491550445557
07/29 02:12:48 AM | weighted loss = 4.047492027282715
07/29 02:12:48 AM | Likelihood = tensor([0.7199, 0.7198, 0.7197,  ..., 0.7198, 0.7198, 0.7198], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17994.65234375, dataIndex = 3776, step = 117
07/29 02:12:53 AM | standard loss = 4.28571891784668
07/29 02:12:53 AM | weighted loss = 4.28571891784668
07/29 02:12:53 AM | Likelihood = tensor([0.7198, 0.7197, 0.7196,  ..., 0.7197, 0.7197, 0.7197], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17992.125, dataIndex = 3808, step = 118
07/29 02:12:58 AM | standard loss = 4.286352157592773
07/29 02:12:58 AM | weighted loss = 4.286352634429932
07/29 02:12:58 AM | Likelihood = tensor([0.7197, 0.7196, 0.7195,  ..., 0.7196, 0.7196, 0.7196], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17989.59765625, dataIndex = 3840, step = 119
07/29 02:13:02 AM | standard loss = 4.220588684082031
07/29 02:13:02 AM | weighted loss = 4.2205891609191895
07/29 02:13:02 AM | Likelihood = tensor([0.7196, 0.7195, 0.7194,  ..., 0.7195, 0.7195, 0.7195], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17987.0703125, dataIndex = 3872, step = 120
07/29 02:13:07 AM | standard loss = 4.070113182067871
07/29 02:13:07 AM | weighted loss = 4.070113182067871
07/29 02:13:07 AM | Likelihood = tensor([0.7195, 0.7194, 0.7193,  ..., 0.7194, 0.7194, 0.7194], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17984.54296875, dataIndex = 3904, step = 121
07/29 02:13:12 AM | standard loss = 4.414323329925537
07/29 02:13:12 AM | weighted loss = 4.414323806762695
07/29 02:13:12 AM | Likelihood = tensor([0.7194, 0.7193, 0.7192,  ..., 0.7193, 0.7193, 0.7193], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17982.015625, dataIndex = 3936, step = 122
07/29 02:13:17 AM | standard loss = 4.162932395935059
07/29 02:13:17 AM | weighted loss = 4.1629319190979
07/29 02:13:17 AM | Likelihood = tensor([0.7193, 0.7192, 0.7191,  ..., 0.7192, 0.7192, 0.7192], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17979.48828125, dataIndex = 3968, step = 123
07/29 02:13:22 AM | standard loss = 4.030611038208008
07/29 02:13:22 AM | weighted loss = 4.030611038208008
07/29 02:13:22 AM | Likelihood = tensor([0.7192, 0.7191, 0.7190,  ..., 0.7191, 0.7191, 0.7191], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17976.95703125, dataIndex = 4000, step = 124
07/29 02:13:27 AM | standard loss = 4.336581230163574
07/29 02:13:27 AM | weighted loss = 4.336581230163574
07/29 02:13:27 AM | Likelihood = tensor([0.7191, 0.7190, 0.7189,  ..., 0.7190, 0.7190, 0.7190], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17974.4296875, dataIndex = 4032, step = 125
07/29 02:13:32 AM | standard loss = 4.154642581939697
07/29 02:13:32 AM | weighted loss = 4.1546430587768555
07/29 02:13:32 AM | Likelihood = tensor([0.7190, 0.7189, 0.7188,  ..., 0.7189, 0.7189, 0.7189], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17971.896484375, dataIndex = 4064, step = 126
07/29 02:13:37 AM | standard loss = 4.127108097076416
07/29 02:13:37 AM | weighted loss = 4.127107620239258
07/29 02:13:37 AM | Likelihood = tensor([0.7189, 0.7188, 0.7187,  ..., 0.7188, 0.7188, 0.7188], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17969.3671875, dataIndex = 4096, step = 127
07/29 02:13:42 AM | standard loss = 4.303463459014893
07/29 02:13:42 AM | weighted loss = 4.303462982177734
07/29 02:13:42 AM | Likelihood = tensor([0.7188, 0.7187, 0.7186,  ..., 0.7187, 0.7187, 0.7187], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17966.83984375, dataIndex = 4128, step = 128
07/29 02:13:47 AM | standard loss = 4.344395637512207
07/29 02:13:47 AM | weighted loss = 4.344396114349365
07/29 02:13:47 AM | Likelihood = tensor([0.7187, 0.7186, 0.7185,  ..., 0.7186, 0.7186, 0.7186], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17964.3046875, dataIndex = 4160, step = 129
07/29 02:13:52 AM | standard loss = 4.028528690338135
07/29 02:13:52 AM | weighted loss = 4.028529644012451
07/29 02:13:52 AM | Likelihood = tensor([0.7186, 0.7185, 0.7184,  ..., 0.7185, 0.7185, 0.7185], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17961.775390625, dataIndex = 4192, step = 130
07/29 02:13:57 AM | standard loss = 4.199259281158447
07/29 02:13:57 AM | weighted loss = 4.199259281158447
07/29 02:13:57 AM | Likelihood = tensor([0.7185, 0.7184, 0.7183,  ..., 0.7184, 0.7184, 0.7184], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17959.24609375, dataIndex = 4224, step = 131
07/29 02:14:02 AM | standard loss = 4.260374546051025
07/29 02:14:02 AM | weighted loss = 4.260373592376709
07/29 02:14:02 AM | Likelihood = tensor([0.7184, 0.7183, 0.7182,  ..., 0.7183, 0.7183, 0.7183], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17956.7109375, dataIndex = 4256, step = 132
07/29 02:14:07 AM | standard loss = 4.07984733581543
07/29 02:14:07 AM | weighted loss = 4.07984733581543
07/29 02:14:07 AM | Likelihood = tensor([0.7183, 0.7182, 0.7181,  ..., 0.7182, 0.7182, 0.7182], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17954.1796875, dataIndex = 4288, step = 133
07/29 02:14:12 AM | standard loss = 4.177545547485352
07/29 02:14:12 AM | weighted loss = 4.177545547485352
07/29 02:14:12 AM | Likelihood = tensor([0.7182, 0.7181, 0.7180,  ..., 0.7181, 0.7181, 0.7181], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17951.64453125, dataIndex = 4320, step = 134
07/29 02:14:17 AM | standard loss = 4.241663455963135
07/29 02:14:17 AM | weighted loss = 4.241663455963135
07/29 02:14:17 AM | Likelihood = tensor([0.7181, 0.7180, 0.7179,  ..., 0.7180, 0.7180, 0.7180], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17949.115234375, dataIndex = 4352, step = 135
07/29 02:14:22 AM | standard loss = 4.309301853179932
07/29 02:14:22 AM | weighted loss = 4.309301376342773
07/29 02:14:22 AM | Likelihood = tensor([0.7180, 0.7179, 0.7178,  ..., 0.7179, 0.7179, 0.7179], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17946.583984375, dataIndex = 4384, step = 136
07/29 02:14:26 AM | standard loss = 3.700267791748047
07/29 02:14:26 AM | weighted loss = 3.700268030166626
07/29 02:14:26 AM | Likelihood = tensor([0.7179, 0.7177, 0.7177,  ..., 0.7178, 0.7178, 0.7178], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17944.046875, dataIndex = 4416, step = 137
07/29 02:14:32 AM | standard loss = 4.277794361114502
07/29 02:14:32 AM | weighted loss = 4.277794361114502
07/29 02:14:32 AM | Likelihood = tensor([0.7178, 0.7176, 0.7176,  ..., 0.7177, 0.7177, 0.7177], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17941.51171875, dataIndex = 4448, step = 138
07/29 02:14:37 AM | standard loss = 4.049460411071777
07/29 02:14:37 AM | weighted loss = 4.049459934234619
07/29 02:14:37 AM | Likelihood = tensor([0.7177, 0.7175, 0.7175,  ..., 0.7176, 0.7176, 0.7176], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17938.98046875, dataIndex = 4480, step = 139
07/29 02:14:43 AM | standard loss = 3.9474785327911377
07/29 02:14:43 AM | weighted loss = 3.9474778175354004
07/29 02:14:43 AM | Likelihood = tensor([0.7176, 0.7174, 0.7174,  ..., 0.7175, 0.7175, 0.7175], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17936.4453125, dataIndex = 4512, step = 140
07/29 02:14:48 AM | standard loss = 4.381255149841309
07/29 02:14:48 AM | weighted loss = 4.381255149841309
07/29 02:14:48 AM | Likelihood = tensor([0.7175, 0.7173, 0.7173,  ..., 0.7174, 0.7174, 0.7174], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17933.9140625, dataIndex = 4544, step = 141
07/29 02:14:53 AM | standard loss = 4.428191661834717
07/29 02:14:53 AM | weighted loss = 4.428191661834717
07/29 02:14:53 AM | Likelihood = tensor([0.7174, 0.7172, 0.7172,  ..., 0.7173, 0.7173, 0.7173], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17931.376953125, dataIndex = 4576, step = 142
07/29 02:14:58 AM | standard loss = 4.036877632141113
07/29 02:14:58 AM | weighted loss = 4.036877632141113
07/29 02:14:58 AM | Likelihood = tensor([0.7173, 0.7171, 0.7171,  ..., 0.7172, 0.7172, 0.7172], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17928.841796875, dataIndex = 4608, step = 143
07/29 02:15:03 AM | standard loss = 3.8472814559936523
07/29 02:15:03 AM | weighted loss = 3.847280979156494
07/29 02:15:03 AM | Likelihood = tensor([0.7172, 0.7170, 0.7170,  ..., 0.7170, 0.7170, 0.7170], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17926.306640625, dataIndex = 4640, step = 144
07/29 02:15:08 AM | standard loss = 4.464926242828369
07/29 02:15:08 AM | weighted loss = 4.464926719665527
07/29 02:15:08 AM | Likelihood = tensor([0.7171, 0.7169, 0.7169,  ..., 0.7169, 0.7169, 0.7169], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17923.76953125, dataIndex = 4672, step = 145
07/29 02:15:13 AM | standard loss = 4.200486660003662
07/29 02:15:13 AM | weighted loss = 4.200486183166504
07/29 02:15:13 AM | Likelihood = tensor([0.7170, 0.7168, 0.7168,  ..., 0.7168, 0.7168, 0.7168], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17921.232421875, dataIndex = 4704, step = 146
07/29 02:15:18 AM | standard loss = 4.131637096405029
07/29 02:15:18 AM | weighted loss = 4.1316375732421875
07/29 02:15:18 AM | Likelihood = tensor([0.7169, 0.7167, 0.7167,  ..., 0.7167, 0.7167, 0.7167], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17918.697265625, dataIndex = 4736, step = 147
07/29 02:15:23 AM | standard loss = 4.07922887802124
07/29 02:15:23 AM | weighted loss = 4.079229354858398
07/29 02:15:23 AM | Likelihood = tensor([0.7168, 0.7166, 0.7166,  ..., 0.7166, 0.7166, 0.7166], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17916.162109375, dataIndex = 4768, step = 148
07/29 02:15:27 AM | standard loss = 4.17534065246582
07/29 02:15:27 AM | weighted loss = 4.17534065246582
07/29 02:15:27 AM | Likelihood = tensor([0.7167, 0.7165, 0.7165,  ..., 0.7165, 0.7165, 0.7165], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17913.625, dataIndex = 4800, step = 149
07/29 02:15:32 AM | standard loss = 4.557626247406006
07/29 02:15:32 AM | weighted loss = 4.557625770568848
07/29 02:15:32 AM | Likelihood = tensor([0.7166, 0.7164, 0.7164,  ..., 0.7164, 0.7164, 0.7164], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17911.087890625, dataIndex = 4832, step = 150
07/29 02:15:33 AM | Train: [ 1/50] Step 150/781 Loss 4.371 Prec@(1,5) (4.4%, 16.5%)
07/29 02:15:37 AM | standard loss = 4.256018161773682
07/29 02:15:37 AM | weighted loss = 4.256017684936523
07/29 02:15:37 AM | Likelihood = tensor([0.7165, 0.7163, 0.7163,  ..., 0.7163, 0.7163, 0.7163], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17908.548828125, dataIndex = 4864, step = 151
07/29 02:15:42 AM | standard loss = 3.885488510131836
07/29 02:15:42 AM | weighted loss = 3.885488271713257
07/29 02:15:42 AM | Likelihood = tensor([0.7164, 0.7162, 0.7162,  ..., 0.7162, 0.7162, 0.7162], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17906.01171875, dataIndex = 4896, step = 152
07/29 02:15:47 AM | standard loss = 3.706895112991333
07/29 02:15:47 AM | weighted loss = 3.706895351409912
07/29 02:15:47 AM | Likelihood = tensor([0.7163, 0.7161, 0.7161,  ..., 0.7161, 0.7161, 0.7161], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17903.47265625, dataIndex = 4928, step = 153
07/29 02:15:52 AM | standard loss = 4.050923824310303
07/29 02:15:52 AM | weighted loss = 4.050923824310303
07/29 02:15:52 AM | Likelihood = tensor([0.7162, 0.7160, 0.7160,  ..., 0.7160, 0.7160, 0.7160], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17900.931640625, dataIndex = 4960, step = 154
07/29 02:15:57 AM | standard loss = 4.363590717315674
07/29 02:15:57 AM | weighted loss = 4.363590240478516
07/29 02:15:57 AM | Likelihood = tensor([0.7161, 0.7159, 0.7159,  ..., 0.7159, 0.7159, 0.7159], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17898.39453125, dataIndex = 4992, step = 155
07/29 02:16:02 AM | standard loss = 4.162581920623779
07/29 02:16:02 AM | weighted loss = 4.162581920623779
07/29 02:16:02 AM | Likelihood = tensor([0.7160, 0.7158, 0.7158,  ..., 0.7158, 0.7158, 0.7158], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17895.85546875, dataIndex = 5024, step = 156
07/29 02:16:07 AM | standard loss = 3.6928324699401855
07/29 02:16:07 AM | weighted loss = 3.6928329467773438
07/29 02:16:07 AM | Likelihood = tensor([0.7159, 0.7157, 0.7157,  ..., 0.7157, 0.7157, 0.7157], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17893.31640625, dataIndex = 5056, step = 157
07/29 02:16:12 AM | standard loss = 4.155817985534668
07/29 02:16:12 AM | weighted loss = 4.155818462371826
07/29 02:16:12 AM | Likelihood = tensor([0.7158, 0.7156, 0.7156,  ..., 0.7156, 0.7156, 0.7156], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17890.77734375, dataIndex = 5088, step = 158
07/29 02:16:16 AM | standard loss = 3.9595353603363037
07/29 02:16:16 AM | weighted loss = 3.959536075592041
07/29 02:16:16 AM | Likelihood = tensor([0.7157, 0.7155, 0.7155,  ..., 0.7155, 0.7155, 0.7155], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17888.23828125, dataIndex = 5120, step = 159
07/29 02:16:21 AM | standard loss = 4.818939208984375
07/29 02:16:21 AM | weighted loss = 4.818939685821533
07/29 02:16:21 AM | Likelihood = tensor([0.7156, 0.7154, 0.7154,  ..., 0.7154, 0.7154, 0.7154], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17885.697265625, dataIndex = 5152, step = 160
07/29 02:16:26 AM | standard loss = 4.144440650939941
07/29 02:16:26 AM | weighted loss = 4.144440650939941
07/29 02:16:26 AM | Likelihood = tensor([0.7155, 0.7153, 0.7153,  ..., 0.7153, 0.7153, 0.7153], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17883.158203125, dataIndex = 5184, step = 161
07/29 02:16:31 AM | standard loss = 4.240786075592041
07/29 02:16:31 AM | weighted loss = 4.240785121917725
07/29 02:16:31 AM | Likelihood = tensor([0.7153, 0.7152, 0.7152,  ..., 0.7152, 0.7152, 0.7152], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17880.6171875, dataIndex = 5216, step = 162
07/29 02:16:36 AM | standard loss = 4.236035346984863
07/29 02:16:36 AM | weighted loss = 4.236035346984863
07/29 02:16:36 AM | Likelihood = tensor([0.7152, 0.7151, 0.7151,  ..., 0.7151, 0.7151, 0.7151], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17878.078125, dataIndex = 5248, step = 163
07/29 02:16:41 AM | standard loss = 4.23901891708374
07/29 02:16:41 AM | weighted loss = 4.23901891708374
07/29 02:16:41 AM | Likelihood = tensor([0.7151, 0.7150, 0.7149,  ..., 0.7150, 0.7150, 0.7150], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17875.5390625, dataIndex = 5280, step = 164
07/29 02:16:46 AM | standard loss = 4.052395820617676
07/29 02:16:46 AM | weighted loss = 4.052395343780518
07/29 02:16:46 AM | Likelihood = tensor([0.7150, 0.7149, 0.7148,  ..., 0.7149, 0.7149, 0.7149], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17872.9921875, dataIndex = 5312, step = 165
07/29 02:16:51 AM | standard loss = 3.4887847900390625
07/29 02:16:51 AM | weighted loss = 3.4887847900390625
07/29 02:16:51 AM | Likelihood = tensor([0.7149, 0.7148, 0.7147,  ..., 0.7148, 0.7148, 0.7148], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17870.453125, dataIndex = 5344, step = 166
07/29 02:16:56 AM | standard loss = 3.818094253540039
07/29 02:16:56 AM | weighted loss = 3.818094253540039
07/29 02:16:56 AM | Likelihood = tensor([0.7148, 0.7147, 0.7146,  ..., 0.7147, 0.7147, 0.7147], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17867.912109375, dataIndex = 5376, step = 167
07/29 02:17:01 AM | standard loss = 4.093006134033203
07/29 02:17:01 AM | weighted loss = 4.093006134033203
07/29 02:17:01 AM | Likelihood = tensor([0.7147, 0.7146, 0.7145,  ..., 0.7146, 0.7146, 0.7146], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17865.369140625, dataIndex = 5408, step = 168
07/29 02:17:06 AM | standard loss = 3.9441978931427
07/29 02:17:06 AM | weighted loss = 3.944197654724121
07/29 02:17:06 AM | Likelihood = tensor([0.7146, 0.7145, 0.7144,  ..., 0.7145, 0.7145, 0.7145], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17862.83203125, dataIndex = 5440, step = 169
07/29 02:17:11 AM | standard loss = 3.9847664833068848
07/29 02:17:11 AM | weighted loss = 3.9847660064697266
07/29 02:17:11 AM | Likelihood = tensor([0.7145, 0.7144, 0.7143,  ..., 0.7144, 0.7144, 0.7144], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17860.28515625, dataIndex = 5472, step = 170
07/29 02:17:16 AM | standard loss = 4.124693870544434
07/29 02:17:16 AM | weighted loss = 4.124693870544434
07/29 02:17:16 AM | Likelihood = tensor([0.7144, 0.7143, 0.7142,  ..., 0.7143, 0.7143, 0.7143], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17857.744140625, dataIndex = 5504, step = 171
07/29 02:17:21 AM | standard loss = 4.079718589782715
07/29 02:17:21 AM | weighted loss = 4.079718589782715
07/29 02:17:21 AM | Likelihood = tensor([0.7143, 0.7142, 0.7141,  ..., 0.7142, 0.7142, 0.7142], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17855.201171875, dataIndex = 5536, step = 172
07/29 02:17:26 AM | standard loss = 4.192333221435547
07/29 02:17:26 AM | weighted loss = 4.192332744598389
07/29 02:17:26 AM | Likelihood = tensor([0.7142, 0.7141, 0.7140,  ..., 0.7141, 0.7141, 0.7141], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17852.66015625, dataIndex = 5568, step = 173
07/29 02:17:31 AM | standard loss = 4.019421100616455
07/29 02:17:31 AM | weighted loss = 4.019420623779297
07/29 02:17:31 AM | Likelihood = tensor([0.7141, 0.7140, 0.7139,  ..., 0.7140, 0.7140, 0.7140], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17850.115234375, dataIndex = 5600, step = 174
07/29 02:17:36 AM | standard loss = 4.1463518142700195
07/29 02:17:36 AM | weighted loss = 4.1463518142700195
07/29 02:17:36 AM | Likelihood = tensor([0.7140, 0.7139, 0.7138,  ..., 0.7139, 0.7139, 0.7139], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17847.57421875, dataIndex = 5632, step = 175
07/29 02:17:42 AM | standard loss = 3.8709557056427
07/29 02:17:42 AM | weighted loss = 3.870955467224121
07/29 02:17:42 AM | Likelihood = tensor([0.7139, 0.7138, 0.7137,  ..., 0.7138, 0.7138, 0.7138], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17845.02734375, dataIndex = 5664, step = 176
07/29 02:17:47 AM | standard loss = 3.916069269180298
07/29 02:17:47 AM | weighted loss = 3.9160690307617188
07/29 02:17:47 AM | Likelihood = tensor([0.7138, 0.7137, 0.7136,  ..., 0.7137, 0.7137, 0.7137], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17842.484375, dataIndex = 5696, step = 177
07/29 02:17:52 AM | standard loss = 4.673593044281006
07/29 02:17:52 AM | weighted loss = 4.673593521118164
07/29 02:17:52 AM | Likelihood = tensor([0.7137, 0.7136, 0.7135,  ..., 0.7136, 0.7136, 0.7136], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17839.94140625, dataIndex = 5728, step = 178
07/29 02:17:57 AM | standard loss = 4.152397632598877
07/29 02:17:57 AM | weighted loss = 4.152397632598877
07/29 02:17:57 AM | Likelihood = tensor([0.7136, 0.7135, 0.7134,  ..., 0.7135, 0.7135, 0.7135], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17837.39453125, dataIndex = 5760, step = 179
07/29 02:18:02 AM | standard loss = 3.757596731185913
07/29 02:18:02 AM | weighted loss = 3.757596492767334
07/29 02:18:02 AM | Likelihood = tensor([0.7135, 0.7134, 0.7133,  ..., 0.7134, 0.7134, 0.7134], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17834.853515625, dataIndex = 5792, step = 180
07/29 02:18:07 AM | standard loss = 3.9434850215911865
07/29 02:18:07 AM | weighted loss = 3.9434850215911865
07/29 02:18:07 AM | Likelihood = tensor([0.7134, 0.7133, 0.7132,  ..., 0.7133, 0.7133, 0.7133], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17832.30859375, dataIndex = 5824, step = 181
07/29 02:18:11 AM | standard loss = 4.276701927185059
07/29 02:18:11 AM | weighted loss = 4.276701927185059
07/29 02:18:11 AM | Likelihood = tensor([0.7133, 0.7132, 0.7131,  ..., 0.7132, 0.7132, 0.7132], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17829.765625, dataIndex = 5856, step = 182
07/29 02:18:17 AM | standard loss = 3.9526820182800293
07/29 02:18:17 AM | weighted loss = 3.952681541442871
07/29 02:18:17 AM | Likelihood = tensor([0.7132, 0.7131, 0.7130,  ..., 0.7131, 0.7131, 0.7131], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17827.216796875, dataIndex = 5888, step = 183
07/29 02:18:21 AM | standard loss = 3.955965042114258
07/29 02:18:21 AM | weighted loss = 3.9559648036956787
07/29 02:18:21 AM | Likelihood = tensor([0.7131, 0.7129, 0.7129,  ..., 0.7130, 0.7130, 0.7130], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17824.673828125, dataIndex = 5920, step = 184
07/29 02:18:26 AM | standard loss = 3.6682751178741455
07/29 02:18:26 AM | weighted loss = 3.6682751178741455
07/29 02:18:26 AM | Likelihood = tensor([0.7130, 0.7128, 0.7128,  ..., 0.7129, 0.7129, 0.7129], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17822.126953125, dataIndex = 5952, step = 185
07/29 02:18:31 AM | standard loss = 4.029980182647705
07/29 02:18:31 AM | weighted loss = 4.029980182647705
07/29 02:18:31 AM | Likelihood = tensor([0.7129, 0.7127, 0.7127,  ..., 0.7128, 0.7128, 0.7128], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17819.58203125, dataIndex = 5984, step = 186
07/29 02:18:36 AM | standard loss = 3.9049744606018066
07/29 02:18:36 AM | weighted loss = 3.9049742221832275
07/29 02:18:36 AM | Likelihood = tensor([0.7128, 0.7126, 0.7126,  ..., 0.7127, 0.7127, 0.7127], device='cuda:0',
       grad_fn=<SigmoidBackward>), Likelihood sum=17817.03515625, dataIndex = 6016, step = 187
